{"title": "Outlier Ranking in Large-Scale Public Health Streams", "author": "Ananya Joshi, Tina Townes, Nolan Gormley, Luke Neureiter, Roni Rosenfeld, Bryan Wilder", "abstract": "Disease control experts inspect public health data streams daily for outliers\nworth investigating, like those corresponding to data quality issues or disease\noutbreaks. However, they can only examine a few of the thousands of\nmaximally-tied outliers returned by univariate outlier detection methods\napplied to large-scale public health data streams. To help experts distinguish\nthe most important outliers from these thousands of tied outliers, we propose a\nnew task for algorithms to rank the outputs of any univariate method applied to\neach of many streams. Our novel algorithm for this task, which leverages\nhierarchical networks and extreme value analysis, performed the best across\ntraditional outlier detection metrics in a human-expert evaluation using public\nhealth data streams. Most importantly, experts have used our open-source Python\nimplementation since April 2023 and report identifying outliers worth\ninvestigating 9.1x faster than their prior baseline. Other organizations can\nreadily adapt this implementation to create rankings from the outputs of their\ntailored univariate methods across large-scale streams.", "published": "2024-01-02", "categories": ["cs.AI"], "links": "http://arxiv.org/abs/2401.01459v1"}
{"title": "Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint", "author": "Soyed Tuhin Ahmed, Mehdi B. tahoori", "abstract": "Neural networks (NNs) are increasingly used in always-on safety-critical\napplications deployed on hardware accelerators (NN-HAs) employing various\nmemory technologies. Reliable continuous operation of NN is essential for\nsafety-critical applications. During online operation, NNs are susceptible to\nsingle and multiple permanent and soft errors due to factors such as radiation,\naging, and thermal effects. Explicit NN-HA testing methods cannot detect\ntransient faults during inference, are unsuitable for always-on applications,\nand require extensive test vector generation and storage. Therefore, in this\npaper, we propose the \\emph{uncertainty fingerprint} approach representing the\nonline fault status of NN. Furthermore, we propose a dual head NN topology\nspecifically designed to produce uncertainty fingerprints and the primary\nprediction of the NN in \\emph{a single shot}. During the online operation, by\nmatching the uncertainty fingerprint, we can concurrently self-test NNs with up\nto $100\\%$ coverage with a low false positive rate while maintaining a similar\nperformance of the primary task. Compared to existing works, memory overhead is\nreduced by up to $243.7$ MB, multiply and accumulate (MAC) operation is reduced\nby up to $10000\\times$, and false-positive rates are reduced by up to $89\\%$.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.ET"], "links": "http://arxiv.org/abs/2401.01458v1"}
{"title": "Hierarchical Over-the-Air Federated Learning with Awareness of Interference and Data Heterogeneity", "author": "Seyed Mohammad Azimi-Abarghouyi, Viktoria Fodor", "abstract": "When implementing hierarchical federated learning over wireless networks,\nscalability assurance and the ability to handle both interference and device\ndata heterogeneity are crucial. This work introduces a learning method designed\nto address these challenges, along with a scalable transmission scheme that\nefficiently uses a single wireless resource through over-the-air computation.\nTo provide resistance against data heterogeneity, we employ gradient\naggregations. Meanwhile, the impact of interference is minimized through\noptimized receiver normalizing factors. For this, we model a multi-cluster\nwireless network using stochastic geometry, and characterize the mean squared\nerror of the aggregation estimations as a function of the network parameters.\nWe show that despite the interference and the data heterogeneity, the proposed\nscheme achieves high learning accuracy and can significantly outperform the\nconventional hierarchical algorithm.", "published": "2024-01-02", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "links": "http://arxiv.org/abs/2401.01442v1"}
{"title": "Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference", "author": "Md Musfiqur Rahman, Murat Kocaoglu", "abstract": "Pearl's causal hierarchy establishes a clear separation between\nobservational, interventional, and counterfactual questions. Researchers\nproposed sound and complete algorithms to compute identifiable causal queries\nat a given level of the hierarchy using the causal structure and data from the\nlower levels of the hierarchy. However, most of these algorithms assume that we\ncan accurately estimate the probability distribution of the data, which is an\nimpractical assumption for high-dimensional variables such as images. On the\nother hand, modern generative deep learning architectures can be trained to\nlearn how to accurately sample from such high-dimensional distributions.\nEspecially with the recent rise of foundation models for images, it is\ndesirable to leverage pre-trained models to answer causal queries with such\nhigh-dimensional data. To address this, we propose a sequential training\nalgorithm that, given the causal structure and a pre-trained conditional\ngenerative model, can train a deep causal generative model, which utilizes the\npre-trained model and can provably sample from identifiable interventional and\ncounterfactual distributions. Our algorithm, called Modular-DCM, uses\nadversarial training to learn the network weights, and to the best of our\nknowledge, is the first algorithm that can make use of pre-trained models and\nprovably sample from any identifiable causal query in the presence of latent\nconfounders with high-dimensional data. We demonstrate the utility of our\nalgorithm using semi-synthetic and real-world datasets containing images as\nvariables in the causal structure.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ME", "stat.ML"], "links": "http://arxiv.org/abs/2401.01426v1"}
{"title": "SwapTransformer: highway overtaking tactical planner model via imitation learning on OSHA dataset", "author": "Alireza Shamsoshoara, Safin B Salih, Pedram Aghazadeh", "abstract": "This paper investigates the high-level decision-making problem in highway\nscenarios regarding lane changing and over-taking other slower vehicles. In\nparticular, this paper aims to improve the Travel Assist feature for automatic\novertaking and lane changes on highways. About 9 million samples including lane\nimages and other dynamic objects are collected in simulation. This data;\nOvertaking on Simulated HighwAys (OSHA) dataset is released to tackle this\nchallenge. To solve this problem, an architecture called SwapTransformer is\ndesigned and implemented as an imitation learning approach on the OSHA dataset.\nMoreover, auxiliary tasks such as future points and car distance network\npredictions are proposed to aid the model in better understanding the\nsurrounding environment. The performance of the proposed solution is compared\nwith a multi-layer perceptron (MLP) and multi-head self-attention networks as\nbaselines in a simulation environment. We also demonstrate the performance of\nthe model with and without auxiliary tasks. All models are evaluated based on\ndifferent metrics such as time to finish each lap, number of overtakes, and\nspeed difference with speed limit. The evaluation shows that the\nSwapTransformer model outperforms other models in different traffic densities\nin the inference phase.", "published": "2024-01-02", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "links": "http://arxiv.org/abs/2401.01425v1"}
{"title": "Quantifying the Uniqueness of Donald Trump in Presidential Discourse", "author": "Karen Zhou, Alexander A. Meitus, Milo Chase, Grace Wang, Anne Mykland, William Howell, Chenhao Tan", "abstract": "Does Donald Trump speak differently from other presidents? If so, in what\nways? Are these differences confined to any single medium of communication? To\ninvestigate these questions, this paper introduces a novel metric of uniqueness\nbased on large language models, develops a new lexicon for divisive speech, and\npresents a framework for comparing the lexical features of political opponents.\nApplying these tools to a variety of corpora of presidential speeches, we find\nconsiderable evidence that Trump's speech patterns diverge from those of all\nmajor party nominees for the presidency in recent history. Some notable\nfindings include Trump's employment of particularly divisive and antagonistic\nlanguage targeting of his political opponents and his patterns of repetition\nfor emphasis. Furthermore, Trump is significantly more distinctive than his\nfellow Republicans, whose uniqueness values are comparably closer to those of\nthe Democrats. These differences hold across a variety of measurement\nstrategies, arise on both the campaign trail and in official presidential\naddresses, and do not appear to be an artifact of secular time trends.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "links": "http://arxiv.org/abs/2401.01405v1"}
{"title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models", "author": "Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, Quanquan Gu", "abstract": "Harnessing the power of human-annotated data through Supervised Fine-Tuning\n(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we\ndelve into the prospect of growing a strong LLM out of a weak one without the\nneed for acquiring additional human-annotated data. We propose a new\nfine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a\nsupervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,\nwhere the LLM refines its capability by playing against instances of itself.\nMore specifically, the LLM generates its own training data from its previous\niterations, refining its policy by discerning these self-generated responses\nfrom those obtained from human-annotated data. Our method progressively\nelevates the LLM from a nascent model to a formidable one, unlocking the full\npotential of human-annotated demonstration data for SFT. Theoretically, we\nprove that the global optimum to the training objective function of our method\nis achieved only when the LLM policy aligns with the target data distribution.\nEmpirically, we evaluate our method on several benchmark datasets including the\nHuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our\nresults show that SPIN can significantly improve the LLM's performance across a\nvariety of benchmarks and even outperform models trained through direct\npreference optimization (DPO) supplemented with extra GPT-4 preference data.\nThis sheds light on the promise of self-play, enabling the achievement of\nhuman-level performance in LLMs without the need for expert opponents.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "links": "http://arxiv.org/abs/2401.01335v1"}
{"title": "TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview", "author": "Mohammad Aliannejadi, Zahra Abbasiantaeb, Shubham Chatterjee, Jeffery Dalton, Leif Azzopardi", "abstract": "Conversational Information Seeking stands as a pivotal research area with\nsignificant contributions from previous works. The TREC Interactive Knowledge\nAssistance Track (iKAT) builds on the foundational work of the TREC\nConversational Assistance Track (CAsT). However, iKAT distinctively emphasizes\nthe creation and research of conversational search agents that adapt responses\nbased on user's prior interactions and present context. The challenge lies in\nenabling Conversational Search Agents (CSA) to incorporate this personalized\ncontext to efficiency and effectively guide users through the relevant\ninformation to them. iKAT also emphasizes decisional search tasks, where users\nsift through data and information to weigh up options in order to reach a\nconclusion or perform an action. These tasks, prevalent in everyday\ninformation-seeking decisions -- be it related to travel, health, or shopping\n-- often revolve around a subset of high-level information operators where\nqueries or questions about the information space include: finding options,\ncomparing options, identifying the pros and cons of options, etc. Given the\ndifferent personas and their information need (expressed through the sequence\nof questions), diverse conversation trajectories will arise -- because the\nanswers to these similar queries will be very different. In this paper, we\nreport on the first year of TREC iKAT, describing the task, topics, data\ncollection, and evaluation framework. We further review the submissions and\nsummarize the findings.", "published": "2024-01-02", "categories": ["cs.IR", "cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01330v1"}
{"title": "An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction", "author": "Zaratiana Urchade, Nadi Tomeh, Pierre Holat, Thierry Charnois", "abstract": "In this paper, we propose a novel method for joint entity and relation\nextraction from unstructured text by framing it as a conditional sequence\ngeneration problem. In contrast to conventional generative information\nextraction models that are left-to-right token-level generators, our approach\nis \\textit{span-based}. It generates a linearized graph where nodes represent\ntext spans and edges represent relation triplets. Our method employs a\ntransformer encoder-decoder architecture with pointing mechanism on a dynamic\nvocabulary of spans and relation types. Our model can capture the structural\ncharacteristics and boundaries of entities and relations through span\nrepresentations while simultaneously grounding the generated output in the\noriginal text thanks to the pointing mechanism. Evaluation on benchmark\ndatasets validates the effectiveness of our approach, demonstrating competitive\nresults. Code is available at https://github.com/urchade/ATG.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01326v1"}
{"title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning", "author": "Hongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng Jiang, Zirui Liu, Chia-Yuan Chang, Huiyuan Chen, Xia Hu", "abstract": "This work elicits LLMs' inherent ability to handle long contexts without\nfine-tuning. The limited length of the training sequence during training may\nlimit the application of Large Language Models (LLMs) on long input sequences\nfor inference. In this work, we argue that existing LLMs themselves have\ninherent capabilities for handling long contexts. Based on this argument, we\nsuggest extending LLMs' context window by themselves to fully utilize the\ninherent ability.We propose Self-Extend to stimulate LLMs' long context\nhandling potential. The basic idea is to construct bi-level attention\ninformation: the group level and the neighbor level. The two levels are\ncomputed by the original model's self-attention, which means the proposed does\nnot require any training. With only four lines of code modification, the\nproposed method can effortlessly extend existing LLMs' context window without\nany fine-tuning. We conduct comprehensive experiments and the results show that\nthe proposed method can effectively extend existing LLMs' context window's\nlength.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01325v1"}
{"title": "Experimental Validation of Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles", "author": "Sagar Dasgupta, Kazi Hassan Shakib, Mizanur Rahman", "abstract": "In this paper, we validate the performance of the a sensor fusion-based\nGlobal Navigation Satellite System (GNSS) spoofing attack detection framework\nfor Autonomous Vehicles (AVs). To collect data, a vehicle equipped with a GNSS\nreceiver, along with Inertial Measurement Unit (IMU) is used. The detection\nframework incorporates two strategies: The first strategy involves comparing\nthe predicted location shift, which is the distance traveled between two\nconsecutive timestamps, with the inertial sensor-based location shift. For this\npurpose, data from low-cost in-vehicle inertial sensors such as the\naccelerometer and gyroscope sensor are fused and fed into a long short-term\nmemory (LSTM) neural network. The second strategy employs a Random-Forest\nsupervised machine learning model to detect and classify turns, distinguishing\nbetween left and right turns using the output from the steering angle sensor.\nIn experiments, two types of spoofing attack models: turn-by-turn and wrong\nturn are simulated. These spoofing attacks are modeled as SQL injection\nattacks, where, upon successful implementation, the navigation system perceives\ninjected spoofed location information as legitimate while being unable to\ndetect legitimate GNSS signals. Importantly, the IMU data remains uncompromised\nthroughout the spoofing attack. To test the effectiveness of the detection\nframework, experiments are conducted in Tuscaloosa, AL, mimicking urban road\nstructures. The results demonstrate the framework's ability to detect various\nsophisticated GNSS spoofing attacks, even including slow position drifting\nattacks. Overall, the experimental results showcase the robustness and efficacy\nof the sensor fusion-based spoofing attack detection approach in safeguarding\nAVs against GNSS spoofing threats.", "published": "2024-01-02", "categories": ["cs.CR", "cs.AI"], "links": "http://arxiv.org/abs/2401.01304v1"}
{"title": "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models", "author": "Matthew Dahl, Varun Magesh, Mirac Suzgun, Daniel E. Ho", "abstract": "Large language models (LLMs) have the potential to transform the practice of\nlaw, but this potential is threatened by the presence of legal hallucinations\n-- responses from these models that are not consistent with legal facts. We\ninvestigate the extent of these hallucinations using an original suite of legal\nqueries, comparing LLMs' responses to structured legal metadata and examining\ntheir consistency. Our work makes four key contributions: (1) We develop a\ntypology of legal hallucinations, providing a conceptual framework for future\nresearch in this area. (2) We find that legal hallucinations are alarmingly\nprevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with\nLlama 2, when these models are asked specific, verifiable questions about\nrandom federal court cases. (3) We illustrate that LLMs often fail to correct a\nuser's incorrect legal assumptions in a contra-factual question setup. (4) We\nprovide evidence that LLMs cannot always predict, or do not always know, when\nthey are producing legal hallucinations. Taken together, these findings caution\nagainst the rapid and unsupervised integration of popular LLMs into legal\ntasks. Even experienced lawyers must remain wary of legal hallucinations, and\nthe risks are highest for those who stand to benefit from LLMs the most -- pro\nse litigants or those without access to traditional legal resources.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CY"], "links": "http://arxiv.org/abs/2401.01301v1"}
{"title": "Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges", "author": "Ethan Zhu, Haijian Sun, Mingyue Ji", "abstract": "Channel modeling is fundamental in advancing wireless systems and has thus\nattracted considerable research focus. Recent trends have seen a growing\nreliance on data-driven techniques to facilitate the modeling process and yield\naccurate channel predictions. In this work, we first provide a concise overview\nof data-driven channel modeling methods, highlighting their limitations.\nSubsequently, we introduce the concept and advantages of physics-informed\nneural network (PINN)-based modeling and a summary of recent contributions in\nthis area. Our findings demonstrate that PINN-based approaches in channel\nmodeling exhibit promising attributes such as generalizability,\ninterpretability, and robustness. We offer a comprehensive architecture for\nPINN methodology, designed to inform and inspire future model development. A\ncase-study of our recent work on precise indoor channel prediction with\nsemantic segmentation and deep learning is presented. The study concludes by\naddressing the challenges faced and suggesting potential research directions in\nthis field.", "published": "2024-01-02", "categories": ["cs.IT", "cs.AI", "cs.CV", "math.IT"], "links": "http://arxiv.org/abs/2401.01288v1"}
{"title": "A Comprehensive Study of Knowledge Editing for Large Language Models", "author": "Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, Siyuan Cheng, Ziwen Xu, Xin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen", "abstract": "Large Language Models (LLMs) have shown extraordinary capabilities in\nunderstanding and generating text that closely mirrors human communication.\nHowever, a primary limitation lies in the significant computational demands\nduring training, arising from their extensive parameterization. This challenge\nis further intensified by the dynamic nature of the world, necessitating\nfrequent updates to LLMs to correct outdated information or integrate new\nknowledge, thereby ensuring their continued relevance. Note that many\napplications demand continual model adjustments post-training to address\ndeficiencies or undesirable behaviors. There is an increasing interest in\nefficient, lightweight methods for on-the-fly model modifications. To this end,\nrecent years have seen a burgeoning in the techniques of knowledge editing for\nLLMs, which aim to efficiently modify LLMs' behaviors within specific domains\nwhile preserving overall performance across various inputs. In this paper, we\nfirst define the knowledge editing problem and then provide a comprehensive\nreview of cutting-edge approaches. Drawing inspiration from educational and\ncognitive research theories, we propose a unified categorization criterion that\nclassifies knowledge editing methods into three groups: resorting to external\nknowledge, merging knowledge into the model, and editing intrinsic knowledge.\nFurthermore, we introduce a new benchmark, KnowEdit, for a comprehensive\nempirical evaluation of representative knowledge editing approaches.\nAdditionally, we provide an in-depth analysis of knowledge location, which can\nprovide a deeper understanding of the knowledge structures inherent within\nLLMs. Finally, we discuss several potential applications of knowledge editing,\noutlining its broad and impactful implications.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "links": "http://arxiv.org/abs/2401.01286v1"}
{"title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection", "author": "Noble Saji Mathews, Yelizaveta Brus, Yousra Aafer, Mei Nagappan, Shane McIntosh", "abstract": "Despite the continued research and progress in building secure systems,\nAndroid applications continue to be ridden with vulnerabilities, necessitating\neffective detection methods. Current strategies involving static and dynamic\nanalysis tools come with limitations like overwhelming number of false\npositives and limited scope of analysis which make either difficult to adopt.\nOver the past years, machine learning based approaches have been extensively\nexplored for vulnerability detection, but its real-world applicability is\nconstrained by data requirements and feature engineering challenges. Large\nLanguage Models (LLMs), with their vast parameters, have shown tremendous\npotential in understanding semnatics in human as well as programming languages.\nWe dive into the efficacy of LLMs for detecting vulnerabilities in the context\nof Android security. We focus on building an AI-driven workflow to assist\ndevelopers in identifying and rectifying vulnerabilities. Our experiments show\nthat LLMs outperform our expectations in finding issues within applications\ncorrectly flagging insecure apps in 91.67% of cases in the Ghera benchmark. We\nuse inferences from our experiments towards building a robust and actionable\nvulnerability detection system and demonstrate its effectiveness. Our\nexperiments also shed light on how different various simple configurations can\naffect the True Positive (TP) and False Positive (FP) rates.", "published": "2024-01-02", "categories": ["cs.CR", "cs.AI", "cs.SE"], "links": "http://arxiv.org/abs/2401.01269v1"}
{"title": "Optimal Synthesis of Finite State Machines with Universal Gates using Evolutionary Algorithm", "author": "Noor Ullah, Khawaja M. Yahya, Irfan Ahmed", "abstract": "This work presents an optimization method for the synthesis of finite state\nmachines. The focus is on the reduction in the on-chip area and the cost of the\ncircuit. A list of finite state machines from MCNC91 benchmark circuits have\nbeen evolved using Cartesian Genetic Programming. On the average, almost 30% of\nreduction in the total number of gates has been achieved. The effects of some\nparameters on the evolutionary process have also been discussed in the paper.", "published": "2024-01-02", "categories": ["cs.NE", "cs.AI"], "links": "http://arxiv.org/abs/2401.01265v1"}
{"title": "Fairness Certification for Natural Language Processing and Large Language Models", "author": "Vincent Freiberger, Erik Buchmann", "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives,\nparticularly due to the enormous progress of Large Language Models (LLM).\nHowever, NLP has many fairness-critical use cases, e.g., as an expert system in\nrecruitment or as an LLM-based tutor in education. Since NLP is based on human\nlanguage, potentially harmful biases can diffuse into NLP systems and produce\nunfair results, discriminate against minorities or generate legal issues.\nHence, it is important to develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certification for\nNLP. In particular, we have reviewed a large body of literature on algorithmic\nfairness, and we have conducted semi-structured expert interviews with a wide\nrange of experts from that area. We have systematically devised six fairness\ncriteria for NLP, which can be further refined into 18 sub-categories. Our\ncriteria offer a foundation for operationalizing and testing processes to\ncertify fairness, both from the perspective of the auditor and the audited\norganization.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "68T50", "I.2.7"], "links": "http://arxiv.org/abs/2401.01262v2"}
{"title": "Do Concept Bottleneck Models Obey Locality?", "author": "Naveen Raman, Mateo Espinosa Zarlenga, Juyeon Heo, Mateja Jamnik", "abstract": "Concept-based learning improves a deep learning model's interpretability by\nexplaining its predictions via human-understandable concepts. Deep learning\nmodels trained under this paradigm heavily rely on the assumption that neural\nnetworks can learn to predict the presence or absence of a given concept\nindependently of other concepts. Recent work, however, strongly suggests that\nthis assumption may fail to hold in Concept Bottleneck Models (CBMs), a\nquintessential family of concept-based interpretable architectures. In this\npaper, we investigate whether CBMs correctly capture the degree of conditional\nindependence across concepts when such concepts are localised both spatially,\nby having their values entirely defined by a fixed subset of features, and\nsemantically, by having their values correlated with only a fixed subset of\npredefined concepts. To understand locality, we analyse how changes to features\noutside of a concept's spatial or semantic locality impact concept predictions.\nOur results suggest that even in well-defined scenarios where the presence of a\nconcept is localised to a fixed feature subspace, or whose semantics are\ncorrelated to a small subset of other concepts, CBMs fail to learn this\nlocality. These results cast doubt upon the quality of concept representations\nlearnt by CBMs and strongly suggest that concept-based explanations may be\nfragile to changes outside their localities.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01259v1"}
{"title": "Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning", "author": "Tobias Engelhardt Rasmussen, Siv Sørensen", "abstract": "Broadband infrastructure owners do not always know how their customers are\nconnected in the local networks, which are structured as rooted trees. A recent\nstudy is able to infer the topology of a local network using discrete time\nseries data from the leaves of the tree (customers). In this study we propose a\ncontrastive approach for learning a binary event encoder from continuous time\nseries data. As a preliminary result, we show that our approach has some\npotential in learning a valuable encoder.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.SI", "stat.ML"], "links": "http://arxiv.org/abs/2401.01242v1"}
{"title": "IdentiFace : A VGG Based Multimodal Facial Biometric System", "author": "Mahmoud Rabea, Hanya Ahmed, Sohaila Mahmoud, Nourhan Sayed", "abstract": "The development of facial biometric systems has contributed greatly to the\ndevelopment of the computer vision field. Nowadays, there's always a need to\ndevelop a multimodal system that combines multiple biometric traits in an\nefficient, meaningful way. In this paper, we introduce \"IdentiFace\" which is a\nmultimodal facial biometric system that combines the core of facial recognition\nwith some of the most important soft biometric traits such as gender, face\nshape, and emotion. We also focused on developing the system using only VGG-16\ninspired architecture with minor changes across different subsystems. This\nunification allows for simpler integration across modalities. It makes it\neasier to interpret the learned features between the tasks which gives a good\nindication about the decision-making process across the facial modalities and\npotential connection. For the recognition problem, we acquired a 99.2% test\naccuracy for five classes with high intra-class variations using data collected\nfrom the FERET database[1]. We achieved 99.4% on our dataset and 95.15% on the\npublic dataset[2] in the gender recognition problem. We were also able to\nachieve a testing accuracy of 88.03% in the face-shape problem using the\ncelebrity face-shape dataset[3]. Finally, we achieved a decent testing accuracy\nof 66.13% in the emotion task which is considered a very acceptable accuracy\ncompared to related work on the FER2013 dataset[4].", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI"], "links": "http://arxiv.org/abs/2401.01227v1"}
{"title": "Zero-Shot Position Debiasing for Large Language Models", "author": "Zhongkun Liu, Zheng Chen, Mengqi Zhang, Zhaochun Ren, Zhumin Chen, Pengjie Ren", "abstract": "Fine-tuning has been demonstrated to be an effective method to improve the\ndomain performance of large language models (LLMs). However, LLMs might fit the\ndataset bias and shortcuts for prediction, leading to poor generation\nperformance. Experimental result shows that LLMs are prone to exhibit position\nbias, i.e., leveraging information positioned at the beginning or end, or\nspecific positional cues within the input. Existing works on mitigating\nposition bias require external bias knowledge or annotated non-biased samples,\nwhich is unpractical in reality. In this work, we propose a zero-shot position\ndebiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages\nunsupervised responses from pre-trained LLMs for debiasing, thus without any\nexternal knowledge or datasets. To improve the quality of unsupervised\nresponses, we propose a master-slave alignment (MSA) module to prune these\nresponses. Experiments on eight datasets and five tasks show that ZOE\nconsistently outperforms existing methods in mitigating four types of position\nbiases. Besides, ZOE achieves this by sacrificing only a small performance on\nbiased samples, which is simple and effective.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "links": "http://arxiv.org/abs/2401.01218v1"}
{"title": "PPBFL: A Privacy Protected Blockchain-based Federated Learning Model", "author": "Yang Li, Chunhe Xia, Wanshuang Lin, Tianbo Wang", "abstract": "With the rapid development of machine learning and growing concerns about\ndata privacy, federated learning has become an increasingly prominent focus.\nHowever, challenges such as attacks on model parameters and the lack of\nincentive mechanisms hinder the effectiveness of federated learning. Therefore,\nwe propose a Privacy Protected Blockchain-based Federated Learning Model\n(PPBFL) to enhance the security of federated learning and promote the active\nparticipation of nodes in model training. Blockchain ensures that model\nparameters stored in the InterPlanetary File System (IPFS) remain unaltered. A\nnovel adaptive differential privacy addition algorithm is simultaneously\napplied to local and global models, preserving the privacy of local models and\npreventing a decrease in the security of the global model due to the presence\nof numerous local models in federated learning. Additionally, we introduce a\nnew mix transactions mechanism to better protect the identity privacy of local\ntraining clients. Security analysis and experimental results demonstrate that\nPPBFL outperforms baseline methods in both model performance and security.", "published": "2024-01-02", "categories": ["cs.CR", "cs.AI"], "links": "http://arxiv.org/abs/2401.01204v1"}
{"title": "Skin cancer diagnosis using NIR spectroscopy data of skin lesions in vivo using machine learning algorithms", "author": "Flavio P. Loss, Pedro H. da Cunha, Matheus B. Rocha, Madson Poltronieri Zanoni, Leandro M. de Lima, Isadora Tavares Nascimento, Isabella Rezende, Tania R. P. Canuto, Luciana de Paula Vieira, Renan Rossoni, Maria C. S. Santos, Patricia Lyra Frasson, Wanderson Romão, Paulo R. Filgueiras, Renato A. Krohling", "abstract": "Skin lesions are classified in benign or malignant. Among the malignant,\nmelanoma is a very aggressive cancer and the major cause of deaths. So, early\ndiagnosis of skin cancer is very desired. In the last few years, there is a\ngrowing interest in computer aided diagnostic (CAD) using most image and\nclinical data of the lesion. These sources of information present limitations\ndue to their inability to provide information of the molecular structure of the\nlesion. NIR spectroscopy may provide an alternative source of information to\nautomated CAD of skin lesions. The most commonly used techniques and\nclassification algorithms used in spectroscopy are Principal Component Analysis\n(PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support\nVector Machines (SVM). Nonetheless, there is a growing interest in applying the\nmodern techniques of machine and deep learning (MDL) to spectroscopy. One of\nthe main limitations to apply MDL to spectroscopy is the lack of public\ndatasets. Since there is no public dataset of NIR spectral data to skin\nlesions, as far as we know, an effort has been made and a new dataset named\nNIR-SC-UFES, has been collected, annotated and analyzed generating the\ngold-standard for classification of NIR spectral data to skin cancer. Next, the\nmachine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutional\nneural network (1D-CNN) were investigated to classify cancer and non-cancer\nskin lesions. Experimental results indicate the best performance obtained by\nLightGBM with pre-processing using standard normal variate (SNV), feature\nextraction providing values of 0.839 for balanced accuracy, 0.851 for recall,\n0.852 for precision, and 0.850 for F-score. The obtained results indicate the\nfirst steps in CAD of skin lesions aiming the automated triage of patients with\nskin lesions in vivo using NIR spectral data.", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI"], "links": "http://arxiv.org/abs/2401.01200v1"}
{"title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example", "author": "Benedetta Tondi, Wei Guo, Mauro Barni", "abstract": "Most of the approaches proposed so far to craft targeted adversarial examples\nagainst Deep Learning classifiers are highly suboptimal and typically rely on\nincreasing the likelihood of the target class, thus implicitly focusing on\none-hot encoding settings. In this paper, we propose a more general,\ntheoretically sound, targeted attack that resorts to the minimization of a\nJacobian-induced MAhalanobis distance (JMA) term, taking into account the\neffort (in the input space) required to move the latent space representation of\nthe input sample in a given direction. The minimization is solved by exploiting\nthe Wolfe duality theorem, reducing the problem to the solution of a\nNon-Negative Least Square (NNLS) problem. The proposed algorithm provides an\noptimal solution to a linearized version of the adversarial example problem\noriginally introduced by Szegedy et al. \\cite{szegedy2013intriguing}. The\nexperiments we carried out confirm the generality of the proposed attack which\nis proven to be effective under a wide variety of output encoding schemes.\nNoticeably, the JMA attack is also effective in a multi-label classification\nscenario, being capable to induce a targeted modification of up to half the\nlabels in a complex multilabel classification scenario with 20 labels, a\ncapability that is out of reach of all the attacks proposed so far. As a\nfurther advantage, the JMA attack usually requires very few iterations, thus\nresulting more efficient than existing methods.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.CV"], "links": "http://arxiv.org/abs/2401.01199v1"}
{"title": "Uncertainty Resolution in Misinformation Detection", "author": "Yury Orlovskiy, Camille Thibault, Anne Imouza, Jean-François Godbout, Reihaneh Rabbany, Kellin Pelrine", "abstract": "Misinformation poses a variety of risks, such as undermining public trust and\ndistorting factual discourse. Large Language Models (LLMs) like GPT-4 have been\nshown effective in mitigating misinformation, particularly in handling\nstatements where enough context is provided. However, they struggle to assess\nambiguous or context-deficient statements accurately. This work introduces a\nnew method to resolve uncertainty in such statements. We propose a framework to\ncategorize missing information and publish category labels for the LIAR-New\ndataset, which is adaptable to cross-domain content with missing information.\nWe then leverage this framework to generate effective user queries for missing\ncontext. Compared to baselines, our method improves the rate at which generated\nquestions are answerable by the user by 38 percentage points and classification\nperformance by over 10 percentage points macro F1. Thus, this approach may\nprovide a valuable component for future misinformation mitigation pipelines.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01197v1"}
{"title": "NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments", "author": "Ziheng Xu, Jianwei Niu, Qingfeng Li, Tao Ren, Chen Chen", "abstract": "Neural implicit representations have been explored to enhance visual SLAM\nalgorithms, especially in providing high-fidelity dense map. Existing methods\noperate robustly in static scenes but struggle with the disruption caused by\nmoving objects. In this paper we present NID-SLAM, which significantly improves\nthe performance of neural SLAM in dynamic environments. We propose a new\napproach to enhance inaccurate regions in semantic masks, particularly in\nmarginal areas. Utilizing the geometric information present in depth images,\nthis method enables accurate removal of dynamic objects, thereby reducing the\nprobability of camera drift. Additionally, we introduce a keyframe selection\nstrategy for dynamic scenes, which enhances camera tracking robustness against\nlarge-scale objects and improves the efficiency of mapping. Experiments on\npublicly available RGB-D datasets demonstrate that our method outperforms\ncompetitive neural SLAM approaches in tracking accuracy and mapping quality in\ndynamic environments.", "published": "2024-01-02", "categories": ["cs.RO", "cs.AI"], "links": "http://arxiv.org/abs/2401.01189v1"}
{"title": "Unifying Structured Data as Graph for Data-to-Text Pre-Training", "author": "Shujie Li, Liang Li, Ruiying Geng, Min Yang, Binhua Li, Guanghu Yuan, Wanwei He, Shao Yuan, Can Ma, Fei Huang, Yongbin Li", "abstract": "Data-to-text (D2T) generation aims to transform structured data into natural\nlanguage text. Data-to-text pre-training has proved to be powerful in enhancing\nD2T generation and yields impressive performances. However, previous\npre-training methods either oversimplified structured data into a sequence\nwithout considering input structures or designed training objectives tailored\nfor a specific data structure (e.g., table or knowledge graph). In this paper,\nwe unify different types of structured data (i.e., table, key-value data,\nknowledge graph) into the graph format and cast different data-to-text\ngeneration tasks as graph-to-text generation. To effectively exploit the\nstructural information of the input graph, we propose a structure-enhanced\npre-training method for D2T generation by designing a structure-enhanced\nTransformer. Concretely, we devise a position matrix for the Transformer,\nencoding relative positional information of connected nodes in the input graph.\nIn addition, we propose a new attention matrix to incorporate graph structures\ninto the original Transformer by taking the available explicit connectivity\nstructure into account. Extensive experiments on six benchmark datasets show\nthe effectiveness of our model. Our source codes are available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01183v1"}
{"title": "Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery", "author": "Asim Khan, Umair Nawaz, Anwaar Ulhaq, Iqbal Gondal, Sajid Javed", "abstract": "Deforestation, a major contributor to climate change, poses detrimental\nconsequences such as agricultural sector disruption, global warming, flash\nfloods, and landslides. Conventional approaches to urban street tree inventory\nsuffer from inaccuracies and necessitate specialised equipment. To overcome\nthese challenges, this paper proposes an innovative method that leverages deep\nlearning techniques and mobile phone imaging for urban street tree inventory.\nOur approach utilises a pair of images captured by smartphone cameras to\naccurately segment tree trunks and compute the diameter at breast height (DBH).\nCompared to traditional methods, our approach exhibits several advantages,\nincluding superior accuracy, reduced dependency on specialised equipment, and\napplicability in hard-to-reach areas. We evaluated our method on a\ncomprehensive dataset of 400 trees and achieved a DBH estimation accuracy with\nan error rate of less than 2.5%. Our method holds significant potential for\nsubstantially improving forest management practices. By enhancing the accuracy\nand efficiency of tree inventory, our model empowers urban management to\nmitigate the adverse effects of deforestation and climate change.", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI", "eess.IV"], "links": "http://arxiv.org/abs/2401.01180v1"}
{"title": "Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training", "author": "Jiuming Qin, Che Liu, Sibo Cheng, Yike Guo, Rossella Arcucci", "abstract": "Modern healthcare often utilises radiographic images alongside textual\nreports for diagnostics, encouraging the use of Vision-Language Self-Supervised\nLearning (VL-SSL) with large pre-trained models to learn versatile medical\nvision representations. However, most existing VL-SSL frameworks are trained\nend-to-end, which is computation-heavy and can lose vital prior information\nembedded in pre-trained encoders. To address both issues, we introduce the\nbackbone-agnostic Adaptor framework, which preserves medical knowledge in\npre-trained image and text encoders by keeping them frozen, and employs a\nlightweight Adaptor module for cross-modal learning. Experiments on medical\nimage classification and segmentation tasks across three datasets reveal that\nour framework delivers competitive performance while cutting trainable\nparameters by over 90% compared to current pre-training approaches. Notably,\nwhen fine-tuned with just 1% of data, Adaptor outperforms several\nTransformer-based methods trained on full datasets in medical image\nsegmentation.", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01179v1"}
{"title": "Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults", "author": "Mohammad Al-Sa'd, Tuomas Jalonen, Serkan Kiranyaz, Moncef Gabbouj", "abstract": "Diagnosis of bearing faults is paramount to reducing maintenance costs and\noperational breakdowns. Bearing faults are primary contributors to machine\nvibrations, and analyzing their signal morphology offers insights into their\nhealth status. Unfortunately, existing approaches are optimized for controlled\nenvironments, neglecting realistic conditions such as time-varying rotational\nspeeds and the vibration's non-stationary nature. This paper presents a fusion\nof time-frequency analysis and deep learning techniques to diagnose bearing\nfaults under time-varying speeds and varying noise levels. First, we formulate\nthe bearing fault-induced vibrations and discuss the link between their\nnon-stationarity and the bearing's inherent and operational parameters. We also\nelucidate quadratic time-frequency distributions and validate their\neffectiveness in resolving distinctive dynamic patterns associated with\ndifferent bearing faults. Based on this, we design a time-frequency\nconvolutional neural network (TF-CNN) to diagnose various faults in\nrolling-element bearings. Our experimental findings undeniably demonstrate the\nsuperior performance of TF-CNN in comparison to recently developed techniques.\nThey also assert its versatility in capturing fault-relevant non-stationary\nfeatures that couple with speed changes and show its exceptional resilience to\nnoise, consistently surpassing competing methods across various signal-to-noise\nratios and performance metrics. Altogether, the TF-CNN achieves substantial\naccuracy improvements up to 15%, in severe noise conditions.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "links": "http://arxiv.org/abs/2401.01172v1"}
{"title": "Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge", "author": "Alessio Carpegna, Alessandro Savino, Stefano Di Carlo", "abstract": "Including Artificial Neural Networks in embedded systems at the edge allows\napplications to exploit Artificial Intelligence capabilities directly within\ndevices operating at the network periphery. This paper introduces Spiker+, a\ncomprehensive framework for generating efficient, low-power, and low-area\ncustomized Spiking Neural Networks (SNN) accelerators on FPGA for inference at\nthe edge. Spiker+ presents a configurable multi-layer hardware SNN, a library\nof highly efficient neuron architectures, and a design framework, enabling the\ndevelopment of complex neural network accelerators with few lines of Python\ncode. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking\nHeidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance\ncompared to state-of-the-art SNN accelerators. It outperforms them in terms of\nresource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs\n(BRAMs), which makes it fit in very small FPGA, and power consumption, draining\nonly 180mW for a complete inference on an input image. The latency is\ncomparable to the ones observed in the state-of-the-art, with 780us/img. To the\nauthors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD. In\nthis case, the accelerator requires 18,268 logic cells and 51 BRAM, with an\noverall power consumption of 430mW and a latency of 54 us for a complete\ninference on input data. This underscores the significance of Spiker+ in the\nhardware-accelerated SNN landscape, making it an excellent solution to deploy\nconfigurable and tunable SNN architectures in resource and power-constrained\nedge applications.", "published": "2024-01-02", "categories": ["cs.NE", "cs.AI", "cs.AR"], "links": "http://arxiv.org/abs/2401.01141v1"}
{"title": "Explainable Adaptive Tree-based Model Selection for Time Series Forecasting", "author": "Matthias Jakobs, Amal Saadallah", "abstract": "Tree-based models have been successfully applied to a wide variety of tasks,\nincluding time series forecasting. They are increasingly in demand and widely\naccepted because of their comparatively high level of interpretability.\nHowever, many of them suffer from the overfitting problem, which limits their\napplication in real-world decision-making. This problem becomes even more\nsevere in online-forecasting settings where time series observations are\nincrementally acquired, and the distributions from which they are drawn may\nkeep changing over time. In this context, we propose a novel method for the\nonline selection of tree-based models using the TreeSHAP explainability method\nin the task of time series forecasting. We start with an arbitrary set of\ndifferent tree-based models. Then, we outline a performance-based ranking with\na coherent design to make TreeSHAP able to specialize the tree-based\nforecasters across different regions in the input time series. In this\nframework, adequate model selection is performed online, adaptively following\ndrift detection in the time series. In addition, explainability is supported on\nthree levels, namely online input importance, model selection, and model output\nexplanation. An extensive empirical study on various real-world datasets\ndemonstrates that our method achieves excellent or on-par results in comparison\nto the state-of-the-art approaches as well as several baselines.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01124v1"}
{"title": "Utilizing Autoregressive Networks for Full Lifecycle Data Generation of Rolling Bearings for RUL Prediction", "author": "Junliang Wang, Qinghua Zhang, Guanhua Zhu, Guoxi Sun", "abstract": "The prediction of rolling bearing lifespan is of significant importance in\nindustrial production. However, the scarcity of high-quality, full lifecycle\ndata has been a major constraint in achieving precise predictions. To address\nthis challenge, this paper introduces the CVGAN model, a novel framework\ncapable of generating one-dimensional vibration signals in both horizontal and\nvertical directions, conditioned on historical vibration data and remaining\nuseful life. In addition, we propose an autoregressive generation method that\ncan iteratively utilize previously generated vibration information to guide the\ngeneration of current signals. The effectiveness of the CVGAN model is\nvalidated through experiments conducted on the PHM 2012 dataset. Our findings\ndemonstrate that the CVGAN model, in terms of both MMD and FID metrics,\noutperforms many advanced methods in both autoregressive and non-autoregressive\ngeneration modes. Notably, training using the full lifecycle data generated by\nthe CVGAN model significantly improves the performance of the predictive model.\nThis result highlights the effectiveness of the data generated by CVGans in\nenhancing the predictive power of these models.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01119v1"}
{"title": "AI-FLARES: Artificial Intelligence for the Analysis of Solar Flares Data", "author": "Michele Piana, Federico Benvenuto, Anna Maria Massone, Cristina Campi, Sabrina Guastavino, Francesco Marchetti, Paolo Massa, Emma Perracchione, Anna Volpara", "abstract": "AI-FLARES (Artificial Intelligence for the Analysis of Solar Flares Data) is\na research project funded by the Agenzia Spaziale Italiana and by the Istituto\nNazionale di Astrofisica within the framework of the ``Attivit\\`a di Studio per\nla Comunit\\`a Scientifica Nazionale Sole, Sistema Solare ed Esopianeti''\nprogram. The topic addressed by this project was the development and use of\ncomputational methods for the analysis of remote sensing space data associated\nto solar flare emission. This paper overviews the main results obtained by the\nproject, with specific focus on solar flare forecasting, reconstruction of\nmorphologies of the flaring sources, and interpretation of acceleration\nmechanisms triggered by solar flares.", "published": "2024-01-02", "categories": ["astro-ph.SR", "cs.AI", "85-04, 68T01"], "links": "http://arxiv.org/abs/2401.01104v1"}
{"title": "Efficient Parallel Audio Generation using Group Masked Language Modeling", "author": "Myeonghun Jeong, Minchan Kim, Joun Yeop Lee, Nam Soo Kim", "abstract": "We present a fast and high-quality codec language model for parallel audio\ngeneration. While SoundStorm, a state-of-the-art parallel audio generation\nmodel, accelerates inference speed compared to autoregressive models, it still\nsuffers from slow inference due to iterative sampling. To resolve this problem,\nwe propose Group-Masked Language Modeling~(G-MLM) and Group Iterative Parallel\nDecoding~(G-IPD) for efficient parallel audio generation. Both the training and\nsampling schemes enable the model to synthesize high-quality audio with a small\nnumber of iterations by effectively modeling the group-wise conditional\ndependencies. In addition, our model employs a cross-attention-based\narchitecture to capture the speaker style of the prompt voice and improves\ncomputational efficiency. Experimental results demonstrate that our proposed\nmodel outperforms the baselines in prompt-based audio generation.", "published": "2024-01-02", "categories": ["eess.AS", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01099v1"}
{"title": "Quokka: An Open-source Large Language Model ChatBot for Material Science", "author": "Xianjun Yang, Stephen D. Wilson, Linda Petzold", "abstract": "This paper presents the development of a specialized chatbot for materials\nscience, leveraging the Llama-2 language model, and continuing pre-training on\nthe expansive research articles in the materials science domain from the S2ORC\ndataset. The methodology involves an initial pretraining phase on over one\nmillion domain-specific papers, followed by an instruction-tuning process to\nrefine the chatbot's capabilities. The chatbot is designed to assist\nresearchers, educators, and students by providing instant, context-aware\nresponses to queries in the field of materials science. We make the four\ntrained checkpoints (7B, 13B, with or without chat ability) freely available to\nthe research community at https://github.com/Xianjun-Yang/Quokka.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CE"], "links": "http://arxiv.org/abs/2401.01089v1"}
{"title": "Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation", "author": "Triet Minh Huynh, Quan Le Bao", "abstract": "Poetry generation has been a challenging task in the field of Natural\nLanguage Processing, as it requires the model to understand the nuances of\nlanguage, sentiment, and style. In this paper, we propose using Large Language\nModels to generate Vietnamese poems of various genres from natural language\nprompts, thereby facilitating an intuitive process with enhanced content\ncontrol. Our most efficacious model, the GPT-3 Babbage variant, achieves a\ncustom evaluation score of 0.8, specifically tailored to the \"luc bat\" genre of\nVietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems\ninto normal text prompts and yield a relatively high score of 0.781 in the \"luc\nbat\" genre. This experiment presents the potential for cross-Language\npoem-to-poem translation with translated poems as the inputs while concurrently\nmaintaining complete control over the generated content.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01078v3"}
{"title": "Discovering Significant Topics from Legal Decisions with Selective Inference", "author": "Jerrold Soh", "abstract": "We propose and evaluate an automated pipeline for discovering significant\ntopics from legal decision texts by passing features synthesized with topic\nmodels through penalised regressions and post-selection significance tests. The\nmethod identifies case topics significantly correlated with outcomes,\ntopic-word distributions which can be manually-interpreted to gain insights\nabout significant topics, and case-topic weights which can be used to identify\nrepresentative cases for each topic. We demonstrate the method on a new dataset\nof domain name disputes and a canonical dataset of European Court of Human\nRights violation cases. Topic models based on latent semantic analysis as well\nas language model embeddings are evaluated. We show that topics derived by the\npipeline are consistent with legal doctrines in both areas and can be useful in\nother related legal analysis tasks.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01068v1"}
{"title": "BEV-CLIP: Multi-modal BEV Retrieval Methodology for Complex Scene in Autonomous Driving", "author": "Dafeng Wei, Tian Gao, Zhengyu Jia, Changwei Cai, Chengkai Hou, Peng Jia, Fu Liu, Kun Zhan, Jingchen Fan, Yixing Zhao, Yang Wang", "abstract": "The demand for the retrieval of complex scene data in autonomous driving is\nincreasing, especially as passenger vehicles have been equipped with the\nability to navigate urban settings, with the imperative to address long-tail\nscenarios. Meanwhile, under the pre-existing two dimensional image retrieval\nmethod, some problems may arise with scene retrieval, such as lack of global\nfeature representation and subpar text retrieval ability. To address these\nissues, we have proposed \\textbf{BEV-CLIP}, the first multimodal Bird's-Eye\nView(BEV) retrieval methodology that utilizes descriptive text as an input to\nretrieve corresponding scenes. This methodology applies the semantic feature\nextraction abilities of a large language model (LLM) to facilitate zero-shot\nretrieval of extensive text descriptions, and incorporates semi-structured\ninformation from a knowledge graph to improve the semantic richness and variety\nof the language embedding. Our experiments result in 87.66% accuracy on\nNuScenes dataset in text-to-BEV feature retrieval. The demonstrated cases in\nour paper support that our retrieval method is also indicated to be effective\nin identifying certain long-tail corner scenes.", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI", "I.2.10"], "links": "http://arxiv.org/abs/2401.01065v1"}
{"title": "Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction", "author": "Yunpeng Qu, Zhilin Lu, Rui Zeng, Jintao Wang, Jian Wang", "abstract": "Automatic Modulation Recognition (AMR) plays a crucial role in wireless\ncommunication systems. Deep learning AMR strategies have achieved tremendous\nsuccess in recent years. Modulated signals exhibit long temporal dependencies,\nand extracting global features is crucial in identifying modulation schemes.\nTraditionally, human experts analyze patterns in constellation diagrams to\nclassify modulation schemes. Classical convolutional-based networks, due to\ntheir limited receptive fields, excel at extracting local features but struggle\nto capture global relationships. To address this limitation, we introduce a\nnovel hybrid deep framework named TLDNN, which incorporates the architectures\nof the transformer and long short-term memory (LSTM). We utilize the\nself-attention mechanism of the transformer to model the global correlations in\nsignal sequences while employing LSTM to enhance the capture of temporal\ndependencies. To mitigate the impact like RF fingerprint features and channel\ncharacteristics on model generalization, we propose data augmentation\nstrategies known as segment substitution (SS) to enhance the model's robustness\nto modulation-related features. Experimental results on widely-used datasets\ndemonstrate that our method achieves state-of-the-art performance and exhibits\nsignificant advantages in terms of complexity. Our proposed framework serves as\na foundational backbone that can be extended to different datasets. We have\nverified the effectiveness of our augmentation approach in enhancing the\ngeneralization of the models, particularly in few-shot scenarios. Code is\navailable at \\url{https://github.com/AMR-Master/TLDNN}.", "published": "2024-01-02", "categories": ["eess.SP", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01056v1"}
{"title": "LLaMA Beyond English: An Empirical Study on Language Capability Transfer", "author": "Jun Zhao, Zhihao Zhang, Qi Zhang, Tao Gui, Xuanjing Huang", "abstract": "In recent times, substantial advancements have been witnessed in large\nlanguage models (LLMs), exemplified by ChatGPT, showcasing remarkable\nproficiency across a range of complex tasks. However, many mainstream LLMs\n(e.g. LLaMA) are pretrained on English-dominant corpus, which limits their\nperformance in other non-English languages. In this paper, we focus on how to\neffectively transfer the capabilities of language generation and following\ninstructions to a non-English language. To answer this question, we conduct an\nextensive empirical investigation based on LLaMA, accumulating over 1440 GPU\nhours. We analyze the impact of key factors such as vocabulary extension,\nfurther pretraining, and instruction tuning on transfer. To accurately assess\nthe model's level of knowledge, we employ four widely used standardized testing\nbenchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a\ncomprehensive evaluation of the model's response quality is conducted,\nconsidering aspects such as accuracy, fluency, informativeness, logical\ncoherence, and harmlessness, based on LLM-Eval, a benchmarks consisting\ninstruction tasks from 17 diverse categories. Our evaluation results\ndemonstrate that comparable performance to state-of-the-art transfer models can\nbe achieved with less than 1% of the pretraining data, both in terms of\nknowledge alignment and response quality. Furthermore, the experimental\noutcomes across the thirteen low-resource languages also exhibit similar\ntrends. We anticipate that the conclusions revealed by the experiments will aid\nthe community in developing non-English LLMs.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01055v1"}
{"title": "Elastic Multi-Gradient Descent for Parallel Continual Learning", "author": "Fan Lyu, Wei Feng, Yuepan Li, Qing Sun, Fanhua Shang, Liang Wan, Liang Wang", "abstract": "The goal of Continual Learning (CL) is to continuously learn from new data\nstreams and accomplish the corresponding tasks. Previously studied CL assumes\nthat data are given in sequence nose-to-tail for different tasks, thus indeed\nbelonging to Serial Continual Learning (SCL). This paper studies the novel\nparadigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios,\nwhere a diverse set of tasks is encountered at different time points. PCL\npresents challenges due to the training of an unspecified number of tasks with\nvarying learning progress, leading to the difficulty of guaranteeing effective\nmodel updates for all encountered tasks. In our previous conference work, we\nfocused on measuring and reducing the discrepancy among gradients in a\nmulti-objective optimization problem, which, however, may still contain\nnegative transfers in every model update. To address this issue, in the dynamic\nmulti-objective optimization problem, we introduce task-specific elastic\nfactors to adjust the descent direction towards the Pareto front. The proposed\nmethod, called Elastic Multi-Gradient Descent (EMGD), ensures that each update\nfollows an appropriate Pareto descent direction, minimizing any negative impact\non previously learned tasks. To balance the training between old and new tasks,\nwe also propose a memory editing mechanism guided by the gradient computed\nusing EMGD. This editing process updates the stored data points, reducing\ninterference in the Pareto descent direction from previous tasks. Experiments\non public datasets validate the effectiveness of our EMGD in the PCL setting.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01054v1"}
{"title": "Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation", "author": "Jinlong Xue, Yayue Deng, Yingming Gao, Ya Li", "abstract": "Recent advancements in diffusion models and large language models (LLMs) have\nsignificantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning\nAIGC application designed to generate audio from natural language prompts, is\nattracting increasing attention. However, existing TTA studies often struggle\nwith generation quality and text-audio alignment, especially for complex\ntextual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I)\ndiffusion models, we introduce Auffusion, a TTA system adapting T2I model\nframeworks to TTA task, by effectively leveraging their inherent generative\nstrengths and precise cross-modal alignment. Our objective and subjective\nevaluations demonstrate that Auffusion surpasses previous TTA approaches using\nlimited data and computational resource. Furthermore, previous studies in T2I\nrecognizes the significant impact of encoder choice on cross-modal alignment,\nlike fine-grained details and object bindings, while similar evaluation is\nlacking in prior TTA works. Through comprehensive ablation studies and\ninnovative cross-attention map visualizations, we provide insightful\nassessments of text-audio alignment in TTA. Our findings reveal Auffusion's\nsuperior capability in generating audios that accurately match textual\ndescriptions, which further demonstrated in several related tasks, such as\naudio style transfer, inpainting and other manipulations. Our implementation\nand demos are available at https://auffusion.github.io.", "published": "2024-01-02", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "links": "http://arxiv.org/abs/2401.01044v1"}
{"title": "Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI", "author": "Zishen Wan, Che-Kai Liu, Hanchen Yang, Chaojian Li, Haoran You, Yonggan Fu, Cheng Wan, Tushar Krishna, Yingyan Lin, Arijit Raychowdhury", "abstract": "The remarkable advancements in artificial intelligence (AI), primarily driven\nby deep neural networks, have significantly impacted various aspects of our\nlives. However, the current challenges surrounding unsustainable computational\ntrajectories, limited robustness, and a lack of explainability call for the\ndevelopment of next-generation AI systems. Neuro-symbolic AI (NSAI) emerges as\na promising paradigm, fusing neural, symbolic, and probabilistic approaches to\nenhance interpretability, robustness, and trustworthiness while facilitating\nlearning from much less data. Recent NSAI systems have demonstrated great\npotential in collaborative human-AI scenarios with reasoning and cognitive\ncapabilities. In this paper, we provide a systematic review of recent progress\nin NSAI and analyze the performance characteristics and computational operators\nof NSAI models. Furthermore, we discuss the challenges and potential future\ndirections of NSAI from both system and architectural perspectives.", "published": "2024-01-02", "categories": ["cs.AI", "cs.AR"], "links": "http://arxiv.org/abs/2401.01040v1"}
{"title": "Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment", "author": "Jie Zhu, Leye Wang, Xiao Han, Anmin Liu, Tao Xie", "abstract": "The size of deep learning models in artificial intelligence (AI) software is\nincreasing rapidly, hindering the large-scale deployment on resource-restricted\ndevices (e.g., smartphones). To mitigate this issue, AI software compression\nplays a crucial role, which aims to compress model size while keeping high\nperformance. However, the intrinsic defects in a big model may be inherited by\nthe compressed one. Such defects may be easily leveraged by adversaries, since\na compressed model is usually deployed in a large number of devices without\nadequate protection. In this article, we aim to address the safe model\ncompression problem from the perspective of safety-performance co-optimization.\nSpecifically, inspired by the test-driven development (TDD) paradigm in\nsoftware engineering, we propose a test-driven sparse training framework called\nSafeCompress. By simulating the attack mechanism as safety testing,\nSafeCompress can automatically compress a big model to a small one following\nthe dynamic sparse training paradigm. Then, considering two kinds of\nrepresentative and heterogeneous attack mechanisms, i.e., black-box membership\ninference attack and white-box membership inference attack, we develop two\nconcrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we\nimplement another instance called MMIA-SafeCompress by extending SafeCompress\nto defend against the occasion when adversaries conduct black-box and white-box\nmembership inference attacks simultaneously. We conduct extensive experiments\non five datasets for both computer vision and natural language processing\ntasks. The results show the effectiveness and generalizability of our\nframework. We also discuss how to adapt SafeCompress to other attacks besides\nmembership inference attack, demonstrating the flexibility of SafeCompress.", "published": "2024-01-02", "categories": ["cs.AI", "cs.CR", "cs.SE"], "links": "http://arxiv.org/abs/2401.00996v1"}
{"title": "Real-Time Object Detection in Occluded Environment with Background Cluttering Effects Using Deep Learning", "author": "Syed Muhammad Aamir, Hongbin Ma, Malak Abid Ali Khan, Muhammad Aaqib", "abstract": "Detection of small, undetermined moving objects or objects in an occluded\nenvironment with a cluttered background is the main problem of computer vision.\nThis greatly affects the detection accuracy of deep learning models. To\novercome these problems, we concentrate on deep learning models for real-time\ndetection of cars and tanks in an occluded environment with a cluttered\nbackground employing SSD and YOLO algorithms and improved precision of\ndetection and reduce problems faced by these models. The developed method makes\nthe custom dataset and employs a preprocessing technique to clean the noisy\ndataset. For training the developed model we apply the data augmentation\ntechnique to balance and diversify the data. We fine-tuned, trained, and\nevaluated these models on the established dataset by applying these techniques\nand highlighting the results we got more accurately than without applying these\ntechniques. The accuracy and frame per second of the SSD-Mobilenet v2 model are\nhigher than YOLO V3 and YOLO V4. Furthermore, by employing various techniques\nlike data enhancement, noise reduction, parameter optimization, and model\nfusion we improve the effectiveness of detection and recognition. We further\nadded a counting algorithm, and target attributes experimental comparison, and\nmade a graphical user interface system for the developed model with features of\nobject counting, alerts, status, resolution, and frame per second.\nSubsequently, to justify the importance of the developed method analysis of\nYOLO V3, V4, and SSD were incorporated. Which resulted in the overall\ncompletion of the proposed method.", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI"], "links": "http://arxiv.org/abs/2401.00986v1"}
