{"title": "On Time-Indexing as Inductive Bias in Deep RL for Sequential Manipulation Tasks", "author": "M. Nomaan Qureshi, Ben Eisner, David Held", "abstract": "While solving complex manipulation tasks, manipulation policies often need to\nlearn a set of diverse skills to accomplish these tasks. The set of skills is\noften quite multimodal - each one may have a quite distinct distribution of\nactions and states. Standard deep policy-learning algorithms often model\npolicies as deep neural networks with a single output head (deterministic or\nstochastic). This structure requires the network to learn to switch between\nmodes internally, which can lead to lower sample efficiency and poor\nperformance. In this paper we explore a simple structure which is conducive to\nskill learning required for so many of the manipulation tasks. Specifically, we\npropose a policy architecture that sequentially executes different action heads\nfor fixed durations, enabling the learning of primitive skills such as reaching\nand grasping. Our empirical evaluation on the Metaworld tasks reveals that this\nsimple structure outperforms standard policy learning methods, highlighting its\npotential for improved skill acquisition.", "published": "2024-01-03", "categories": ["cs.RO", "cs.AI"], "links": "http://arxiv.org/abs/2401.01993v1"}
{"title": "GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning", "author": "Aarash Feizi, Randall Balestriero, Adriana Romero-Soriano, Reihaneh Rabbany", "abstract": "We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a\ngeneral method to inject a priori knowledge into Self-Supervised Learning (SSL)\npositive samples selection. Current SSL methods leverage Data-Augmentations\n(DA) for generating positive samples and incorporate prior knowledge - an\nincorrect, or too weak DA will drastically reduce the quality of the learned\nrepresentation. GPS-SSL proposes instead to design a metric space where\nEuclidean distances become a meaningful proxy for semantic relationship. In\nthat space, it is now possible to generate positive samples from nearest\nneighbor sampling. Any prior knowledge can now be embedded into that metric\nspace independently from the employed DA. From its simplicity, GPS-SSL is\napplicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is\nin reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches\n85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We\ntherefore move a step forward towards the goal of making SSL less reliant on\nDA. We also show that even when using strong DAs, GPS-SSL outperforms the\nbaselines on under-studied domains. We evaluate GPS-SSL along with multiple\nbaseline SSL methods on numerous downstream datasets from different domains\nwhen the models use strong or minimal data augmentations. We hope that GPS-SSL\nwill open new avenues in studying how to inject a priori knowledge into SSL in\na principled manner.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01990v1"}
{"title": "Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias", "author": "Anshuman Chhabra, Hadi Askari, Prasant Mohapatra", "abstract": "We characterize and study zero-shot abstractive summarization in Large\nLanguage Models (LLMs) by measuring position bias, which we propose as a\ngeneral formulation of the more restrictive lead bias phenomenon studied\npreviously in the literature. Position bias captures the tendency of a model\nunfairly prioritizing information from certain parts of the input text over\nothers, leading to undesirable behavior. Through numerous experiments on four\ndiverse real-world datasets, we study position bias in multiple LLM models such\nas GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained\nencoder-decoder abstractive summarization models such as Pegasus and BART. Our\nfindings lead to novel insights and discussion on performance and position bias\nof models for zero-shot summarization tasks.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01989v1"}
{"title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers", "author": "Aleksandar StaniÄ‡, Sergi Caelles, Michael Tschannen", "abstract": "Visual reasoning is dominated by end-to-end neural networks scaled to\nbillions of model parameters and training examples. However, even the largest\nmodels struggle with compositional reasoning, generalization, fine-grained\nspatial and temporal reasoning, and counting. Visual reasoning with large\nlanguage models (LLMs) as controllers can, in principle, address these\nlimitations by decomposing the task and solving subtasks by orchestrating a set\nof (visual) tools. Recently, these models achieved great performance on tasks\nsuch as compositional visual question answering, visual grounding, and video\ntemporal reasoning. Nevertheless, in their current form, these models heavily\nrely on human engineering of in-context examples in the prompt, which are often\ndataset- and task-specific and require significant labor by highly skilled\nprogrammers. In this work, we present a framework that mitigates these issues\nby introducing spatially and temporally abstract routines and by leveraging a\nsmall number of labeled examples to automatically generate in-context examples,\nthereby avoiding human-created in-context examples. On a number of visual\nreasoning tasks, we show that our framework leads to consistent gains in\nperformance, makes LLMs as controllers setup more robust, and removes the need\nfor human engineering of in-context examples.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01974v1"}
{"title": "FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding", "author": "Xingxing Zuo, Pouya Samangouei, Yunwen Zhou, Yan Di, Mingyang Li", "abstract": "Precisely perceiving the geometric and semantic properties of real-world 3D\nobjects is crucial for the continued evolution of augmented reality and robotic\napplications. To this end, we present \\algfull{} (\\algname{}), which\nincorporates vision-language embeddings of foundation models into 3D Gaussian\nSplatting (GS). The key contribution of this work is an efficient method to\nreconstruct and represent 3D vision-language models. This is achieved by\ndistilling feature maps generated from image-based foundation models into those\nrendered from our 3D model. To ensure high-quality rendering and fast training,\nwe introduce a novel scene representation by integrating strengths from both GS\nand multi-resolution hash encodings (MHE). Our effective training procedure\nalso introduces a pixel alignment loss that makes the rendered feature distance\nof same semantic entities close, following the pixel-level semantic boundaries.\nOur results demonstrate remarkable multi-view semantic consistency,\nfacilitating diverse downstream tasks, beating state-of-the-art methods by\n$\\mathbf{10.2}$ percent on open-vocabulary language-based object detection,\ndespite that we are $\\mathbf{851\\times}$ faster for inference. This research\nexplores the intersection of vision, language, and 3D scene representation,\npaving the way for enhanced scene understanding in uncontrolled real-world\nenvironments. We plan to release the code upon paper acceptance.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI"], "links": "http://arxiv.org/abs/2401.01970v1"}
{"title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity", "author": "Andrew Lee, Xiaoyan Bai, Itamar Pres, Martin Wattenberg, Jonathan K. Kummerfeld, Rada Mihalcea", "abstract": "While alignment algorithms are now commonly used to tune pre-trained language\nmodels towards a user's preferences, we lack explanations for the underlying\nmechanisms in which models become ``aligned'', thus making it difficult to\nexplain phenomena like jailbreaks. In this work we study a popular algorithm,\ndirect preference optimization (DPO), and the mechanisms by which it reduces\ntoxicity. Namely, we first study how toxicity is represented and elicited in a\npre-trained language model, GPT2-medium. We then apply DPO with a carefully\ncrafted pairwise dataset to reduce toxicity. We examine how the resulting model\naverts toxic outputs, and find that capabilities learned from pre-training are\nnot removed, but rather bypassed. We use this insight to demonstrate a simple\nmethod to un-align the model, reverting it back to its toxic behavior.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01967v1"}
{"title": "Instruct-Imagen: Image Generation with Multi-modal Instruction", "author": "Hexiang Hu, Kelvin C. K. Chan, Yu-Chuan Su, Wenhu Chen, Yandong Li, Kihyuk Sohn, Yang Zhao, Xue Ben, Boqing Gong, William Cohen, Ming-Wei Chang, Xuhui Jia", "abstract": "This paper presents instruct-imagen, a model that tackles heterogeneous image\ngeneration tasks and generalizes across unseen tasks. We introduce *multi-modal\ninstruction* for image generation, a task representation articulating a range\nof generation intents with precision. It uses natural language to amalgamate\ndisparate modalities (e.g., text, edge, style, subject, etc.), such that\nabundant generation intents can be standardized in a uniform format.\n  We then build instruct-imagen by fine-tuning a pre-trained text-to-image\ndiffusion model with a two-stage framework. First, we adapt the model using the\nretrieval-augmented training, to enhance model's capabilities to ground its\ngeneration on external multimodal context. Subsequently, we fine-tune the\nadapted model on diverse image generation tasks that requires vision-language\nunderstanding (e.g., subject-driven generation, etc.), each paired with a\nmulti-modal instruction encapsulating the task's essence. Human evaluation on\nvarious image generation datasets reveals that instruct-imagen matches or\nsurpasses prior task-specific models in-domain and demonstrates promising\ngeneralization to unseen and more complex tasks.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01952v1"}
{"title": "Can We Generate Realistic Hands Only Using Convolution?", "author": "Mehran Hosseini, Peyman Hosseini", "abstract": "The enduring inability of image generative models to recreate intricate\ngeometric features, such as those present in human hands and fingers has been\nan ongoing problem in image generation for nearly a decade. While strides have\nbeen made by increasing model sizes and diversifying training datasets, this\nissue remains prevalent across all models, from denoising diffusion models to\nGenerative Adversarial Networks (GAN), pointing to a fundamental shortcoming in\nthe underlying architectures. In this paper, we demonstrate how this problem\ncan be mitigated by augmenting convolution layers geometric capabilities\nthrough providing them with a single input channel incorporating the relative\n$n$-dimensional Cartesian coordinate system. We show that this drastically\nimproves quality of hand and face images generated by GANs and Variational\nAutoEncoders (VAE).", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG", "51", "I.2.10; I.4.0; I.4.10"], "links": "http://arxiv.org/abs/2401.01951v1"}
{"title": "Generalist embedding models are better at short-context clinical semantic search than specialized embedding models", "author": "Jean-Baptiste Excoffier, Tom Roehr, Alexei Figueroa, Michalis Papaaioannou, Keno Bressem, Matthieu Ortala", "abstract": "The increasing use of tools and solutions based on Large Language Models\n(LLMs) for various tasks in the medical domain has become a prominent trend.\nTheir use in this highly critical and sensitive domain has thus raised\nimportant questions about their robustness, especially in response to\nvariations in input, and the reliability of the generated outputs. This study\naddresses these questions by constructing a textual dataset based on the\nICD-10-CM code descriptions, widely used in US hospitals and containing many\nclinical terms, and their easily reproducible rephrasing. We then benchmarked\nexisting embedding models, either generalist or specialized in the clinical\ndomain, in a semantic search task where the goal was to correctly match the\nrephrased text to the original description. Our results showed that generalist\nmodels performed better than clinical models, suggesting that existing clinical\nspecialized models are more sensitive to small changes in input that confuse\nthem. The highlighted problem of specialized models may be due to the fact that\nthey have not been trained on sufficient data, and in particular on datasets\nthat are not diverse enough to have a reliable global language understanding,\nwhich is still necessary for accurate handling of medical documents.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01943v1"}
{"title": "Step length measurement in the wild using FMCW radar", "author": "Parthipan Siva, Alexander Wong, Patricia Hewston, George Ioannidis, Dr. Jonathan Adachi, Dr. Alexander Rabinovich, Andrea Lee, Alexandra Papaioannou", "abstract": "With an aging population, numerous assistive and monitoring technologies are\nunder development to enable older adults to age in place. To facilitate aging\nin place predicting risk factors such as falls, and hospitalization and\nproviding early interventions are important. Much of the work on ambient\nmonitoring for risk prediction has centered on gait speed analysis, utilizing\nprivacy-preserving sensors like radar. Despite compelling evidence that\nmonitoring step length, in addition to gait speed, is crucial for predicting\nrisk, radar-based methods have not explored step length measurement in the\nhome. Furthermore, laboratory experiments on step length measurement using\nradars are limited to proof of concept studies with few healthy subjects. To\naddress this gap, a radar-based step length measurement system for the home is\nproposed based on detection and tracking using radar point cloud, followed by\nDoppler speed profiling of the torso to obtain step lengths in the home. The\nproposed method was evaluated in a clinical environment, involving 35 frail\nolder adults, to establish its validity. Additionally, the method was assessed\nin people's homes, with 21 frail older adults who had participated in the\nclinical assessment. The proposed radar-based step length measurement method\nwas compared to the gold standard Zeno Walkway Gait Analysis System, revealing\na 4.5cm/8.3% error in a clinical setting. Furthermore, it exhibited excellent\nreliability (ICC(2,k)=0.91, 95% CI 0.82 to 0.96) in uncontrolled home settings.\nThe method also proved accurate in uncontrolled home settings, as indicated by\na strong agreement (ICC(3,k)=0.81 (95% CI 0.53 to 0.92)) between home\nmeasurements and in-clinic assessments.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "I.5.4; C.3; J.7"], "links": "http://arxiv.org/abs/2401.01868v1"}
{"title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality", "author": "Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, Matan Eyal", "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. One promising approach is cross-lingual transfer, where a model\nacquires specific functionality on some language by finetuning on another\nlanguage. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages. We\nfirst show that many languages transfer some instruction-following capabilities\nto other languages from even monolingual tuning. Furthermore, we find that only\n40 multilingual examples in an English tuning set substantially improve\nmultilingual instruction-following, both in seen and unseen languages during\ntuning. In general, we observe that models tuned on multilingual mixtures\nexhibit comparable or superior performance in several languages compared to\nmonolingually tuned models, despite training on 10x fewer examples in those\nlanguages. Finally, we find that increasing the number of languages in the\ninstruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual\ngeneralization. Our results suggest that building massively multilingual\ninstruction-tuned models can be done with only a very small set of multilingual\ninstruction-responses.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01854v1"}
{"title": "The Power of Training: How Different Neural Network Setups Influence the Energy Demand", "author": "Daniel GeiÃŸler, Bo Zhou, Mengxi Liu, Sungho Suh, Paul Lukowicz", "abstract": "This work examines the effects of variations in machine learning training\nregimes and learning paradigms on the corresponding energy consumption. While\nincreasing data availability and innovation in high-performance hardware fuels\nthe training of sophisticated models, it also supports the fading perception of\nenergy consumption and carbon emission. Therefore, the goal of this work is to\ncreate awareness about the energy impact of general training parameters and\nprocesses, from learning rate over batch size to knowledge transfer. Multiple\nsetups with different hyperparameter initializations are evaluated on two\ndifferent hardware configurations to obtain meaningful results. Experiments on\npretraining and multitask training are conducted on top of the baseline results\nto determine their potential towards sustainable machine learning.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.PF"], "links": "http://arxiv.org/abs/2401.01851v1"}
{"title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets", "author": "Himmet Toprak Kesgin, Mehmet Fatih Amasyali", "abstract": "Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01843v1"}
{"title": "Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes", "author": "Baiting Luo, Yunuo Zhang, Abhishek Dubey, Ayan Mukhopadhyay", "abstract": "A fundamental (and largely open) challenge in sequential decision-making is\ndealing with non-stationary environments, where exogenous environmental\nconditions change over time. Such problems are traditionally modeled as\nnon-stationary Markov decision processes (NSMDP). However, existing approaches\nfor decision-making in NSMDPs have two major shortcomings: first, they assume\nthat the updated environmental dynamics at the current time are known (although\nfuture dynamics can change); and second, planning is largely pessimistic, i.e.,\nthe agent acts ``safely'' to account for the non-stationary evolution of the\nenvironment. We argue that both these assumptions are invalid in practice --\nupdated environmental conditions are rarely known, and as the agent interacts\nwith the environment, it can learn about the updated dynamics and avoid being\npessimistic, at least in states whose dynamics it is confident about. We\npresent a heuristic search algorithm called \\textit{Adaptive Monte Carlo Tree\nSearch (ADA-MCTS)} that addresses these challenges. We show that the agent can\nlearn the updated dynamics of the environment over time and then act as it\nlearns, i.e., if the agent is in a region of the state space about which it has\nupdated knowledge, it can avoid being pessimistic. To quantify ``updated\nknowledge,'' we disintegrate the aleatoric and epistemic uncertainty in the\nagent's updated belief and show how the agent can use these estimates for\ndecision-making. We compare the proposed approach with the multiple\nstate-of-the-art approaches in decision-making across multiple well-established\nopen-source problems and empirically show that our approach is faster and\nhighly adaptive without sacrificing safety.", "published": "2024-01-03", "categories": ["cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01841v1"}
{"title": "NODEC: Neural ODE For Optimal Control of Unknown Dynamical Systems", "author": "Cheng Chi", "abstract": "Controlling complex dynamical systems is generally associated with minimizing\ncertain control objectives with known dynamics under the variational calculus\nframework. For systems with unknown dynamics, an additional step of dynamics\nmodeling is required. However, any inaccuracy in dynamics modeling will lead to\nsub-optimality in the resulting control function. Another set of approaches for\ncontrolling unknown dynamical systems - reinforcement learning, folds the\ndynamics modeling into controller training via value function approximation or\npolicy gradient through extensively interacting with the environment, but it\nsuffers from low data efficiency. To address these, we introduce NODEC, a novel\nframework for controlling unknown dynamical systems, which combines dynamics\nmodelling and controller training using a coupled neural ODE model. Through an\nintriguing interplay between the two coupled neural networks, NODEC learns\nsystem dynamics as well as optimal controls that guides the unknown dynamical\nsystem towards target states. Our experiments demonstrate the effectiveness and\ndata efficiency of NODEC for learning optimal control of unknown dynamical\nsystems.", "published": "2024-01-03", "categories": ["cs.AI"], "links": "http://arxiv.org/abs/2401.01836v1"}
{"title": "Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR)", "author": "Arash Shahmansoori", "abstract": "Addressing the complexity of comprehensive information retrieval, this study\nintroduces an innovative, iterative retrieval-augmented generation system. Our\napproach uniquely integrates a vector-space driven re-ranking mechanism with\nconcurrent brainstorming to expedite the retrieval of highly relevant\ndocuments, thereby streamlining the generation of potential queries. This sets\nthe stage for our novel hybrid process, which synergistically combines\nhypothesis formulation with satisfying decision-making strategy to determine\ncontent adequacy, leveraging a chain of thought-based prompting technique. This\nunified hypothesize-satisfied phase intelligently distills information to\nascertain whether user queries have been satisfactorily addressed. Upon\nreaching this criterion, the system refines its output into a concise\nrepresentation, maximizing conceptual density with minimal verbosity. The\niterative nature of the workflow enhances process efficiency and accuracy.\nCrucially, the concurrency within the brainstorming phase significantly\naccelerates recursive operations, facilitating rapid convergence to solution\nsatisfaction. Compared to conventional methods, our system demonstrates a\nmarked improvement in computational time and cost-effectiveness. This research\nadvances the state-of-the-art in intelligent retrieval systems, setting a new\nbenchmark for resource-efficient information extraction and abstraction in\nknowledge-intensive applications.", "published": "2024-01-03", "categories": ["cs.IT", "cs.AI", "cs.IR", "math.IT"], "links": "http://arxiv.org/abs/2401.01835v1"}
{"title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling", "author": "Himmet Toprak Kesgin, Mehmet Fatih Amasyali", "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01830v1"}
{"title": "Large Language Models Relearn Removed Concepts", "author": "Michelle Lo, Shay B. Cohen, Fazl Barez", "abstract": "Advances in model editing through neuron pruning hold promise for removing\nundesirable concepts from large language models. However, it remains unclear\nwhether models have the capacity to reacquire pruned concepts after editing. To\ninvestigate this, we evaluate concept relearning in models by tracking concept\nsaliency and similarity in pruned neurons during retraining. Our findings\nreveal that models can quickly regain performance post-pruning by relocating\nadvanced concepts to earlier layers and reallocating pruned concepts to primed\nneurons with similar semantics. This demonstrates that models exhibit\npolysemantic capacities and can blend old and new concepts in individual\nneurons. While neuron pruning provides interpretability into model concepts,\nour results highlight the challenges of permanent concept removal for improved\nmodel \\textit{safety}. Monitoring concept reemergence and developing techniques\nto mitigate relearning of unsafe concepts will be important directions for more\nrobust model editing. Overall, our work strongly demonstrates the resilience\nand fluidity of concept representations in LLMs post concept removal.", "published": "2024-01-03", "categories": ["cs.AI"], "links": "http://arxiv.org/abs/2401.01814v1"}
{"title": "A quatum inspired neural network for geometric modeling", "author": "Weitao Du, Shengchao Liu, Hongyu Guo", "abstract": "By conceiving physical systems as 3D many-body point clouds, geometric graph\nneural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased\npromising performance. In particular, their effective message-passing mechanics\nmake them adept at modeling molecules and crystalline materials. However,\ncurrent geometric GNNs only offer a mean-field approximation of the many-body\nsystem, encapsulated within two-body message passing, thus falling short in\ncapturing intricate relationships within these geometric graphs. To address\nthis limitation, tensor networks, widely employed by computational physics to\nhandle manybody systems using high-order tensors, have been introduced.\nNevertheless, integrating these tensorized networks into the message-passing\nframework of GNNs faces scalability and symmetry conservation (e.g.,\npermutation and rotation) challenges. In response, we introduce an innovative\nequivariant Matrix Product State (MPS)-based message-passing strategy, through\nachieving an efficient implementation of the tensor contraction operation. Our\nmethod effectively models complex many-body relationships, suppressing\nmean-field approximations, and captures symmetries within geometric graphs.\nImportantly, it seamlessly replaces the standard message-passing and\nlayer-aggregation modules intrinsic to geometric GNNs. We empirically validate\nthe superior accuracy of our approach on benchmark tasks, including predicting\nclassical Newton systems and quantum tensor Hamiltonian matrices. To our\nknowledge, our approach represents the inaugural utilization of parameterized\ngeometric tensor networks.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "links": "http://arxiv.org/abs/2401.01801v1"}
{"title": "CoMoSVC: Consistency Model-based Singing Voice Conversion", "author": "Yiwen Lu, Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, Yike Guo", "abstract": "The diffusion-based Singing Voice Conversion (SVC) methods have achieved\nremarkable performances, producing natural audios with high similarity to the\ntarget timbre. However, the iterative sampling process results in slow\ninference speed, and acceleration thus becomes crucial. In this paper, we\npropose CoMoSVC, a consistency model-based SVC method, which aims to achieve\nboth high-quality generation and high-speed sampling. A diffusion-based teacher\nmodel is first specially designed for SVC, and a student model is further\ndistilled under self-consistency properties to achieve one-step sampling.\nExperiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a\nsignificantly faster inference speed than the state-of-the-art (SOTA)\ndiffusion-based SVC system, it still achieves comparable or superior conversion\nperformance based on both subjective and objective metrics. Audio samples and\ncodes are available at https://comosvc.github.io/.", "published": "2024-01-03", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.01792v1"}
{"title": "Deep learning the Hurst parameter of linear fractional processes and assessing its reliability", "author": "DÃ¡niel Boros, BÃ¡lint CsanÃ¡dy, IvÃ¡n Ivkovic, LÃ³rÃ¡nt Nagy, AndrÃ¡s LukÃ¡cs, LÃ¡szlÃ³ MÃ¡rkus", "abstract": "This research explores the reliability of deep learning, specifically Long\nShort-Term Memory (LSTM) networks, for estimating the Hurst parameter in\nfractional stochastic processes. The study focuses on three types of processes:\nfractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process,\nand linear fractional stable motions (lfsm). The work involves a fast\ngeneration of extensive datasets for fBm and fOU to train the LSTM network on a\nlarge volume of data in a feasible time. The study analyses the accuracy of the\nLSTM network's Hurst parameter estimation regarding various performance\nmeasures like RMSE, MAE, MRE, and quantiles of the absolute and relative\nerrors. It finds that LSTM outperforms the traditional statistical methods in\nthe case of fBm and fOU processes; however, it has limited accuracy on lfsm\nprocesses. The research also delves into the implications of training length\nand valuation sequence length on the LSTM's performance. The methodology is\napplied by estimating the Hurst parameter in Li-ion battery degradation data\nand obtaining confidence bounds for the estimation. The study concludes that\nwhile deep learning methods show promise in parameter estimation of fractional\nprocesses, their effectiveness is contingent on the process type and the\nquality of training data.", "published": "2024-01-03", "categories": ["stat.ML", "cs.AI", "cs.LG", "68T07"], "links": "http://arxiv.org/abs/2401.01789v1"}
{"title": "Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review", "author": "Ihsane Gryech, Chaimae Assad, Mounir Ghogho, Abdellatif Kobbane", "abstract": "According to the World Health Organization (WHO), air pollution kills seven\nmillion people every year. Outdoor air pollution is a major environmental\nhealth problem affecting low, middle, and high-income countries. In the past\nfew years, the research community has explored IoT-enabled machine learning\napplications for outdoor air pollution prediction. The general objective of\nthis paper is to systematically review applications of machine learning and\nInternet of Things (IoT) for outdoor air pollution prediction and the\ncombination of monitoring sensors and input features used. Two research\nquestions were formulated for this review. 1086 publications were collected in\nthe initial PRISMA stage. After the screening and eligibility phases, 37 papers\nwere selected for inclusion. A cost-based analysis was conducted on the\nfindings to highlight high-cost monitoring, low-cost IoT and hybrid enabled\nprediction. Three methods of prediction were identified: time series,\nfeature-based and spatio-temporal. This review's findings identify major\nlimitations in applications found in the literature, namely lack of coverage,\nlack of diversity of data and lack of inclusion of context-specific features.\nThis review proposes directions for future research and underlines practical\nimplications in healthcare, urban planning, global synergy and smart cities.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01788v1"}
{"title": "A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure", "author": "Yanjie Li, Weijun Li, Lina Yu, Min Wu, Jinyi Liu, Wenqiang Li, Meilan Hao", "abstract": "Artificial neural networks (ANNs) have permeated various disciplinary\ndomains, ranging from bioinformatics to financial analytics, where their\napplication has become an indispensable facet of contemporary scientific\nresearch endeavors. However, the inherent limitations of traditional neural\nnetworks arise due to their relatively fixed network structures and activation\nfunctions. 1, The type of activation function is single and relatively fixed,\nwhich leads to poor \"unit representation ability\" of the network, and it is\noften used to solve simple problems with very complex networks; 2, the network\nstructure is not adaptive, it is easy to cause network structure redundant or\ninsufficient. To address the aforementioned issues, this study proposes a novel\nneural network called X-Net. By utilizing our designed Alternating\nBackpropagation mechanism, X-Net dynamically selects appropriate activation\nfunctions based on derivative information during training to enhance the\nnetwork's representation capability for specific tasks. Simultaneously, it\naccurately adjusts the network structure at the neuron level to accommodate\ntasks of varying complexities and reduce computational costs. Through a series\nof experiments, we demonstrate the dual advantages of X-Net in terms of\nreducing model size and improving representation power. Specifically, in terms\nof the number of parameters, X-Net is only 3$\\%$ of baselines on average, and\nonly 1.4$\\%$ under some tasks. In terms of representation ability, X-Net can\nachieve an average $R^2$=0.985 on the fitting task by only optimizing the\nactivation function without introducing any parameters. Finally, we also tested\nthe ability of X-Net to help scientific discovery on data from multiple\ndisciplines such as society, energy, environment, and aerospace, and achieved\nconcise and good results.", "published": "2024-01-03", "categories": ["cs.AI", "cs.NI"], "links": "http://arxiv.org/abs/2401.01772v1"}
{"title": "Incremental FastPitch: Chunk-based High Quality Text to Speech", "author": "Muyang Du, Chuan Liu, Junjie Lai", "abstract": "Parallel text-to-speech models have been widely applied for real-time speech\nsynthesis, and they offer more controllability and a much faster synthesis\nprocess compared with conventional auto-regressive models. Although parallel\nmodels have benefits in many aspects, they become naturally unfit for\nincremental synthesis due to their fully parallel architecture such as\ntransformer. In this work, we propose Incremental FastPitch, a novel FastPitch\nvariant capable of incrementally producing high-quality Mel chunks by improving\nthe architecture with chunk-based FFT blocks, training with receptive-field\nconstrained chunk attention masks, and inference with fixed size past model\nstates. Experimental results show that our proposal can produce speech quality\ncomparable to the parallel FastPitch, with a significant lower latency that\nallows even lower response time for real-time speech applications.", "published": "2024-01-03", "categories": ["cs.SD", "cs.AI", "eess.AS"], "links": "http://arxiv.org/abs/2401.01755v1"}
{"title": "Using AI/ML to Find and Remediate Enterprise Secrets in Code & Document Sharing Platforms", "author": "Gregor Kerr, David Algorry, Senad Ibraimoski, Peter Maciver, Sean Moran", "abstract": "We introduce a new challenge to the software development community: 1)\nleveraging AI to accurately detect and flag up secrets in code and on popular\ndocument sharing platforms that frequently used by developers, such as\nConfluence and 2) automatically remediating the detections (e.g. by suggesting\npassword vault functionality). This is a challenging, and mostly unaddressed\ntask. Existing methods leverage heuristics and regular expressions, that can be\nvery noisy, and therefore increase toil on developers. The next step -\nmodifying code itself - to automatically remediate a detection, is a complex\ntask. We introduce two baseline AI models that have good detection performance\nand propose an automatic mechanism for remediating secrets found in code,\nopening up the study of this task to the wider community.", "published": "2024-01-03", "categories": ["cs.SE", "cs.AI"], "links": "http://arxiv.org/abs/2401.01754v1"}
{"title": "A Generative AI Assistant to Accelerate Cloud Migration", "author": "Amal Vaidya, Mohan Krishna Vankayalapati, Jacky Chan, Senad Ibraimoski, Sean Moran", "abstract": "We present a tool that leverages generative AI to accelerate the migration of\non-premises applications to the cloud. The Cloud Migration LLM accepts input\nfrom the user specifying the parameters of their migration, and outputs a\nmigration strategy with an architecture diagram. A user study suggests that the\nmigration LLM can assist inexperienced users in finding the right cloud\nmigration profile, while avoiding complexities of a manual approach.", "published": "2024-01-03", "categories": ["cs.AI"], "links": "http://arxiv.org/abs/2401.01753v1"}
{"title": "Task and Explanation Network", "author": "Moshe Sipper", "abstract": "Explainability in deep networks has gained increased importance in recent\nyears. We argue herein that an AI must be tasked not just with a task but also\nwith an explanation of why said task was accomplished as such. We present a\nbasic framework -- Task and Explanation Network (TENet) -- which fully\nintegrates task completion and its explanation. We believe that the field of AI\nas a whole should insist -- quite emphatically -- on explainability.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.NE"], "links": "http://arxiv.org/abs/2401.01732v1"}
{"title": "Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices", "author": "Anirudh Rajiv Menon, Unnikrishnan Menon, Kailash Ahirwar", "abstract": "Modern deep learning models, growing larger and more complex, have\ndemonstrated exceptional generalization and accuracy due to training on huge\ndatasets. This trend is expected to continue. However, the increasing size of\nthese models poses challenges in training, as traditional centralized methods\nare limited by memory constraints at such scales. This paper proposes an\nasynchronous decentralized training paradigm for large modern deep learning\nmodels that harnesses the compute power of regular heterogeneous PCs with\nlimited resources connected across the internet to achieve favourable\nperformance metrics. Ravnest facilitates decentralized training by efficiently\norganizing compute nodes into clusters with similar data transfer rates and\ncompute capabilities, without necessitating that each node hosts the entire\nmodel. These clusters engage in $\\textit{Zero-Bubble Asynchronous Model\nParallel}$ training, and a $\\textit{Parallel Multi-Ring All-Reduce}$ method is\nemployed to effectively execute global parameter averaging across all clusters.\nWe have framed our asynchronous SGD loss function as a block structured\noptimization problem with delayed updates and derived an optimal convergence\nrate of $O\\left(\\frac{1}{\\sqrt{K}}\\right)$. We further discuss linear speedup\nwith respect to the number of participating clusters and the bound on the\nstaleness parameter.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.DC"], "links": "http://arxiv.org/abs/2401.01728v1"}
{"title": "Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed", "author": "Xuejian Li, Ze Wang, Bingqi Zhu, Fei He, Yongkang Wang, Xingxing Wang", "abstract": "E-commerce platforms usually present an ordered list, mixed with several\norganic items and an advertisement, in response to each user's page view\nrequest. This list, the outcome of ad auction and allocation processes,\ndirectly impacts the platform's ad revenue and gross merchandise volume (GMV).\nSpecifically, the ad auction determines which ad is displayed and the\ncorresponding payment, while the ad allocation decides the display positions of\nthe advertisement and organic items. The prevalent methods of segregating the\nad auction and allocation into two distinct stages face two problems: 1) Ad\nauction does not consider externalities, such as the influence of actual\ndisplay position and context on ad Click-Through Rate (CTR); 2) The ad\nallocation, which utilizes the auction-winning ad's payment to determine the\ndisplay position dynamically, fails to maintain incentive compatibility (IC)\nfor the advertisement. For instance, in the auction stage employing the\ntraditional Generalized Second Price (GSP) , even if the winning ad increases\nits bid, its payment remains unchanged. This implies that the advertisement\ncannot secure a better position and thus loses the opportunity to achieve\nhigher utility in the subsequent ad allocation stage. Previous research often\nfocused on one of the two stages, neglecting the two-stage problem, which may\nresult in suboptimal outcomes...", "published": "2024-01-03", "categories": ["cs.GT", "cs.AI"], "links": "http://arxiv.org/abs/2401.01656v1"}
{"title": "AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI", "author": "Fanda Fan, Chunjie Luo, Jianfeng Zhan, Wanling Gao", "abstract": "The burgeoning field of Artificial Intelligence Generated Content (AIGC) is\nwitnessing rapid advancements, particularly in video generation. This paper\nintroduces AIGCBench, a pioneering comprehensive and scalable benchmark\ndesigned to evaluate a variety of video generation tasks, with a primary focus\non Image-to-Video (I2V) generation. AIGCBench tackles the limitations of\nexisting benchmarks, which suffer from a lack of diverse datasets, by including\na varied and open-domain image-text dataset that evaluates different\nstate-of-the-art algorithms under equivalent conditions. We employ a novel text\ncombiner and GPT-4 to create rich text prompts, which are then used to generate\nimages via advanced Text-to-Image models. To establish a unified evaluation\nframework for video generation tasks, our benchmark includes 11 metrics\nspanning four dimensions to assess algorithm performance. These dimensions are\ncontrol-video alignment, motion effects, temporal consistency, and video\nquality. These metrics are both reference video-dependent and video-free,\nensuring a comprehensive evaluation strategy. The evaluation standard proposed\ncorrelates well with human judgment, providing insights into the strengths and\nweaknesses of current I2V algorithms. The findings from our extensive\nexperiments aim to stimulate further research and development in the I2V field.\nAIGCBench represents a significant step toward creating standardized benchmarks\nfor the broader AIGC landscape, proposing an adaptable and equitable framework\nfor future assessments of video generation tasks.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI"], "links": "http://arxiv.org/abs/2401.01651v1"}
{"title": "A Cybersecurity Risk Analysis Framework for Systems with Artificial Intelligence Components", "author": "Jose Manuel Camacho, Aitor Couce-Vieira, David Arroyo, David Rios Insua", "abstract": "The introduction of the European Union Artificial Intelligence Act, the NIST\nArtificial Intelligence Risk Management Framework, and related norms demands a\nbetter understanding and implementation of novel risk analysis approaches to\nevaluate systems with Artificial Intelligence components. This paper provides a\ncybersecurity risk analysis framework that can help assessing such systems. We\nuse an illustrative example concerning automated driving systems.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CR", "stat.AP"], "links": "http://arxiv.org/abs/2401.01630v1"}
{"title": "Synthetic Data in AI: Challenges, Applications, and Ethical Implications", "author": "Shuang Hao, Wenfeng Han, Tao Jiang, Yiping Li, Haonan Wu, Chunlin Zhong, Zhangjun Zhou, He Tang", "abstract": "In the rapidly evolving field of artificial intelligence, the creation and\nutilization of synthetic datasets have become increasingly significant. This\nreport delves into the multifaceted aspects of synthetic data, particularly\nemphasizing the challenges and potential biases these datasets may harbor. It\nexplores the methodologies behind synthetic data generation, spanning\ntraditional statistical models to advanced deep learning techniques, and\nexamines their applications across diverse domains. The report also critically\naddresses the ethical considerations and legal implications associated with\nsynthetic datasets, highlighting the urgent need for mechanisms to ensure\nfairness, mitigate biases, and uphold ethical standards in AI development.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.CY"], "links": "http://arxiv.org/abs/2401.01629v1"}
{"title": "On the Expressive Power of Graph Neural Networks", "author": "Ashwin Nalwade, Kelly Marshall, Axel Eladi, Umang Sharma", "abstract": "The study of Graph Neural Networks has received considerable interest in the\npast few years. By extending deep learning to graph-structured data, GNNs can\nsolve a diverse set of tasks in fields including social science, chemistry, and\nmedicine. The development of GNN architectures has largely been focused on\nimproving empirical performance on tasks like node or graph classification.\nHowever, a line of recent work has instead sought to find GNN architectures\nthat have desirable theoretical properties - by studying their expressive power\nand designing architectures that maximize this expressiveness.\n  While there is no consensus on the best way to define the expressiveness of a\nGNN, it can be viewed from several well-motivated perspectives. Perhaps the\nmost natural approach is to study the universal approximation properties of\nGNNs, much in the way that this has been studied extensively for MLPs. Another\ndirection focuses on the extent to which GNNs can distinguish between different\ngraph structures, relating this to the graph isomorphism test. Besides, a GNN's\nability to compute graph properties such as graph moments has been suggested as\nanother form of expressiveness. All of these different definitions are\ncomplementary and have yielded different recommendations for GNN architecture\nchoices. In this paper, we would like to give an overview of the notion of\n\"expressive power\" of GNNs and provide some valuable insights regarding the\ndesign choices of GNNs.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01626v1"}
{"title": "Can AI Be as Creative as Humans?", "author": "Haonan Wang, James Zou, Michael Mozer, Linjun Zhang, Anirudh Goyal, Alex Lamb, Zhun Deng, Michael Qizhe Xie, Hannah Brown, Kenji Kawaguchi", "abstract": "Creativity serves as a cornerstone for societal progress and innovation, but\nits assessment remains a complex and often subjective endeavor. With the rise\nof advanced generative AI models capable of tasks once reserved for human\ncreativity, the study of AI's creative potential becomes imperative for its\nresponsible development and application. This paper addresses the complexities\nin defining and evaluating creativity by introducing a new concept called\nRelative Creativity. Instead of trying to define creativity universally, we\nshift the focus to whether AI can match the creative abilities of a\nhypothetical human. This perspective draws inspiration from the Turing Test,\nexpanding upon it to address the challenges and subjectivities inherent in\nevaluating creativity. This methodological shift facilitates a statistically\nquantifiable evaluation of AI's creativity, which we term Statistical\nCreativity. This approach allows for direct comparisons of AI's creative\nabilities with those of specific human groups. Building on this foundation, we\ndiscuss the application of statistical creativity in contemporary\nprompt-conditioned autoregressive models. In addition to defining and analyzing\na measure of creativity, we introduce an actionable training guideline,\neffectively bridging the gap between theoretical quantification of creativity\nand practical model training. Through these multifaceted contributions, the\npaper establishes a cohesive, continuously evolving, and transformative\nframework for assessing and fostering statistical creativity in AI models.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01623v1"}
{"title": "Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication", "author": "Philip Chung, Christine T Fong, Andrew M Walters, Nima Aghaeepour, Meliha Yetisgen, Vikas N O'Reilly-Shah", "abstract": "We investigate whether general-domain large language models such as GPT-4\nTurbo can perform risk stratification and predict post-operative outcome\nmeasures using a description of the procedure and a patient's clinical notes\nderived from the electronic health record. We examine predictive performance on\n8 different tasks: prediction of ASA Physical Status Classification, hospital\nadmission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1\nduration, hospital duration, and ICU duration. Few-shot and chain-of-thought\nprompting improves predictive performance for several of the tasks. We achieve\nF1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU\nadmission, and 0.86 for hospital mortality. Performance on duration prediction\ntasks were universally poor across all prompt strategies. Current generation\nlarge language models can assist clinicians in perioperative risk\nstratification on classification tasks and produce high-quality natural\nlanguage summaries and explanations.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01620v1"}
{"title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded", "author": "Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, Yu Su", "abstract": "The recent development on large multimodal models (LMMs), especially\nGPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries\nof multimodal models beyond traditional tasks like image captioning and visual\nquestion answering. In this work, we explore the potential of LMMs like GPT-4V\nas a generalist web agent that can follow natural language instructions to\ncomplete tasks on any given website. We propose SEEACT, a generalist web agent\nthat harnesses the power of LMMs for integrated visual understanding and acting\non the web. We evaluate on the recent MIND2WEB benchmark. In addition to\nstandard offline evaluation on cached websites, we enable a new online\nevaluation setting by developing a tool that allows running web agents on live\nwebsites. We show that GPT-4V presents a great potential for web agents - it\ncan successfully complete 50% of the tasks on live websites if we manually\nground its textual plans into actions on the websites. This substantially\noutperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)\nspecifically fine-tuned for web agents. However, grounding still remains a\nmajor challenge. Existing LMM grounding strategies like set-of-mark prompting\nturns out not effective for web agents, and the best grounding strategy we\ndevelop in this paper leverages both the HTML text and visuals. Yet, there is\nstill a substantial gap with oracle grounding, leaving ample room for further\nimprovement.", "published": "2024-01-03", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "links": "http://arxiv.org/abs/2401.01614v1"}
{"title": "PLLaMa: An Open-source Large Language Model for Plant Science", "author": "Xianjun Yang, Junfeng Gao, Wenxin Xue, Erik Alexandersson", "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "links": "http://arxiv.org/abs/2401.01600v1"}
{"title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries", "author": "Akash Ghosh, Arkadeep Acharya, Prince Jha, Aniket Gaudgaul, Rajdeep Majumdar, Sriparna Saha, Aman Chadha, Raghav Jain, Setu Sinha, Shivani Agarwal", "abstract": "In the healthcare domain, summarizing medical questions posed by patients is\ncritical for improving doctor-patient interactions and medical decision-making.\nAlthough medical data has grown in complexity and quantity, the current body of\nresearch in this domain has primarily concentrated on text-based methods,\noverlooking the integration of visual cues. Also prior works in the area of\nmedical question summarisation have been limited to the English language. This\nwork introduces the task of multimodal medical question summarization for\ncodemixed input in a low-resource setting. To address this gap, we introduce\nthe Multimodal Medical Codemixed Question Summarization MMCQS dataset, which\ncombines Hindi-English codemixed medical queries with visual aids. This\nintegration enriches the representation of a patient's medical condition,\nproviding a more comprehensive perspective. We also propose a framework named\nMedSumm that leverages the power of LLMs and VLMs for this task. By utilizing\nour MMCQS dataset, we demonstrate the value of integrating visual information\nfrom images to improve the creation of medically detailed summaries. This\nmultimodal strategy not only improves healthcare decision-making but also\npromotes a deeper comprehension of patient queries, paving the way for future\nexploration in personalized and responsive medical care. Our dataset, code, and\npre-trained models will be made publicly available.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01596v1"}
{"title": "Adversarial Machine Learning-Enabled Anonymization of OpenWiFi Data", "author": "Samhita Kuili, Kareem Dabbour, Irtiza Hasan, Andrea Herscovich, Burak Kantarci, Marcel Chenier, Melike Erol-Kantarci", "abstract": "Data privacy and protection through anonymization is a critical issue for\nnetwork operators or data owners before it is forwarded for other possible use\nof data. With the adoption of Artificial Intelligence (AI), data anonymization\naugments the likelihood of covering up necessary sensitive information;\npreventing data leakage and information loss. OpenWiFi networks are vulnerable\nto any adversary who is trying to gain access or knowledge on traffic\nregardless of the knowledge possessed by data owners. The odds for discovery of\nactual traffic information is addressed by applied conditional tabular\ngenerative adversarial network (CTGAN). CTGAN yields synthetic data; which\ndisguises as actual data but fostering hidden acute information of actual data.\nIn this paper, the similarity assessment of synthetic with actual data is\nshowcased in terms of clustering algorithms followed by a comparison of\nperformance for unsupervised cluster validation metrics. A well-known\nalgorithm, K-means outperforms other algorithms in terms of similarity\nassessment of synthetic data over real data while achieving nearest scores\n0.634, 23714.57, and 0.598 as Silhouette, Calinski and Harabasz and Davies\nBouldin metric respectively. On exploiting a comparative analysis in validation\nscores among several algorithms, K-means forms the epitome of unsupervised\nclustering algorithms ensuring explicit usage of synthetic data at the same\ntime a replacement for real data. Hence, the experimental results aim to show\nthe viability of using CTGAN-generated synthetic data in lieu of publishing\nanonymized data to be utilized in various applications.", "published": "2024-01-03", "categories": ["cs.NI", "cs.AI"], "links": "http://arxiv.org/abs/2401.01542v1"}
{"title": "The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers", "author": "Orson Mengara", "abstract": "The area of Machine Learning as a Service (MLaaS) is experiencing increased\nimplementation due to recent advancements in the AI (Artificial Intelligence)\nindustry. However, this spike has prompted concerns regarding AI defense\nmechanisms, specifically regarding potential covert attacks from third-party\nproviders that cannot be entirely trusted. Recent research has uncovered that\nauditory backdoors may use certain modifications as their initiating mechanism.\nDynamicTrigger is introduced as a methodology for carrying out dynamic backdoor\nattacks that use cleverly designed tweaks to ensure that corrupted samples are\nindistinguishable from clean. By utilizing fluctuating signal sampling rates\nand masking speaker identities through dynamic sound triggers (such as the\nclapping of hands), it is possible to deceive speech recognition systems (ASR).\nOur empirical testing demonstrates that DynamicTrigger is both potent and\nstealthy, achieving impressive success rates during covert attacks while\nmaintaining exceptional accuracy with non-poisoned datasets.", "published": "2024-01-03", "categories": ["cs.CR", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01537v1"}
{"title": "GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse", "author": "Hongzhan Lin, Ziyang Luo, Bo Wang, Ruichao Yang, Jing Ma", "abstract": "The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and imagery. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01523v1"}
{"title": "Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review", "author": "Luoma Ke, Song Tong, Peng Chen, Kaiping Peng", "abstract": "This paper explores the frontiers of large language models (LLMs) in\npsychology applications. Psychology has undergone several theoretical changes,\nand the current use of Artificial Intelligence (AI) and Machine Learning,\nparticularly LLMs, promises to open up new research directions. We provide a\ndetailed exploration of how LLMs like ChatGPT are transforming psychological\nresearch. It discusses the impact of LLMs across various branches of\npsychology, including cognitive and behavioral, clinical and counseling,\neducational and developmental, and social and cultural psychology, highlighting\ntheir potential to simulate aspects of human cognition and behavior. The paper\ndelves into the capabilities of these models to emulate human-like text\ngeneration, offering innovative tools for literature review, hypothesis\ngeneration, experimental design, experimental subjects, data analysis, academic\nwriting, and peer review in psychology. While LLMs are essential in advancing\nresearch methodologies in psychology, the paper also cautions about their\ntechnical and ethical challenges. There are issues like data privacy, the\nethical implications of using LLMs in psychological research, and the need for\na deeper understanding of these models' limitations. Researchers should\nresponsibly use LLMs in psychological studies, adhering to ethical standards\nand considering the potential consequences of deploying these technologies in\nsensitive areas. Overall, the article provides a comprehensive overview of the\ncurrent state of LLMs in psychology, exploring potential benefits and\nchallenges. It serves as a call to action for researchers to leverage LLLs'\nadvantages responsibly while addressing associated risks.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01519v1"}
{"title": "From Pixel to Slide image: Polarization Modality-based Pathological Diagnosis Using Representation Learning", "author": "Jia Dong, Yao Yao, Yang Dong, Hui Ma", "abstract": "Thyroid cancer is the most common endocrine malignancy, and accurately\ndistinguishing between benign and malignant thyroid tumors is crucial for\ndeveloping effective treatment plans in clinical practice. Pathologically,\nthyroid tumors pose diagnostic challenges due to improper specimen sampling. In\nthis study, we have designed a three-stage model using representation learning\nto integrate pixel-level and slice-level annotations for distinguishing thyroid\ntumors. This structure includes a pathology structure recognition method to\npredict structures related to thyroid tumors, an encoder-decoder network to\nextract pixel-level annotation information by learning the feature\nrepresentations of image blocks, and an attention-based learning mechanism for\nthe final classification task. This mechanism learns the importance of\ndifferent image blocks in a pathological region, globally considering the\ninformation from each block. In the third stage, all information from the image\nblocks in a region is aggregated using attention mechanisms, followed by\nclassification to determine the category of the region. Experimental results\ndemonstrate that our proposed method can predict microscopic structures more\naccurately. After color-coding, the method achieves results on unstained\npathology slides that approximate the quality of Hematoxylin and eosin\nstaining, reducing the need for stained pathology slides. Furthermore, by\nleveraging the concept of indirect measurement and extracting polarized\nfeatures from structures correlated with lesions, the proposed method can also\nclassify samples where membrane structures cannot be obtained through sampling,\nproviding a potential objective and highly accurate indirect diagnostic\ntechnique for thyroid tumors.", "published": "2024-01-03", "categories": ["eess.IV", "cs.AI", "cs.CV"], "links": "http://arxiv.org/abs/2401.01496v1"}
{"title": "Free Lunch for Federated Remote Sensing Target Fine-Grained Classification: A Parameter-Efficient Framework", "author": "Shengchao Chen, Ting Shu, Huan Zhao, Jiahao Wang, Sufen Ren, Lina Yang", "abstract": "Remote Sensing Target Fine-grained Classification (TFGC) is of great\nsignificance in both military and civilian fields. Due to location differences,\ngrowth in data size, and centralized server storage constraints, these data are\nusually stored under different databases across regions/countries. However,\nprivacy laws and national security concerns constrain researchers from\naccessing these sensitive remote sensing images for further analysis.\nAdditionally, low-resource remote sensing devices encounter challenges in terms\nof communication overhead and efficiency when dealing with the ever-increasing\ndata and model scales. To solve the above challenges, this paper proposes a\nnovel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed\nPRFL. The proposed framework allows each client to learn global and local\nknowledge to enhance the local representation of private data in environments\nwith extreme statistical heterogeneity (non. Independent and Identically\nDistributed, IID). Thus, it provides highly customized models to clients with\ndifferentiated data distributions. Moreover, the framework minimizes\ncommunication overhead and improves efficiency while ensuring satisfactory\nperformance, thereby enhancing robustness and practical applicability under\nresource-scarce conditions. We demonstrate the effectiveness of the proposed\nPRFL on the classical TFGC task by leveraging four public datasets.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.CR"], "links": "http://arxiv.org/abs/2401.01493v1"}
{"title": "The Neuron as a Direct Data-Driven Controller", "author": "Jason Moore, Alexander Genkin, Magnus Tournoy, Joshua Pughe-Sanford, Rob R. de Ruyter van Steveninck, Dmitri B. Chklovskii", "abstract": "In the quest to model neuronal function amidst gaps in physiological data, a\npromising strategy is to develop a normative theory that interprets neuronal\nphysiology as optimizing a computational objective. This study extends the\ncurrent normative models, which primarily optimize prediction, by\nconceptualizing neurons as optimal feedback controllers. We posit that neurons,\nespecially those beyond early sensory areas, act as controllers, steering their\nenvironment towards a specific desired state through their output. This\nenvironment comprises both synaptically interlinked neurons and external motor\nsensory feedback loops, enabling neurons to evaluate the effectiveness of their\ncontrol via synaptic feedback. Utilizing the novel Direct Data-Driven Control\n(DD-DC) framework, we model neurons as biologically feasible controllers which\nimplicitly identify loop dynamics, infer latent states and optimize control.\nOur DD-DC neuron model explains various neurophysiological phenomena: the shift\nfrom potentiation to depression in Spike-Timing-Dependent Plasticity (STDP)\nwith its asymmetry, the duration and adaptive nature of feedforward and\nfeedback neuronal filters, the imprecision in spike generation under constant\nstimulation, and the characteristic operational variability and noise in the\nbrain. Our model presents a significant departure from the traditional,\nfeedforward, instant-response McCulloch-Pitts-Rosenblatt neuron, offering a\nnovel and biologically-informed fundamental unit for constructing neural\nnetworks.", "published": "2024-01-03", "categories": ["q-bio.NC", "cs.AI", "cs.SY", "eess.SY"], "links": "http://arxiv.org/abs/2401.01489v1"}
{"title": "Uncertainty Regularized Evidential Regression", "author": "Kai Ye, Tiejin Chen, Hua Wei, Liang Zhan", "abstract": "The Evidential Regression Network (ERN) represents a novel approach that\nintegrates deep learning with Dempster-Shafer's theory to predict a target and\nquantify the associated uncertainty. Guided by the underlying theory, specific\nactivation functions must be employed to enforce non-negative values, which is\na constraint that compromises model performance by limiting its ability to\nlearn from all samples. This paper provides a theoretical analysis of this\nlimitation and introduces an improvement to overcome it. Initially, we define\nthe region where the models can't effectively learn from the samples. Following\nthis, we thoroughly analyze the ERN and investigate this constraint. Leveraging\nthe insights from our analysis, we address the limitation by introducing a\nnovel regularization term that empowers the ERN to learn from the whole\ntraining set. Our extensive experiments substantiate our theoretical findings\nand demonstrate the effectiveness of the proposed solution.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01484v1"}
{"title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition", "author": "Kyle Buettner, Sina Malakouti, Xiang Lorraine Li, Adriana Kovashka", "abstract": "Existing object recognition models have been shown to lack robustness in\ndiverse geographical scenarios due to significant domain shifts in design and\ncontext. Class representations need to be adapted to more accurately reflect an\nobject concept under these shifts. In the absence of training data from target\ngeographies, we hypothesize that geography-specific descriptive knowledge of\nobject categories can be leveraged to enhance robustness. For this purpose, we\nexplore the feasibility of probing a large-language model for\ngeography-specific object knowledge, and we investigate integrating knowledge\nin zero-shot and learnable soft prompting with the CLIP vision-language model.\nIn particular, we propose a geography knowledge regularization method to ensure\nthat soft prompts trained on a source set of geographies generalize to an\nunseen target set of geographies. Our gains on DollarStreet when generalizing\nfrom a model trained only on data from Europe are as large as +2.8 on countries\nfrom Africa, and +4.6 on the hardest classes. We further show competitive\nperformance vs. few-shot target training, and provide insights into how\ndescriptive knowledge captures geographical differences.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01482v1"}
{"title": "Token Propagation Controller for Efficient Vision Transformer", "author": "Wentao Zhu", "abstract": "Vision transformers (ViTs) have achieved promising results on a variety of\nComputer Vision tasks, however their quadratic complexity in the number of\ninput tokens has limited their application specially in resource-constrained\nsettings. Previous approaches that employ gradual token reduction to address\nthis challenge assume that token redundancy in one layer implies redundancy in\nall the following layers. We empirically demonstrate that this assumption is\noften not correct, i.e., tokens that are redundant in one layer can be useful\nin later layers. We employ this key insight to propose a novel token\npropagation controller (TPC) that incorporates two different\ntoken-distributions, i.e., pause probability and restart probability to control\nthe reduction and reuse of tokens respectively, which results in more efficient\ntoken utilization. To improve the estimates of token distributions, we propose\na smoothing mechanism that acts as a regularizer and helps remove noisy\noutliers. Furthermore, to improve the training-stability of our proposed TPC,\nwe introduce a model stabilizer that is able to implicitly encode local image\nstructures and minimize accuracy fluctuations during model training. We present\nextensive experimental results on the ImageNet-1K dataset using DeiT, LV-ViT\nand Swin models to demonstrate the effectiveness of our proposed method. For\nexample, compared to baseline models, our proposed method improves the\ninference speed of the DeiT-S by 250% while increasing the classification\naccuracy by 1.0%.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.NE"], "links": "http://arxiv.org/abs/2401.01470v1"}
{"title": "Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation", "author": "Walid Saba, Suzanne Wendelken, James. Shanahan", "abstract": "Summarization of electronic health records (EHRs) can substantially minimize\n'screen time' for both patients as well as medical personnel. In recent years\nsummarization of EHRs have employed machine learning pipelines using state of\nthe art neural models. However, these models have produced less than adequate\nresults that are attributed to the difficulty of obtaining sufficient annotated\ndata for training. Moreover, the requirement to consider the entire content of\nan EHR in summarization has resulted in poor performance due to the fact that\nattention mechanisms in modern large language models (LLMs) adds a quadratic\ncomplexity in terms of the size of the input. We propose here a method that\nmitigates these shortcomings by combining semantic search, retrieval augmented\ngeneration (RAG) and question-answering using the latest LLMs. In our approach\nsummarization is the extraction of answers to specific questions that are\ndeemed important by subject-matter experts (SMEs). Our approach is quite\nefficient; requires minimal to no training; does not suffer from the\n'hallucination' problem of LLMs; and it ensures diversity, since the summary\nwill not have repeated content but diverse answers to specific questions.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01469v1"}
