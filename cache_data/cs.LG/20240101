{"title": "Downstream Task-Oriented Generative Model Selections on Synthetic Data Training for Fraud Detection Models", "author": "Yinan Cheng, Chi-Hua Wang, Vamsi K. Potluru, Tucker Balch, Guang Cheng", "abstract": "Devising procedures for downstream task-oriented generative model selections\nis an unresolved problem of practical importance. Existing studies focused on\nthe utility of a single family of generative models. They provided limited\ninsights on how synthetic data practitioners select the best family generative\nmodels for synthetic training tasks given a specific combination of machine\nlearning model class and performance metric. In this paper, we approach the\ndownstream task-oriented generative model selections problem in the case of\ntraining fraud detection models and investigate the best practice given\ndifferent combinations of model interpretability and model performance\nconstraints. Our investigation supports that, while both Neural\nNetwork(NN)-based and Bayesian Network(BN)-based generative models are both\ngood to complete synthetic training task under loose model interpretability\nconstrain, the BN-based generative models is better than NN-based when\nsynthetic training fraud detection model under strict model interpretability\nconstrain. Our results provides practical guidance for machine learning\npractitioner who is interested in replacing their training dataset from real to\nsynthetic, and shed lights on more general downstream task-oriented generative\nmodel selection problems.", "published": "2024-01-01", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.00974v1"}
{"title": "Facebook Report on Privacy of fNIRS data", "author": "Md Imran Hossen, Sai Venkatesh Chilukoti, Liqun Shan, Vijay Srinivas Tida, Xiali Hei", "abstract": "The primary goal of this project is to develop privacy-preserving machine\nlearning model training techniques for fNIRS data. This project will build a\nlocal model in a centralized setting with both differential privacy (DP) and\ncertified robustness. It will also explore collaborative federated learning to\ntrain a shared model between multiple clients without sharing local fNIRS\ndatasets. To prevent unintentional private information leakage of such clients'\nprivate datasets, we will also implement DP in the federated learning setting.", "published": "2024-01-01", "categories": ["cs.LG", "cs.CR", "I.2.0"], "links": "http://arxiv.org/abs/2401.00973v1"}
{"title": "Robust Meta-Model for Predicting the Need for Blood Transfusion in Non-traumatic ICU Patients", "author": "Alireza Rafiei, Ronald Moore, Tilendra Choudhary, Curtis Marshall, Geoffrey Smith, John D. Roback, Ravi M. Patel, Cassandra D. Josephson, Rishikesan Kamaleswaran", "abstract": "Objective: Blood transfusions, crucial in managing anemia and coagulopathy in\nICU settings, require accurate prediction for effective resource allocation and\npatient risk assessment. However, existing clinical decision support systems\nhave primarily targeted a particular patient demographic with unique medical\nconditions and focused on a single type of blood transfusion. This study aims\nto develop an advanced machine learning-based model to predict the probability\nof transfusion necessity over the next 24 hours for a diverse range of\nnon-traumatic ICU patients.\n  Methods: We conducted a retrospective cohort study on 72,072 adult\nnon-traumatic ICU patients admitted to a high-volume US metropolitan academic\nhospital between 2016 and 2020. We developed a meta-learner and various machine\nlearning models to serve as predictors, training them annually with four-year\ndata and evaluating on the fifth, unseen year, iteratively over five years.\n  Results: The experimental results revealed that the meta-model surpasses the\nother models in different development scenarios. It achieved notable\nperformance metrics, including an Area Under the Receiver Operating\nCharacteristic (AUROC) curve of 0.97, an accuracy rate of 0.93, and an F1-score\nof 0.89 in the best scenario.\n  Conclusion: This study pioneers the use of machine learning models for\npredicting blood transfusion needs in a diverse cohort of critically ill\npatients. The findings of this evaluation confirm that our model not only\npredicts transfusion requirements effectively but also identifies key\nbiomarkers for making transfusion decisions.", "published": "2024-01-01", "categories": ["cs.LG", "cs.CY", "stat.AP"], "links": "http://arxiv.org/abs/2401.00972v1"}
{"title": "Directional Antenna Systems for Long-Range Through-Wall Human Activity Recognition", "author": "Julian Strohmayer, Martin Kampel", "abstract": "WiFi Channel State Information (CSI)-based human activity recognition (HAR)\nenables contactless, long-range sensing in spatially constrained environments\nwhile preserving visual privacy. However, despite the presence of numerous\nWiFi-enabled devices around us, few expose CSI to users, resulting in a lack of\nsensing hardware options. Variants of the Espressif ESP32 have emerged as\npotential low-cost and easy-to-deploy solutions for WiFi CSI-based HAR. In this\nwork, four ESP32-S3-based 2.4GHz directional antenna systems are evaluated for\ntheir ability to facilitate long-range through-wall HAR. Two promising systems\nare proposed, one of which combines the ESP32-S3 with a directional biquad\nantenna. This combination represents, to the best of our knowledge, the first\ndemonstration of such a system in WiFi-based HAR. The second system relies on\nthe built-in printed inverted-F antenna (PIFA) of the ESP32-S3 and achieves\ndirectionality through a plane reflector. In a comprehensive evaluation of\nline-of-sight (LOS) and non-line-of-sight (NLOS) HAR performance, both systems\nare deployed in an office environment spanning a distance of 18 meters across\nfive rooms. In this experimental setup, the Wallhack1.8k dataset, comprising\n1806 CSI amplitude spectrograms of human activities, is collected and made\npublicly available. Based on Wallhack1.8k, we train activity recognition models\nusing the EfficientNetV2 architecture to assess system performance in LOS and\nNLOS scenarios. For the core NLOS activity recognition problem, the biquad\nantenna and PIFA-based systems achieve accuracies of 92.0$\\pm$3.5 and\n86.8$\\pm$4.7, respectively, demonstrating the feasibility of long-range\nthrough-wall HAR with the proposed systems.", "published": "2024-01-01", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01388v1"}
{"title": "Improve Fidelity and Utility of Synthetic Credit Card Transaction Time Series from Data-centric Perspective", "author": "Din-Yin Hsieh, Chi-Hua Wang, Guang Cheng", "abstract": "Exploring generative model training for synthetic tabular data, specifically\nin sequential contexts such as credit card transaction data, presents\nsignificant challenges. This paper addresses these challenges, focusing on\nattaining both high fidelity to actual data and optimal utility for machine\nlearning tasks. We introduce five pre-processing schemas to enhance the\ntraining of the Conditional Probabilistic Auto-Regressive Model (CPAR),\ndemonstrating incremental improvements in the synthetic data's fidelity and\nutility. Upon achieving satisfactory fidelity levels, our attention shifts to\ntraining fraud detection models tailored for time-series data, evaluating the\nutility of the synthetic data. Our findings offer valuable insights and\npractical guidelines for synthetic data practitioners in the finance sector,\ntransitioning from real to synthetic datasets for training purposes, and\nilluminating broader methodologies for synthesizing credit card transaction\ntime series.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00965v1"}
{"title": "Data Augmentation Techniques for Cross-Domain WiFi CSI-based Human Activity Recognition", "author": "Julian Strohmayer, Martin Kampel", "abstract": "The recognition of human activities based on WiFi Channel State Information\n(CSI) enables contactless and visual privacy-preserving sensing in indoor\nenvironments. However, poor model generalization, due to varying environmental\nconditions and sensing hardware, is a well-known problem in this space. To\naddress this issue, in this work, data augmentation techniques commonly used in\nimage-based learning are applied to WiFi CSI to investigate their effects on\nmodel generalization performance in cross-scenario and cross-system settings.\nIn particular, we focus on the generalization between line-of-sight (LOS) and\nnon-line-of-sight (NLOS) through-wall scenarios, as well as on the\ngeneralization between different antenna systems, which remains under-explored.\nWe collect and make publicly available a dataset of CSI amplitude spectrograms\nof human activities. Utilizing this data, an ablation study is conducted in\nwhich activity recognition models based on the EfficientNetV2 architecture are\ntrained, allowing us to assess the effects of each augmentation on model\ngeneralization performance. The gathered results show that specific\ncombinations of simple data augmentation techniques applied to CSI amplitude\ndata can significantly improve cross-scenario and cross-system generalization.", "published": "2024-01-01", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.00964v1"}
{"title": "Automated Model Selection for Tabular Data", "author": "Avinash Amballa, Anmol Mekala, Gayathri Akkinapalli, Manas Madine, Naga Pavana Priya Yarrabolu, Przemyslaw A. Grabowicz", "abstract": "Structured data in the form of tabular datasets contain features that are\ndistinct and discrete, with varying individual and relative importances to the\ntarget. Combinations of one or more features may be more predictive and\nmeaningful than simple individual feature contributions. R's mixed effect\nlinear models library allows users to provide such interactive feature\ncombinations in the model design. However, given many features and possible\ninteractions to select from, model selection becomes an exponentially difficult\ntask. We aim to automate the model selection process for predictions on tabular\ndatasets incorporating feature interactions while keeping computational costs\nsmall. The framework includes two distinct approaches for feature selection: a\nPriority-based Random Grid Search and a Greedy Search method. The\nPriority-based approach efficiently explores feature combinations using prior\nprobabilities to guide the search. The Greedy method builds the solution\niteratively by adding or removing features based on their impact. Experiments\non synthetic demonstrate the ability to effectively capture predictive feature\ncombinations.", "published": "2024-01-01", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.00961v1"}
{"title": "Families of costs with zero and nonnegative MTW tensor in optimal transport", "author": "Du Nguyen", "abstract": "We compute explicitly the MTW tensor (or cross curvature) for the optimal\ntransport problem on $\\mathbb{R}^n$ with a cost function of form $\\mathsf{c}(x,\ny) = \\mathsf{u}(x^{\\mathfrak{t}}y)$, where $\\mathsf{u}$ is a scalar function\nwith inverse $\\mathsf{s}$, $x^{\\ft}y$ is a nondegenerate bilinear pairing of\nvectors $x, y$ belonging to an open subset of $\\mathbb{R}^n$. The condition\nthat the MTW-tensor vanishes on null vectors under the Kim-McCann metric is a\nfourth-order nonlinear ODE, which could be reduced to a linear ODE of the form\n$\\mathsf{s}^{(2)} - S\\mathsf{s}^{(1)} + P\\mathsf{s} = 0$ with constant\ncoefficients $P$ and $S$. The resulting inverse functions include {\\it Lambert}\nand {\\it generalized inverse hyperbolic\\slash trigonometric} functions. The\nsquare Euclidean metric and $\\log$-type costs are equivalent to instances of\nthese solutions. The optimal map for the family is also explicit. For cost\nfunctions of a similar form on a hyperboloid model of the hyperbolic space and\nunit sphere, we also express this tensor in terms of algebraic expressions in\nderivatives of $\\mathsf{s}$ using the Gauss-Codazzi equation, obtaining new\nfamilies of strictly regular costs for these manifolds, including new families\nof {\\it power function costs}. We analyze the $\\sinh$-type hyperbolic cost,\nproviding examples of $\\mathsf{c}$-convex functions and divergence.", "published": "2024-01-01", "categories": ["math.AP", "cs.IT", "cs.LG", "math.IT", "stat.ML", "58C05, 49Q22, 53C80, 57Z20, 57Z25, 68T05, 26B25"], "links": "http://arxiv.org/abs/2401.00953v1"}
{"title": "Tissue Artifact Segmentation and Severity Analysis for Automated Diagnosis Using Whole Slide Images", "author": "Galib Muhammad Shahriar Himel", "abstract": "Traditionally, pathological analysis and diagnosis are performed by manually\neyeballing glass slide specimens under a microscope by an expert. The whole\nslide image is the digital specimen produced from the glass slide. Whole slide\nimage enabled specimens to be observed on a computer screen and led to\ncomputational pathology where computer vision and artificial intelligence are\nutilized for automated analysis and diagnosis. With the current computational\nadvancement, the entire whole slide image can be analyzed autonomously without\nhuman supervision. However, the analysis could fail or lead to wrong diagnosis\nif the whole slide image is affected by tissue artifacts such as tissue fold or\nair bubbles depending on the severity. Existing artifact detection methods rely\non experts for severity assessment to eliminate artifact affected regions from\nthe analysis. This process is time consuming, exhausting and undermines the\ngoal of automated analysis or removal of artifacts without evaluating their\nseverity, which could result in the loss of diagnostically important data.\nTherefore, it is necessary to detect artifacts and then assess their severity\nautomatically. In this paper, we propose a system that incorporates severity\nevaluation with artifact detection utilizing convolutional neural networks. The\nproposed system uses DoubleUNet to segment artifacts and an ensemble network of\nsix fine tuned convolutional neural network models to determine severity. This\nmethod outperformed current state of the art in accuracy by 9 percent for\nartifact segmentation and achieved a strong correlation of 97 percent with the\nevaluation of pathologists for severity assessment. The robustness of the\nsystem was demonstrated using our proposed heterogeneous dataset and practical\nusability was ensured by integrating it with an automated analysis system.", "published": "2024-01-01", "categories": ["eess.IV", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01386v1"}
{"title": "Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP", "author": "Ruinan Jin, Chun-Yin Huang, Chenyu You, Xiaoxiao Li", "abstract": "In recent years, foundation models (FMs) have solidified their role as\ncornerstone advancements in the deep learning domain. By extracting intricate\npatterns from vast datasets, these models consistently achieve state-of-the-art\nresults across a spectrum of downstream tasks, all without necessitating\nextensive computational resources. Notably, MedCLIP, a vision-language\ncontrastive learning-based medical FM, has been designed using unpaired\nimage-text training. While the medical domain has often adopted unpaired\ntraining to amplify data, the exploration of potential security concerns linked\nto this approach hasn't kept pace with its practical usage. Notably, the\naugmentation capabilities inherent in unpaired training also indicate that\nminor label discrepancies can result in significant model deviations. In this\nstudy, we frame this label discrepancy as a backdoor attack problem. We further\nanalyze its impact on medical FMs throughout the FM supply chain. Our\nevaluation primarily revolves around MedCLIP, emblematic of medical FM\nemploying the unpaired strategy. We begin with an exploration of\nvulnerabilities in MedCLIP stemming from unpaired image-text matching, termed\nBadMatch. BadMatch is achieved using a modest set of wrongly labeled data.\nSubsequently, we disrupt MedCLIP's contrastive learning through\nBadDist-assisted BadMatch by introducing a Bad-Distance between the embeddings\nof clean and poisoned data. Additionally, combined with BadMatch and BadDist,\nthe attacking pipeline consistently fends off backdoor assaults across diverse\nmodel designs, datasets, and triggers. Also, our findings reveal that current\ndefense strategies are insufficient in detecting these latent threats in\nmedical FMs' supply chains.", "published": "2024-01-01", "categories": ["cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01911v1"}
{"title": "Multi-Lattice Sampling of Quantum Field Theories via Neural Operators", "author": "Bálint Máté, François Fleuret", "abstract": "We consider the problem of sampling discrete field configurations $\\phi$ from\nthe Boltzmann distribution $[d\\phi] Z^{-1} e^{-S[\\phi]}$, where $S$ is the\nlattice-discretization of the continuous Euclidean action $\\mathcal S$ of some\nquantum field theory. Since such densities arise as the approximation of the\nunderlying functional density $[\\mathcal D\\phi(x)] \\mathcal Z^{-1} e^{-\\mathcal\nS[\\phi(x)]}$, we frame the task as an instance of operator learning. In\nparticular, we propose to approximate a time-dependent operator $\\mathcal V_t$\nwhose time integral provides a mapping between the functional distributions of\nthe free theory $[\\mathcal D\\phi(x)] \\mathcal Z_0^{-1} e^{-\\mathcal\nS_{0}[\\phi(x)]}$ and of the target theory $[\\mathcal D\\phi(x)]\\mathcal\nZ^{-1}e^{-\\mathcal S[\\phi(x)]}$. Whenever a particular lattice is chosen, the\noperator $\\mathcal V_t$ can be discretized to a finite dimensional,\ntime-dependent vector field $V_t$ which in turn induces a continuous\nnormalizing flow between finite dimensional distributions over the chosen\nlattice. This flow can then be trained to be a diffeormorphism between the\ndiscretized free and target theories $[d\\phi] Z_0^{-1} e^{-S_{0}[\\phi]}$,\n$[d\\phi] Z^{-1}e^{-S[\\phi]}$. We run experiments on the $\\phi^4$-theory to\nexplore to what extent such operator-based flow architectures generalize to\nlattice sizes they were not trained on and show that pretraining on smaller\nlattices can lead to speedup over training only a target lattice size.", "published": "2024-01-01", "categories": ["cs.LG", "hep-lat", "stat.ML"], "links": "http://arxiv.org/abs/2401.00828v1"}
{"title": "Graph-Convolutional Autoencoder Ensembles for the Humanities, Illustrated with a Study of the American Slave Trade", "author": "Tom Lippincott", "abstract": "We introduce a graph-aware autoencoder ensemble framework, with associated\nformalisms and tooling, designed to facilitate deep learning for scholarship in\nthe humanities. By composing sub-architectures to produce a model isomorphic to\na humanistic domain we maintain interpretability while providing function\nsignatures for each sub-architectural choice, allowing both traditional and\ncomputational researchers to collaborate without disrupting established\npractices. We illustrate a practical application of our approach to a\nhistorical study of the American post-Atlantic slave trade, and make several\nspecific technical contributions: a novel hybrid graph-convolutional\nautoencoder mechanism, batching policies for common graph topologies, and\nmasking techniques for particular use-cases. The effectiveness of the framework\nfor broadening participation of diverse domains is demonstrated by a growing\nsuite of two dozen studies, both collaborations with humanists and established\ntasks from machine learning literature, spanning a variety of fields and data\nmodalities. We make performance comparisons of several different architectural\nchoices and conclude with an ambitious list of imminent next steps for this\nresearch.", "published": "2024-01-01", "categories": ["cs.LG", "cs.CL"], "links": "http://arxiv.org/abs/2401.00824v1"}
{"title": "GLIMPSE: Generalized Local Imaging with MLPs", "author": "AmirEhsan Khorashadizadeh, Valentin Debarnot, Tianlin Liu, Ivan Dokmanić", "abstract": "Deep learning is the current de facto state of the art in tomographic\nimaging. A common approach is to feed the result of a simple inversion, for\nexample the backprojection, to a convolutional neural network (CNN) which then\ncomputes the reconstruction. Despite strong results on 'in-distribution' test\ndata similar to the training data, backprojection from sparse-view data\ndelocalizes singularities, so these approaches require a large receptive field\nto perform well. As a consequence, they overfit to certain global structures\nwhich leads to poor generalization on out-of-distribution (OOD) samples.\nMoreover, their memory complexity and training time scale unfavorably with\nimage resolution, making them impractical for application at realistic clinical\nresolutions, especially in 3D: a standard U-Net requires a substantial 140GB of\nmemory and 2600 seconds per epoch on a research-grade GPU when training on\n1024x1024 images. In this paper, we introduce GLIMPSE, a local processing\nneural network for computed tomography which reconstructs a pixel value by\nfeeding only the measurements associated with the neighborhood of the pixel to\na simple MLP. While achieving comparable or better performance with successful\nCNNs like the U-Net on in-distribution test data, GLIMPSE significantly\noutperforms them on OOD samples while maintaining a memory footprint almost\nindependent of image resolution; 5GB memory suffices to train on 1024x1024\nimages. Further, we built GLIMPSE to be fully differentiable, which enables\nfeats such as recovery of accurate projection angles if they are out of\ncalibration.", "published": "2024-01-01", "categories": ["cs.CV", "cs.LG", "eess.IV"], "links": "http://arxiv.org/abs/2401.00816v1"}
{"title": "A review on different techniques used to combat the non-IID and heterogeneous nature of data in FL", "author": "Venkataraman Natarajan Iyer", "abstract": "Federated Learning (FL) is a machine-learning approach enabling collaborative\nmodel training across multiple decentralized edge devices that hold local data\nsamples, all without exchanging these samples. This collaborative process\noccurs under the supervision of a central server orchestrating the training or\nvia a peer-to-peer network. The significance of FL is particularly pronounced\nin industries such as healthcare and finance, where data privacy holds\nparamount importance. However, training a model under the Federated learning\nsetting brings forth several challenges, with one of the most prominent being\nthe heterogeneity of data distribution among the edge devices. The data is\ntypically non-independently and non-identically distributed (non-IID), thereby\npresenting challenges to model convergence. This report delves into the issues\narising from non-IID and heterogeneous data and explores current algorithms\ndesigned to address these challenges.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00809v1"}
{"title": "SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models", "author": "Jinglong Luo, Yehong Zhang, Jiaqi Zhang, Xin Mu, Hui Wang, Yue Yu, Zenglin Xu", "abstract": "With the growing use of large language models hosted on cloud platforms to\noffer inference services, privacy concerns are escalating, especially\nconcerning sensitive data like investment plans and bank account details.\nSecure Multi-Party Computing (SMPC) emerges as a promising solution to protect\nthe privacy of inference data and model parameters. However, the application of\nSMPC in Privacy-Preserving Inference (PPI) for large language models,\nparticularly those based on the Transformer architecture, often leads to\nconsiderable slowdowns or declines in performance. This is largely due to the\nmultitude of nonlinear operations in the Transformer architecture, which are\nnot well-suited to SMPC and are difficult to circumvent or optimize\neffectively. To address this concern, we introduce an advanced optimization\nframework called SecFormer, designed to strike an optimal balance between\nperformance and efficiency in PPI for Transformer models. By implementing\nknowledge distillation techniques, we successfully eliminate the high-cost\nexponential and maximum operations in PPI without sacrificing model\nperformance. Additionally, we have developed a suite of efficient SMPC\nprotocols that utilize segmented polynomials and Goldschmidt's method to handle\nother complex nonlinear functions within PPI, such as GeLU, LayerNorm, and\nSoftmax. Our extensive experiments reveal that SecFormer outperforms MPCFormer\nin performance, showing improvements of $5.6\\%$ and $24.2\\%$ for\nBERT$_{\\text{BASE}}$ and BERT$_{\\text{LARGE}}$, respectively. In terms of\nefficiency, SecFormer is 3.4 and 3.2 times faster than Puma, demonstrating its\neffectiveness and speed.", "published": "2024-01-01", "categories": ["cs.LG", "cs.CL", "cs.CR"], "links": "http://arxiv.org/abs/2401.00793v1"}
{"title": "Inferring Heterogeneous Treatment Effects of Crashes on Highway Traffic: A Doubly Robust Causal Machine Learning Approach", "author": "Shuang Li, Ziyuan Pu, Zhiyong Cui, Seunghyeon Lee, Xiucheng Guo, Dong Ngoduy", "abstract": "Highway traffic crashes exert a considerable impact on both transportation\nsystems and the economy. In this context, accurate and dependable emergency\nresponses are crucial for effective traffic management. However, the influence\nof crashes on traffic status varies across diverse factors and may be biased\ndue to selection bias. Therefore, there arises a necessity to accurately\nestimate the heterogeneous causal effects of crashes, thereby providing\nessential insights to facilitate individual-level emergency decision-making.\nThis paper proposes a novel causal machine learning framework to estimate the\ncausal effect of different types of crashes on highway speed. The Neyman-Rubin\nCausal Model (RCM) is employed to formulate this problem from a causal\nperspective. The Conditional Shapley Value Index (CSVI) is proposed based on\ncausal graph theory to filter adverse variables, and the Structural Causal\nModel (SCM) is then adopted to define the statistical estimand for causal\neffects. The treatment effects are estimated by Doubly Robust Learning (DRL)\nmethods, which combine doubly robust causal inference with classification and\nregression machine learning models. Experimental results from 4815 crashes on\nHighway Interstate 5 in Washington State reveal the heterogeneous treatment\neffects of crashes at varying distances and durations. The rear-end crashes\ncause more severe congestion and longer durations than other types of crashes,\nand the sideswipe crashes have the longest delayed impact. Additionally, the\nfindings show that rear-end crashes affect traffic greater at night, while\ncrash to objects has the most significant influence during peak hours.\nStatistical hypothesis tests, error metrics based on matched \"counterfactual\noutcomes\", and sensitive analyses are employed for assessment, and the results\nvalidate the accuracy and effectiveness of our method.", "published": "2024-01-01", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.00781v1"}
{"title": "Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study in the Autism Spectrum Disorder Therapy", "author": "Qin Yang", "abstract": "In recent years, edge computing has served as a paradigm that enables many\nfuture technologies like AI, Robotics, IoT, and high-speed wireless sensor\nnetworks (like 5G) by connecting cloud computing facilities and services to the\nend users. Especially in medical and healthcare applications, it provides\nremote patient monitoring and increases voluminous multimedia. From the\nrobotics angle, robot-assisted therapy (RAT) is an active-assistive robotic\ntechnology in rehabilitation robotics, attracting many researchers to study and\nbenefit people with disability like autism spectrum disorder (ASD) children.\nHowever, the main challenge of RAT is that the model capable of detecting the\naffective states of ASD people exists and can recall individual preferences.\nMoreover, involving expert diagnosis and recommendations to guide robots in\nupdating the therapy approach to adapt to different statuses and scenarios is a\ncrucial part of the ASD therapy process. This paper proposes the architecture\nof edge cognitive computing by combining human experts and assisted robots\ncollaborating in the same framework to help ASD patients with long-term\nsupport. By integrating the real-time computing and analysis of a new cognitive\nrobotic model for ASD therapy, the proposed architecture can achieve a seamless\nremote diagnosis, round-the-clock symptom monitoring, emergency warning,\ntherapy alteration, and advanced assistance.", "published": "2024-01-01", "categories": ["cs.RO", "cs.AI", "cs.DC", "cs.LG", "cs.MA"], "links": "http://arxiv.org/abs/2401.00776v1"}
{"title": "Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures", "author": "Dongwook Kim, Juyeon Park, Hee Cheol Chung, Seonghyun Jeong", "abstract": "Probabilistic mixture models are acknowledged as a valuable tool for\nunsupervised outlier detection owing to their interpretability and intuitive\ngrounding in statistical principles. Within this framework, Dirichlet process\nmixture models emerge as a compelling alternative to conventional finite\nmixture models for both clustering and outlier detection tasks. However,\ndespite their evident advantages, the widespread adoption of Dirichlet process\nmixture models in unsupervised outlier detection has been hampered by\nchallenges related to computational inefficiency and sensitivity to outliers\nduring the construction of detectors. To tackle these challenges, we propose a\nnovel outlier detection method based on ensembles of Dirichlet process Gaussian\nmixtures. The proposed method is a fully unsupervised algorithm that\ncapitalizes on random subspace and subsampling ensembles, not only ensuring\nefficient computation but also enhancing the robustness of the resulting\noutlier detector. Moreover, the proposed method leverages variational inference\nfor Dirichlet process mixtures to ensure efficient and fast computation.\nEmpirical studies with benchmark datasets demonstrate that our method\noutperforms existing approaches for unsupervised outlier detection.", "published": "2024-01-01", "categories": ["cs.LG", "cs.AI", "stat.ML"], "links": "http://arxiv.org/abs/2401.00773v1"}
{"title": "Strong Transitivity Relations and Graph Neural Networks", "author": "Yassin Mohamadi, Mostafa Haghir Chehreghani", "abstract": "Local neighborhoods play a crucial role in embedding generation in\ngraph-based learning. It is commonly believed that nodes ought to have\nembeddings that resemble those of their neighbors. In this research, we try to\ncarefully expand the concept of similarity from nearby neighborhoods to the\nentire graph. We provide an extension of similarity that is based on\ntransitivity relations, which enables Graph Neural Networks (GNNs) to capture\nboth global similarities and local similarities over the whole graph. We\nintroduce Transitivity Graph Neural Network (TransGNN), which more than local\nnode similarities, takes into account global similarities by distinguishing\nstrong transitivity relations from weak ones and exploiting them. We evaluate\nour model over several real-world datasets and showed that it considerably\nimproves the performance of several well-known GNN models, for tasks such as\nnode classification.", "published": "2024-01-01", "categories": ["cs.SI", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01384v1"}
{"title": "MPRE: Multi-perspective Patient Representation Extractor for Disease Prediction", "author": "Ziyue Yu, Jiayi Wang, Wuman Luo, Rita Tse, Giovanni Pau", "abstract": "Patient representation learning based on electronic health records (EHR) is a\ncritical task for disease prediction. This task aims to effectively extract\nuseful information on dynamic features. Although various existing works have\nachieved remarkable progress, the model performance can be further improved by\nfully extracting the trends, variations, and the correlation between the trends\nand variations in dynamic features. In addition, sparse visit records limit the\nperformance of deep learning models. To address these issues, we propose the\nMulti-perspective Patient Representation Extractor (MPRE) for disease\nprediction. Specifically, we propose Frequency Transformation Module (FTM) to\nextract the trend and variation information of dynamic features in the\ntime-frequency domain, which can enhance the feature representation. In the 2D\nMulti-Extraction Network (2D MEN), we form the 2D temporal tensor based on\ntrend and variation. Then, the correlations between trend and variation are\ncaptured by the proposed dilated operation. Moreover, we propose the\nFirst-Order Difference Attention Mechanism (FODAM) to calculate the\ncontributions of differences in adjacent variations to the disease diagnosis\nadaptively. To evaluate the performance of MPRE and baseline methods, we\nconduct extensive experiments on two real-world public datasets. The experiment\nresults show that MPRE outperforms state-of-the-art baseline methods in terms\nof AUROC and AUPRC.", "published": "2024-01-01", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.00756v1"}
{"title": "Saliency-Aware Regularized Graph Neural Network", "author": "Wenjie Pei, Weina Xu, Zongze Wu, Weichao Li, Jinfan Wang, Guangming Lu, Xiangrong Wang", "abstract": "The crux of graph classification lies in the effective representation\nlearning for the entire graph. Typical graph neural networks focus on modeling\nthe local dependencies when aggregating features of neighboring nodes, and\nobtain the representation for the entire graph by aggregating node features.\nSuch methods have two potential limitations: 1) the global node saliency w.r.t.\ngraph classification is not explicitly modeled, which is crucial since\ndifferent nodes may have different semantic relevance to graph classification;\n2) the graph representation directly aggregated from node features may have\nlimited effectiveness to reflect graph-level information. In this work, we\npropose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph\nclassification, which consists of two core modules: 1) a traditional graph\nneural network serving as the backbone for learning node features and 2) the\nGraph Neural Memory designed to distill a compact graph representation from\nnode features of the backbone. We first estimate the global node saliency by\nmeasuring the semantic similarity between the compact graph representation and\nnode features. Then the learned saliency distribution is leveraged to\nregularize the neighborhood aggregation of the backbone, which facilitates the\nmessage passing of features for salient nodes and suppresses the less relevant\nnodes. Thus, our model can learn more effective graph representation. We\ndemonstrate the merits of SAR-GNN by extensive experiments on seven datasets\nacross various types of graph data. Code will be released.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00755v1"}
{"title": "Harmonizing Covariance and Expressiveness for Deep Hamiltonian Regression in Crystalline Material Research: a Hybrid Cascaded Regression Framework", "author": "Shi Yin, Xudong Zhu, Tianyu Gao, Haochong Zhang, Feng Wu, Lixin He", "abstract": "Deep learning for Hamiltonian regression of quantum systems in material\nresearch necessitates satisfying the covariance laws, among which achieving\nSO(3)-equivariance without sacrificing the expressiveness of networks remains\nan elusive challenge due to the restriction to non-linear mappings on\nguaranteeing theoretical equivariance. To alleviate the\ncovariance-expressiveness dilemma, we propose a hybrid framework with two\ncascaded regression stages. The first stage, with a theoretically-guaranteed\ncovariant neural network modeling symmetry properties of 3D atom systems,\nyields theoretically covariant features and baseline Hamiltonian predictions,\nassisting the second stage in learning covariance. Meanwhile, the second stage,\npowered by a non-linear 3D graph Transformer network we propose for structural\nmodeling of 3D atomic systems, refines the first stage's output as a\nfine-grained prediction of Hamiltonians with better expressiveness capability.\nThe combination of a theoretically covariant yet inevitably less expressive\nmodel with a highly expressive non-linear network enables precise,\ngeneralizable predictions while maintaining robust covariance under coordinate\ntransformations. Our method achieves state-of-the-art performance in\nHamiltonian prediction for electronic structure calculations, confirmed through\nexperiments on five crystalline material databases.", "published": "2024-01-01", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG"], "links": "http://arxiv.org/abs/2401.00744v3"}
{"title": "Searching, fast and slow, through product catalogs", "author": "Dayananda Ubrangala, Juhi Sharma, Sharath Kumar Rangappa, Kiran R, Ravi Prasad Kondapalli, Laurent Boué", "abstract": "String matching algorithms in the presence of abbreviations, such as in Stock\nKeeping Unit (SKU) product catalogs, remains a relatively unexplored topic. In\nthis paper, we present a unified architecture for SKU search that provides both\na real-time suggestion system (based on a Trie data structure) as well as a\nlower latency search system (making use of character level TF-IDF in\ncombination with language model vector embeddings) where users initiate the\nsearch process explicitly. We carry out ablation studies that justify designing\na complex search system composed of multiple components to address the delicate\ntrade-off between speed and accuracy. Using SKU search in the Dynamics CRM as\nan example, we show how our system vastly outperforms, in all aspects, the\nresults provided by the default search engine. Finally, we show how SKU\ndescriptions may be enhanced via generative text models (using gpt-3.5-turbo)\nso that the consumers of the search results may get more context and a\ngenerally better experience when presented with the results of their SKU\nsearch.", "published": "2024-01-01", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.SE"], "links": "http://arxiv.org/abs/2401.00737v1"}
{"title": "Diffusion Models, Image Super-Resolution And Everything: A Survey", "author": "Brian B. Moser, Arundhati S. Shanbhag, Federico Raue, Stanislav Frolov, Sebastian Palacio, Andreas Dengel", "abstract": "Diffusion Models (DMs) represent a significant advancement in image\nSuper-Resolution (SR), aligning technical image quality more closely with human\npreferences and expanding SR applications. DMs address critical limitations of\nprevious methods, enhancing overall realism and details in SR images. However,\nDMs suffer from color-shifting issues, and their high computational costs call\nfor efficient sampling alternatives, underscoring the challenge of balancing\ncomputational efficiency and image quality. This survey gives an overview of\nDMs applied to image SR and offers a detailed analysis that underscores the\nunique characteristics and methodologies within this domain, distinct from\nbroader existing reviews in the field. It presents a unified view of DM\nfundamentals and explores research directions, including alternative input\ndomains, conditioning strategies, guidance, corruption spaces, and zero-shot\nmethods. This survey provides insights into the evolution of image SR with DMs,\naddressing current trends, challenges, and future directions in this rapidly\nevolving field.", "published": "2024-01-01", "categories": ["cs.CV", "cs.AI", "cs.GL", "cs.LG", "cs.MM"], "links": "http://arxiv.org/abs/2401.00736v1"}
{"title": "MultiFusionNet: Multilayer Multimodal Fusion of Deep Neural Networks for Chest X-Ray Image Classification", "author": "Saurabh Agarwal, K. V. Arya, Yogesh Kumar Meena", "abstract": "Chest X-ray imaging is a critical diagnostic tool for identifying pulmonary\ndiseases. However, manual interpretation of these images is time-consuming and\nerror-prone. Automated systems utilizing convolutional neural networks (CNNs)\nhave shown promise in improving the accuracy and efficiency of chest X-ray\nimage classification. While previous work has mainly focused on using feature\nmaps from the final convolution layer, there is a need to explore the benefits\nof leveraging additional layers for improved disease classification. Extracting\nrobust features from limited medical image datasets remains a critical\nchallenge. In this paper, we propose a novel deep learning-based multilayer\nmultimodal fusion model that emphasizes extracting features from different\nlayers and fusing them. Our disease detection model considers the\ndiscriminatory information captured by each layer. Furthermore, we propose the\nfusion of different-sized feature maps (FDSFM) module to effectively merge\nfeature maps from diverse layers. The proposed model achieves a significantly\nhigher accuracy of 97.21% and 99.60% for both three-class and two-class\nclassifications, respectively. The proposed multilayer multimodal fusion model,\nalong with the FDSFM module, holds promise for accurate disease classification\nand can also be extended to other disease classifications in chest X-ray\nimages.", "published": "2024-01-01", "categories": ["eess.IV", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.00728v1"}
{"title": "Predicting Infant Brain Connectivity with Federated Multi-Trajectory GNNs using Scarce Data", "author": "Michalis Pistos, Islem Rekik", "abstract": "The understanding of the convoluted evolution of infant brain networks during\nthe first postnatal year is pivotal for identifying the dynamics of early brain\nconnectivity development. Existing deep learning solutions suffer from three\nmajor limitations. First, they cannot generalize to multi-trajectory prediction\ntasks, where each graph trajectory corresponds to a particular imaging modality\nor connectivity type (e.g., T1-w MRI). Second, existing models require\nextensive training datasets to achieve satisfactory performance which are often\nchallenging to obtain. Third, they do not efficiently utilize incomplete time\nseries data. To address these limitations, we introduce FedGmTE-Net++, a\nfederated graph-based multi-trajectory evolution network. Using the power of\nfederation, we aggregate local learnings among diverse hospitals with limited\ndatasets. As a result, we enhance the performance of each hospital's local\ngenerative model, while preserving data privacy. The three key innovations of\nFedGmTE-Net++ are: (i) presenting the first federated learning framework\nspecifically designed for brain multi-trajectory evolution prediction in a\ndata-scarce environment, (ii) incorporating an auxiliary regularizer in the\nlocal objective function to exploit all the longitudinal brain connectivity\nwithin the evolution trajectory and maximize data utilization, (iii)\nintroducing a two-step imputation process, comprising a preliminary KNN-based\nprecompletion followed by an imputation refinement step that employs regressors\nto improve similarity scores and refine imputations. Our comprehensive\nexperimental results showed the outperformance of FedGmTE-Net++ in brain\nmulti-trajectory prediction from a single baseline graph in comparison with\nbenchmark methods.", "published": "2024-01-01", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01383v1"}
{"title": "A Survey on Graph Neural Networks in Intelligent Transportation Systems", "author": "Hourun Li, Yusheng Zhao, Zhengyang Mao, Yifang Qin, Zhiping Xiao, Jiaqi Feng, Yiyang Gu, Wei Ju, Xiao Luo, Ming Zhang", "abstract": "Intelligent Transportation System (ITS) is vital in improving traffic\ncongestion, reducing traffic accidents, optimizing urban planning, etc.\nHowever, due to the complexity of the traffic network, traditional machine\nlearning and statistical methods are relegated to the background. With the\nadvent of the artificial intelligence era, many deep learning frameworks have\nmade remarkable progress in various fields and are now considered effective\nmethods in many areas. As a deep learning method, Graph Neural Networks (GNNs)\nhave emerged as a highly competitive method in the ITS field since 2019 due to\ntheir strong ability to model graph-related problems. As a result, more and\nmore scholars pay attention to the applications of GNNs in transportation\ndomains, which have shown excellent performance. However, most of the research\nin this area is still concentrated on traffic forecasting, while other ITS\ndomains, such as autonomous vehicles and urban planning, still require more\nattention. This paper aims to review the applications of GNNs in six\nrepresentative and emerging ITS domains: traffic forecasting, autonomous\nvehicles, traffic signal control, transportation safety, demand prediction, and\nparking management. We have reviewed extensive graph-related studies from 2018\nto 2023, summarized their methods, features, and contributions, and presented\nthem in informative tables or lists. Finally, we have identified the challenges\nof applying GNNs to ITS and suggested potential future directions.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00713v2"}
{"title": "An attempt to generate new bridge types from latent space of generative adversarial network", "author": "Hongjun Zhang", "abstract": "Try to generate new bridge types using generative artificial intelligence\ntechnology. Symmetric structured image dataset of three-span beam bridge, arch\nbridge, cable-stayed bridge and suspension bridge are used . Based on Python\nprogramming language, TensorFlow and Keras deep learning platform framework ,\nas well as Wasserstein loss function and Lipschitz constraints, generative\nadversarial network is constructed and trained. From the obtained low\ndimensional bridge-type latent space sampling, new bridge types with asymmetric\nstructures can be generated. Generative adversarial network can create new\nbridge types by organically combining different structural components on the\nbasis of human original bridge types. It has a certain degree of human original\nability. Generative artificial intelligence technology can open up imagination\nspace and inspire humanity.", "published": "2024-01-01", "categories": ["cs.LG", "cs.AI", "cs.CV"], "links": "http://arxiv.org/abs/2401.00700v1"}
{"title": "Large Language Models aren't all that you need", "author": "Kiran Voderhobli Holla, Chaithanya Kumar, Aryan Singh", "abstract": "This paper describes the architecture and systems built towards solving the\nSemEval 2023 Task 2: MultiCoNER II (Multilingual Complex Named Entity\nRecognition) [1]. We evaluate two approaches (a) a traditional Conditional\nRandom Fields model and (b) a Large Language Model (LLM) fine-tuned with a\ncustomized head and compare the two approaches. The novel ideas explored are:\n1) Decaying auxiliary loss (with residual) - where we train the model on an\nauxiliary task of Coarse-Grained NER and include this task as a part of the\nloss function 2) Triplet token blending - where we explore ways of blending the\nembeddings of neighboring tokens in the final NER layer prior to prediction 3)\nTask-optimal heads - where we explore a variety of custom heads and learning\nrates for the final layer of the LLM. We also explore multiple LLMs including\nGPT-3 and experiment with a variety of dropout and other hyperparameter\nsettings before arriving at our final model which achieves micro & macro f1 of\n0.85/0.84 (on dev) and 0.67/0.61 on the test data . We show that while\npre-trained LLMs, by themselves, bring about a large improvement in scores as\ncompared to traditional models, we also demonstrate that tangible improvements\nto the Macro-F1 score can be made by augmenting the LLM with additional\nfeature/loss/model engineering techniques described above.", "published": "2024-01-01", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.00698v1"}
{"title": "Self-supervised learning for skin cancer diagnosis with limited training data", "author": "Hamish Haggerty, Rohitash Chandra", "abstract": "Cancer diagnosis is a well-studied problem in machine learning since early\ndetection of cancer is often the determining factor in prognosis. Supervised\ndeep learning achieves excellent results in cancer image classification,\nusually through transfer learning. However, these models require large amounts\nof labelled data and for several types of cancer, large labelled datasets do\nnot exist. In this paper, we demonstrate that a model pre-trained using a\nself-supervised learning algorithm known as Barlow Twins can outperform the\nconventional supervised transfer learning pipeline. We juxtapose two base\nmodels: i) pretrained in a supervised fashion on ImageNet; ii) pretrained in a\nself-supervised fashion on ImageNet. Both are subsequently fine tuned on a\nsmall labelled skin lesion dataset and evaluated on a large test set. We\nachieve a mean test accuracy of 70\\% for self-supervised transfer in comparison\nto 66\\% for supervised transfer. Interestingly, boosting performance further is\npossible by self-supervised pretraining a second time (on unlabelled skin\nlesion images) before subsequent fine tuning. This hints at an alternative path\nto collecting more labelled data in settings where this is challenging - namely\njust collecting more unlabelled images. Our framework is applicable to cancer\nimage classification models in the low-labelled data regime.", "published": "2024-01-01", "categories": ["eess.IV", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.00692v1"}
{"title": "Stochastic Gradient Descent for Additive Nonparametric Regression", "author": "Xin Chen, Jason M. Klusowski", "abstract": "This paper introduces an iterative algorithm designed to train additive\nmodels with favorable memory storage and computational requirements. The\nalgorithm can be viewed as the functional counterpart of stochastic gradient\ndescent, applied to the coefficients of a truncated basis expansion of the\ncomponent functions. We show that the resulting estimator satisfies an oracle\ninequality that allows for model mispecification. In the well-specified\nsetting, by choosing the learning rate carefully across three distinct stages\nof training, we prove that its risk is minimax optimal in terms of the\ndependence on the dimensionality of the data and the size of the training\nsample.", "published": "2024-01-01", "categories": ["stat.ML", "cs.LG"], "links": "http://arxiv.org/abs/2401.00691v1"}
{"title": "Inferring community structure in attributed hypergraphs using stochastic block models", "author": "Kazuki Nakajima, Takeaki Uno", "abstract": "Hypergraphs are a representation of complex systems involving interactions\namong more than two entities and allow to investigation of higher-order\nstructure and dynamics in real-world complex systems. Community structure is a\ncommon property observed in empirical networks in various domains. Stochastic\nblock models have been employed to investigate community structure in networks.\nNode attribute data, often accompanying network data, has been found to\npotentially enhance the learning of community structure in dyadic networks. In\nthis study, we develop a statistical framework that incorporates node attribute\ndata into the learning of community structure in a hypergraph, employing a\nstochastic block model. We demonstrate that our model, which we refer to as\nHyperNEO, enhances the learning of community structure in synthetic and\nempirical hypergraphs when node attributes are sufficiently associated with the\ncommunities. Furthermore, we found that applying a dimensionality reduction\nmethod, UMAP, to the learned representations obtained using stochastic block\nmodels, including our model, maps nodes into a two-dimensional vector space\nwhile largely preserving community structure in empirical hypergraphs. We\nexpect that our framework will broaden the investigation and understanding of\nhigher-order community structure in real-world complex systems.", "published": "2024-01-01", "categories": ["cs.SI", "cs.LG"], "links": "http://arxiv.org/abs/2401.00688v1"}
{"title": "Communication-Efficient Federated Learning for LEO Constellations Integrated with HAPs Using Hybrid NOMA-OFDM", "author": "Mohamed Elmahallawy, Tie Luo, Khaled Ramadan", "abstract": "Space AI has become increasingly important and sometimes even necessary for\ngovernment, businesses, and society. An active research topic under this\nmission is integrating federated learning (FL) with satellite communications\n(SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively\ntrain a machine learning model. However, the special communication environment\nof SatCom leads to a very slow FL training process up to days and weeks. This\npaper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO\nsatellites, that (1) utilizes high-altitude platforms (HAPs) as distributed\nparameter servers (PS) to enhance satellite visibility, and (2) introduces\nnon-orthogonal multiple access (NOMA) into LEO to enable fast and\nbandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a\nnew communication topology that exploits HAPs to bridge satellites among\ndifferent orbits to mitigate the Doppler shift, and (4) a new FL model\naggregation scheme that optimally balances models between different orbits and\nshells. Moreover, we (5) derive a closed-form expression of the outage\nprobability for satellites in near and far shells, as well as for the entire\nsystem. Our extensive simulations have validated the mathematical analysis and\ndemonstrated the superior performance of NomaFedHAP in achieving fast and\nefficient FL model convergence with high accuracy as compared to the\nstate-of-the-art.", "published": "2024-01-01", "categories": ["cs.LG", "cs.AI", "cs.DC"], "links": "http://arxiv.org/abs/2401.00685v1"}
{"title": "A Temporal Filter to Extract Doped Conducting Polymer Information Features from an Electronic Nose", "author": "Wiem Haj Ammar, Aicha Boujnah, Antoine Baron, Aimen Boubaker, Adel Kalboussi, Kamal Lmimouni, Sebastien Pecqueur", "abstract": "Identifying relevant machine-learning features for multi-sensing platforms is\nboth an applicative limitation to recognize environments and a necessity to\ninterpret the physical relevance of transducers' complementarity in their\ninformation processing. Particularly for long acquisitions, feature extraction\nmust be fully automatized without human intervention and resilient to\nperturbations without increasing significantly the computational cost of a\nclassifier. In this study, we investigate on the relative resistance and\ncurrent modulation of a 24-dimensional conductimetric electronic nose, which\nuses the exponential moving average as a floating reference in a low-cost\ninformation descriptor for environment recognition. In particular, we\nidentified that depending on the structure of a linear classifier, the 'modema'\ndescriptor is optimized for different material sensing elements' contributions\nto classify information patterns. The low-pass filtering optimization leads to\nopposite behaviors between unsupervised and supervised learning: the latter one\nfavors longer integration of the reference, allowing to recognize five\ndifferent classes over 90%, while the first one prefers using the latest events\nas its reference to clusterize patterns by environment nature. Its electronic\nimplementation shall greatly diminish the computational requirements of\nconductimetric electronic noses for on-board environment recognition without\nhuman supervision.", "published": "2024-01-01", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "links": "http://arxiv.org/abs/2401.00684v1"}
{"title": "Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning", "author": "Mohamad Abed El Rahman Hammoud, Naila Raboudi, Edriss S. Titi, Omar Knio, Ibrahim Hoteit", "abstract": "Data assimilation (DA) plays a pivotal role in diverse applications, ranging\nfrom climate predictions and weather forecasts to trajectory planning for\nautonomous vehicles. A prime example is the widely used ensemble Kalman filter\n(EnKF), which relies on linear updates to minimize variance among the ensemble\nof forecast states. Recent advancements have seen the emergence of deep\nlearning approaches in this domain, primarily within a supervised learning\nframework. However, the adaptability of such models to untrained scenarios\nremains a challenge. In this study, we introduce a novel DA strategy that\nutilizes reinforcement learning (RL) to apply state corrections using full or\npartial observations of the state variables. Our investigation focuses on\ndemonstrating this approach to the chaotic Lorenz '63 system, where the agent's\nobjective is to minimize the root-mean-squared error between the observations\nand corresponding forecast states. Consequently, the agent develops a\ncorrection strategy, enhancing model forecasts based on available system state\nobservations. Our strategy employs a stochastic action policy, enabling a Monte\nCarlo-based DA framework that relies on randomly sampling the policy to\ngenerate an ensemble of assimilated realizations. Results demonstrate that the\ndeveloped RL algorithm performs favorably when compared to the EnKF.\nAdditionally, we illustrate the agent's capability to assimilate non-Gaussian\ndata, addressing a significant limitation of the EnKF.", "published": "2024-01-01", "categories": ["math.DS", "cs.AI", "cs.LG", "physics.ao-ph"], "links": "http://arxiv.org/abs/2401.00916v1"}
{"title": "General-purpose foundation models for increased autonomy in robot-assisted surgery", "author": "Samuel Schmidgall, Ji Woong Kim, Alan Kuntz, Ahmed Ezzat Ghazi, Axel Krieger", "abstract": "The dominant paradigm for end-to-end robot learning focuses on optimizing\ntask-specific objectives that solve a single robotic problem such as picking up\nan object or reaching a target position. However, recent work on high-capacity\nmodels in robotics has shown promise toward being trained on large collections\nof diverse and task-agnostic datasets of video demonstrations. These models\nhave shown impressive levels of generalization to unseen circumstances,\nespecially as the amount of data and the model complexity scale. Surgical robot\nsystems that learn from data have struggled to advance as quickly as other\nfields of robot learning for a few reasons: (1) there is a lack of existing\nlarge-scale open-source data to train models, (2) it is challenging to model\nthe soft-body deformations that these robots work with during surgery because\nsimulation cannot match the physical and visual complexity of biological\ntissue, and (3) surgical robots risk harming patients when tested in clinical\ntrials and require more extensive safety measures. This perspective article\naims to provide a path toward increasing robot autonomy in robot-assisted\nsurgery through the development of a multi-modal, multi-task,\nvision-language-action model for surgical robots. Ultimately, we argue that\nsurgical robots are uniquely positioned to benefit from general-purpose models\nand provide three guiding actions toward increased autonomy in robot-assisted\nsurgery.", "published": "2024-01-01", "categories": ["cs.RO", "cs.LG", "q-bio.TO"], "links": "http://arxiv.org/abs/2401.00678v1"}
{"title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training", "author": "Haodong Li, Gelei Deng, Yi Liu, Kailong Wang, Yuekang Li, Tianwei Zhang, Yang Liu, Guoai Xu, Guosheng Xu, Haoyu Wang", "abstract": "Pre-training, which utilizes extensive and varied datasets, is a critical\nfactor in the success of Large Language Models (LLMs) across numerous\napplications. However, the detailed makeup of these datasets is often not\ndisclosed, leading to concerns about data security and potential misuse. This\nis particularly relevant when copyrighted material, still under legal\nprotection, is used inappropriately, either intentionally or unintentionally,\ninfringing on the rights of the authors.\n  In this paper, we introduce a detailed framework designed to detect and\nassess the presence of content from potentially copyrighted books within the\ntraining datasets of LLMs. This framework also provides a confidence estimation\nfor the likelihood of each content sample's inclusion. To validate our\napproach, we conduct a series of simulated experiments, the results of which\naffirm the framework's effectiveness in identifying and addressing instances of\ncontent misuse in LLM training processes. Furthermore, we investigate the\npresence of recognizable quotes from famous literary works within these\ndatasets. The outcomes of our study have significant implications for ensuring\nthe ethical use of copyrighted materials in the development of LLMs,\nhighlighting the need for more transparent and responsible data management\npractices in this field.", "published": "2024-01-01", "categories": ["cs.CR", "cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.00676v1"}
{"title": "New Sample Complexity Bounds for (Regularized) Sample Average Approximation in Several Heavy-Tailed, Non-Lipschitzian, and High-Dimensional Cases", "author": "Hongcheng Liu, Jindong Tong", "abstract": "We study the sample complexity of sample average approximation (SAA) and its\nsimple variations, referred to as the regularized SAA (RSAA), in solving convex\nand strongly convex stochastic programming (SP) problems under\nheavy-tailed-ness, non-Lipschitz-ness, and/or high dimensionality. The presence\nof such irregularities underscores critical vacua in the literature. In\nresponse, this paper presents three sets of results: First, we show that the\n(R)SAA is effective even if the objective function is not necessarily Lipschitz\nand the underlying distribution admits some bounded central moments only at\n(near-)optimal solutions. Second, when the SP's objective function is the sum\nof a smooth term and a Lipschitz term, we prove that the (R)SAA's sample\ncomplexity is completely independent from any complexity measures (e.g., the\ncovering number) of the feasible region. Third, we explicate the (R)SAA's\nsample complexities with regard to the dependence on dimensionality $d$: When\nsome $p$th ($p\\geq 2$) central moment of the underlying distribution is\nbounded, we show that the required sample size grows at a rate no worse than\n$\\mathcal O\\left(p d^{2/p}\\right)$ under any one of the three structural\nassumptions: (i) strong convexity w.r.t. the $q$-norm ($q\\geq 1$); (ii) the\ncombination of restricted strong convexity and sparsity; and (iii) a\ndimension-insensitive $q$-norm of an optimal solution. In both cases of (i) and\n(iii), it is further required that $p\\leq q/(q-1)$. As a direct implication,\nthe (R)SAA's complexity becomes (poly-)logarithmic in $d$, whenever $p\\geq\nc\\cdot \\ln d$ is admissible for some constant $c>0$. These new results deviate\nfrom the SAA's typical sample complexities that grow polynomially with $d$.\nPart of our proof is based on the average-replace-one (RO) stability, which\nappears to be novel for the (R)SAA's analyses.", "published": "2024-01-01", "categories": ["math.OC", "cs.LG", "math.PR", "math.ST", "stat.TH", "90C15, 90C25, 60-08"], "links": "http://arxiv.org/abs/2401.00664v1"}
{"title": "Point Cloud in the Air", "author": "Yulin Shao, Chenghong Bian, Li Yang, Qianqian Yang, Zhaoyang Zhang, Deniz Gunduz", "abstract": "Acquisition and processing of point clouds (PCs) is a crucial enabler for\nmany emerging applications reliant on 3D spatial data, such as robot\nnavigation, autonomous vehicles, and augmented reality. In most scenarios, PCs\nacquired by remote sensors must be transmitted to an edge server for fusion,\nsegmentation, or inference. Wireless transmission of PCs not only puts on\nincreased burden on the already congested wireless spectrum, but also confronts\na unique set of challenges arising from the irregular and unstructured nature\nof PCs. In this paper, we meticulously delineate these challenges and offer a\ncomprehensive examination of existing solutions while candidly acknowledging\ntheir inherent limitations. In response to these intricacies, we proffer four\npragmatic solution frameworks, spanning advanced techniques, hybrid schemes,\nand distributed data aggregation approaches. In doing so, our goal is to chart\na path toward efficient, reliable, and low-latency wireless PC transmission.", "published": "2024-01-01", "categories": ["cs.IT", "cs.LG", "cs.MM", "eess.SP", "math.IT"], "links": "http://arxiv.org/abs/2401.00658v1"}
{"title": "On Discprecncies between Perturbation Evaluations of Graph Neural Network Attributions", "author": "Razieh Rezaei, Alireza Dizaji, Ashkan Khakzar, Anees Kazi, Nassir Navab, Daniel Rueckert", "abstract": "Neural networks are increasingly finding their way into the realm of graphs\nand modeling relationships between features. Concurrently graph neural network\nexplanation approaches are being invented to uncover relationships between the\nnodes of the graphs. However, there is a disparity between the existing\nattribution methods, and it is unclear which attribution to trust. Therefore\nresearch has introduced evaluation experiments that assess them from different\nperspectives. In this work, we assess attribution methods from a perspective\nnot previously explored in the graph domain: retraining. The core idea is to\nretrain the network on important (or not important) relationships as identified\nby the attributions and evaluate how networks can generalize based on these\nrelationships. We reformulate the retraining framework to sidestep issues\nlurking in the previous formulation and propose guidelines for correct\nanalysis. We run our analysis on four state-of-the-art GNN attribution methods\nand five synthetic and real-world graph classification datasets. The analysis\nreveals that attributions perform variably depending on the dataset and the\nnetwork. Most importantly, we observe that the famous GNNExplainer performs\nsimilarly to an arbitrary designation of edge importance. The study concludes\nthat the retraining evaluation cannot be used as a generalized benchmark and\nrecommends it as a toolset to evaluate attributions on a specifically addressed\nnetwork, dataset, and sparsity.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00633v1"}
{"title": "Adversarially Trained Actor Critic for offline CMDPs", "author": "Honghao Wei, Xiyue Peng, Xin Liu, Arnob Ghosh", "abstract": "We propose a Safe Adversarial Trained Actor Critic (SATAC) algorithm for\noffline reinforcement learning (RL) with general function approximation in the\npresence of limited data coverage. SATAC operates as a two-player Stackelberg\ngame featuring a refined objective function. The actor (leader player)\noptimizes the policy against two adversarially trained value critics (follower\nplayers), who focus on scenarios where the actor's performance is inferior to\nthe behavior policy. Our framework provides both theoretical guarantees and a\nrobust deep-RL implementation. Theoretically, we demonstrate that when the\nactor employs a no-regret optimization oracle, SATAC achieves two guarantees:\n(i) For the first time in the offline RL setting, we establish that SATAC can\nproduce a policy that outperforms the behavior policy while maintaining the\nsame level of safety, which is critical to designing an algorithm for offline\nRL. (ii) We demonstrate that the algorithm guarantees policy improvement across\na broad range of hyperparameters, indicating its practical robustness.\nAdditionally, we offer a practical version of SATAC and compare it with\nexisting state-of-the-art offline safe-RL algorithms in continuous control\nenvironments. SATAC outperforms all baselines across a range of tasks, thus\nvalidating the theoretical performance.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00629v1"}
{"title": "Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models", "author": "Guangji Bai, Zheng Chai, Chen Ling, Shiyu Wang, Jiaying Lu, Nan Zhang, Tingwei Shi, Ziyang Yu, Mengdan Zhu, Yifei Zhang, Carl Yang, Yue Cheng, Liang Zhao", "abstract": "The burgeoning field of Large Language Models (LLMs), exemplified by\nsophisticated models like OpenAI's ChatGPT, represents a significant\nadvancement in artificial intelligence. These models, however, bring forth\nsubstantial challenges in the high consumption of computational, memory,\nenergy, and financial resources, especially in environments with limited\nresource capabilities. This survey aims to systematically address these\nchallenges by reviewing a broad spectrum of techniques designed to enhance the\nresource efficiency of LLMs. We categorize methods based on their optimization\nfocus: computational, memory, energy, financial, and network resources and\ntheir applicability across various stages of an LLM's lifecycle, including\narchitecture design, pretraining, finetuning, and system design. Additionally,\nthe survey introduces a nuanced categorization of resource efficiency\ntechniques by their specific resource types, which uncovers the intricate\nrelationships and mappings between various resources and corresponding\noptimization techniques. A standardized set of evaluation metrics and datasets\nis also presented to facilitate consistent and fair comparisons across\ndifferent models and techniques. By offering a comprehensive overview of the\ncurrent sota and identifying open research avenues, this survey serves as a\nfoundational reference for researchers and practitioners, aiding them in\ndeveloping more sustainable and efficient LLMs in a rapidly evolving landscape.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00625v2"}
{"title": "Federated Class-Incremental Learning with New-Class Augmented Self-Distillation", "author": "Zhiyuan Wu, Tianliu He, Sheng Sun, Yuwei Wang, Min Liu, Bo Gao, Xuefeng Jiang", "abstract": "Federated Learning (FL) enables collaborative model training among\nparticipants while guaranteeing the privacy of raw data. Mainstream FL\nmethodologies overlook the dynamic nature of real-world data, particularly its\ntendency to grow in volume and diversify in classes over time. This oversight\nresults in FL methods suffering from catastrophic forgetting, where models\ninadvertently discard previously learned information upon assimilating new\ndata. In response to this challenge, we propose a novel Federated\nClass-Incremental Learning (FCIL) method, named FCIL with New-Class Augmented\nSelf-Distillation (FedNASD). FedNASD combines new class scores, which are\ninferred from current models, with historical models' predictions. Based on the\ncombined past and present knowledge, it incorporates self-distillation over\nmodels on clients, aiming to achieve effective knowledge transfer from\nhistorical models to current models. Theoretical analysis demonstrates that\nFedNASD is equivalent to modeling old class scores as conditional probabilities\nin the absence of new classes. Additionally, it reconciles the predictions of\nnew classes with current models to refine the conditional probabilities of\nhistorical scores where new classes do not exist. Empirical experiments\ndemonstrate the superiority of FedNASD over four baseline algorithms in\nreducing the average forgetting rate and boosting global accuracy.", "published": "2024-01-01", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.00622v1"}
