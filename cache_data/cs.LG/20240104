{"title": "Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic Speech Recognition", "author": "David M. Chan, Shalini Ghosh, Hitesh Tulsiani, Ariya Rastrow, Björn Hoffmeister", "abstract": "While word error rates of automatic speech recognition (ASR) systems have\nconsistently fallen, natural language understanding (NLU) applications built on\ntop of ASR systems still attribute significant numbers of failures to\nlow-quality speech recognition results. Existing assistant systems collect\nlarge numbers of these unsuccessful interactions, but these systems usually\nfail to learn from these interactions, even in an offline fashion. In this\nwork, we introduce CLC: Contrastive Learning for Conversations, a family of\nmethods for contrastive fine-tuning of models in a self-supervised fashion,\nmaking use of easily detectable artifacts in unsuccessful conversations with\nassistants. We demonstrate that our CLC family of approaches can improve the\nperformance of ASR models on OD3, a new public large-scale semi-synthetic\nmeta-dataset of audio task-oriented dialogues, by up to 19.2%. These gains\ntransfer to real-world systems as well, where we show that CLC can help to\nimprove performance by up to 6.7% over baselines. We make OD3 publicly\navailable at https://github.com/amazon-science/amazon-od3 .", "published": "2024-01-04", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.02417v1"}
{"title": "ODIN: A Single Model for 2D and 3D Perception", "author": "Ayush Jain, Pushkal Katara, Nikolaos Gkanatsios, Adam W. Harley, Gabriel Sarch, Kriti Aggarwal, Vishrav Chaudhary, Katerina Fragkiadaki", "abstract": "State-of-the-art models on contemporary 3D perception benchmarks like ScanNet\nconsume and label dataset-provided 3D point clouds, obtained through post\nprocessing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website: https://odin-seg.github.io.", "published": "2024-01-04", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "links": "http://arxiv.org/abs/2401.02416v1"}
{"title": "Simulation-Based Inference with Quantile Regression", "author": "He Jia", "abstract": "We present Neural Quantile Estimation (NQE), a novel Simulation-Based\nInference (SBI) method based on conditional quantile regression. NQE\nautoregressively learns individual one dimensional quantiles for each posterior\ndimension, conditioned on the data and previous posterior dimensions. Posterior\nsamples are obtained by interpolating the predicted quantiles using monotonic\ncubic Hermite spline, with specific treatment for the tail behavior and\nmulti-modal distributions. We introduce an alternative definition for the\nBayesian credible region using the local Cumulative Density Function (CDF),\noffering substantially faster evaluation than the traditional Highest Posterior\nDensity Region (HPDR). In case of limited simulation budget and/or known model\nmisspecification, a post-processing broadening step can be integrated into NQE\nto ensure the unbiasedness of the posterior estimation with negligible\nadditional computational cost. We demonstrate that the proposed NQE method\nachieves state-of-the-art performance on a variety of benchmark problems.", "published": "2024-01-04", "categories": ["stat.ML", "cs.LG"], "links": "http://arxiv.org/abs/2401.02413v1"}
{"title": "LLM Augmented LLMs: Expanding Capabilities through Composition", "author": "Rachit Bansal, Bidisha Samanta, Siddharth Dalmia, Nitish Gupta, Shikhar Vashishth, Sriram Ganapathy, Abhishek Bapna, Prateek Jain, Partha Talukdar", "abstract": "Foundational models with billions of parameters which have been trained on\nlarge corpora of data have demonstrated non-trivial skills in a variety of\ndomains. However, due to their monolithic structure, it is challenging and\nexpensive to augment them or impart new skills. On the other hand, due to their\nadaptation abilities, several new instances of these models are being trained\ntowards new domains and tasks. In this work, we study the problem of efficient\nand practical composition of existing foundation models with more specific\nmodels to enable newer capabilities. To this end, we propose CALM --\nComposition to Augment Language Models -- which introduces cross-attention\nbetween models to compose their representations and enable new capabilities.\nSalient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'\nexisting LLMs along with a few additional parameters and data, (ii) Existing\nmodel weights are kept intact, and hence preserves existing capabilities, and\n(iii) Applies to diverse domains and settings. We illustrate that augmenting\nPaLM2-S with a smaller model trained on low-resource languages results in an\nabsolute improvement of up to 13\\% on tasks like translation into English and\narithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is\naugmented with a code-specific model, we see a relative improvement of 40\\%\nover the base model for code generation and explanation tasks -- on-par with\nfully fine-tuned counterparts.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "links": "http://arxiv.org/abs/2401.02412v1"}
{"title": "What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs", "author": "Alex Trevithick, Matthew Chan, Towaki Takikawa, Umar Iqbal, Shalini De Mello, Manmohan Chandraker, Ravi Ramamoorthi, Koki Nagano", "abstract": "3D-aware Generative Adversarial Networks (GANs) have shown remarkable\nprogress in learning to generate multi-view-consistent images and 3D geometries\nof scenes from collections of 2D images via neural volume rendering. Yet, the\nsignificant memory and computational costs of dense sampling in volume\nrendering have forced 3D GANs to adopt patch-based training or employ\nlow-resolution rendering with post-processing 2D super resolution, which\nsacrifices multiview consistency and the quality of resolved geometry.\nConsequently, 3D GANs have not yet been able to fully resolve the rich 3D\ngeometry present in 2D images. In this work, we propose techniques to scale\nneural volume rendering to the much higher resolution of native 2D images,\nthereby resolving fine-grained 3D geometry with unprecedented detail. Our\napproach employs learning-based samplers for accelerating neural rendering for\n3D GAN training using up to 5 times fewer depth samples. This enables us to\nexplicitly \"render every pixel\" of the full-resolution image during training\nand inference without post-processing superresolution in 2D. Together with our\nstrategy to learn high-quality surface geometry, our method synthesizes\nhigh-resolution 3D geometry and strictly view-consistent images while\nmaintaining image quality on par with baselines relying on post-processing\nsuper resolution. We demonstrate state-of-the-art 3D gemetric quality on FFHQ\nand AFHQ, setting a new standard for unsupervised learning of 3D shapes in 3D\nGANs.", "published": "2024-01-04", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "links": "http://arxiv.org/abs/2401.02411v1"}
{"title": "Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks", "author": "Pouyan Sajadi, Mostafa Rahmani Dehaghani, Yifan Tang, G. Gary Wang", "abstract": "Accurately predicting the temperature field in metal additive manufacturing\n(AM) processes is critical to preventing overheating, adjusting process\nparameters, and ensuring process stability. While physics-based computational\nmodels offer precision, they are often time-consuming and unsuitable for\nreal-time predictions and online control in iterative design scenarios.\nConversely, machine learning models rely heavily on high-quality datasets,\nwhich can be costly and challenging to obtain within the metal AM domain. Our\nwork addresses this by introducing a physics-informed neural network framework\nspecifically designed for temperature field prediction in metal AM. This\nframework incorporates a physics-informed input, physics-informed loss\nfunction, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture.\nUtilizing real-time temperature data from the process, our model predicts 2D\ntemperature fields for future timestamps across diverse geometries, deposition\npatterns, and process parameters. We validate the proposed framework in two\nscenarios: full-field temperature prediction for a thin wall and 2D temperature\nfield prediction for cylinder and cubic parts, demonstrating errors below 3%\nand 1%, respectively. Our proposed framework exhibits the flexibility to be\napplied across diverse scenarios with varying process parameters, geometries,\nand deposition patterns.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.02403v1"}
{"title": "Generating synthetic data for neural operators", "author": "Erisa Hasani, Rachel A. Ward", "abstract": "Numerous developments in the recent literature show the promising potential\nof deep learning in obtaining numerical solutions to partial differential\nequations (PDEs) beyond the reach of current numerical solvers. However,\ndata-driven neural operators all suffer from the same problem: the data needed\nto train a network depends on classical numerical solvers such as finite\ndifference or finite element, among others. In this paper, we propose a new\napproach to generating synthetic functional training data that does not require\nsolving a PDE numerically. The way we do this is simple: we draw a large number\n$N$ of independent and identically distributed `random functions' $u_j$ from\nthe underlying solution space (e.g., $H_0^1(\\Omega)$) in which we know the\nsolution lies according to classical theory. We then plug each such random\ncandidate solution into the equation and get a corresponding right-hand side\nfunction $f_j$ for the equation, and consider $(f_j, u_j)_{j=1}^N$ as\nsupervised training data for learning the underlying inverse problem $f\n\\rightarrow u$. This `backwards' approach to generating training data only\nrequires derivative computations, in contrast to standard `forward' approaches,\nwhich require a numerical PDE solver, enabling us to generate a large number of\nsuch data points quickly and efficiently. While the idea is simple, we hope\nthat this method will expand the potential for developing neural PDE solvers\nthat do not depend on classical numerical solvers.", "published": "2024-01-04", "categories": ["cs.LG", "cs.NA", "math.NA"], "links": "http://arxiv.org/abs/2401.02398v1"}
{"title": "Integration of physics-informed operator learning and finite element method for parametric learning of partial differential equations", "author": "Shahed Rezaei, Ahmad Moeineddin, Michael Kaliske, Markus Apel", "abstract": "We present a method that employs physics-informed deep learning techniques\nfor parametrically solving partial differential equations. The focus is on the\nsteady-state heat equations within heterogeneous solids exhibiting significant\nphase contrast. Similar equations manifest in diverse applications like\nchemical diffusion, electrostatics, and Darcy flow. The neural network aims to\nestablish the link between the complex thermal conductivity profiles and\ntemperature distributions, as well as heat flux components within the\nmicrostructure, under fixed boundary conditions. A distinctive aspect is our\nindependence from classical solvers like finite element methods for data. A\nnoteworthy contribution lies in our novel approach to defining the loss\nfunction, based on the discretized weak form of the governing equation. This\nnot only reduces the required order of derivatives but also eliminates the need\nfor automatic differentiation in the construction of loss terms, accepting\npotential numerical errors from the chosen discretization method. As a result,\nthe loss function in this work is an algebraic equation that significantly\nenhances training efficiency. We benchmark our methodology against the standard\nfinite element method, demonstrating accurate yet faster predictions using the\ntrained neural network for temperature and flux profiles. We also show higher\naccuracy by using the proposed method compared to purely data-driven approaches\nfor unforeseen scenarios.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CE"], "links": "http://arxiv.org/abs/2401.02363v1"}
{"title": "A Survey Analyzing Generalization in Deep Reinforcement Learning", "author": "Ezgi Korkmaz", "abstract": "Reinforcement learning research obtained significant success and attention\nwith the utilization of deep neural networks to solve problems in high\ndimensional state or action spaces. While deep reinforcement learning policies\nare currently being deployed in many different fields from medical applications\nto self driving vehicles, there are still ongoing questions the field is trying\nto answer on the generalization capabilities of deep reinforcement learning\npolicies. In this paper, we will outline the fundamental reasons why deep\nreinforcement learning policies encounter overfitting problems that limit their\nrobustness and generalization capabilities. Furthermore, we will formalize and\nunify the diverse solution approaches to increase generalization, and overcome\noverfitting in state-action value functions. We believe our study can provide a\ncompact systematic unified analysis for the current advancements in deep\nreinforcement learning, and help to construct robust deep neural policies with\nimproved generalization abilities.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "stat.ML"], "links": "http://arxiv.org/abs/2401.02349v1"}
{"title": "Multi-Source Domain Adaptation with Transformer-based Feature Generation for Subject-Independent EEG-based Emotion Recognition", "author": "Shadi Sartipi, Mujdat Cetin", "abstract": "Although deep learning-based algorithms have demonstrated excellent\nperformance in automated emotion recognition via electroencephalogram (EEG)\nsignals, variations across brain signal patterns of individuals can diminish\nthe model's effectiveness when applied across different subjects. While\ntransfer learning techniques have exhibited promising outcomes, they still\nencounter challenges related to inadequate feature representations and may\noverlook the fact that source subjects themselves can possess distinct\ncharacteristics. In this work, we propose a multi-source domain adaptation\napproach with a transformer-based feature generator (MSDA-TF) designed to\nleverage information from multiple sources. The proposed feature generator\nretains convolutional layers to capture shallow spatial, temporal, and spectral\nEEG data representations, while self-attention mechanisms extract global\ndependencies within these features. During the adaptation process, we group the\nsource subjects based on correlation values and aim to align the moments of the\ntarget subject with each source as well as within the sources. MSDA-TF is\nvalidated on the SEED dataset and is shown to yield promising results.", "published": "2024-01-04", "categories": ["cs.LG", "eess.SP"], "links": "http://arxiv.org/abs/2401.02344v1"}
{"title": "Evasive Hardware Trojan through Adversarial Power Trace", "author": "Behnam Omidi, Khaled N. Khasawneh, Ihsen Alouani", "abstract": "The globalization of the Integrated Circuit (IC) supply chain, driven by\ntime-to-market and cost considerations, has made ICs vulnerable to hardware\nTrojans (HTs). Against this threat, a promising approach is to use Machine\nLearning (ML)-based side-channel analysis, which has the advantage of being a\nnon-intrusive method, along with efficiently detecting HTs under golden\nchip-free settings. In this paper, we question the trustworthiness of ML-based\nHT detection via side-channel analysis. We introduce a HT obfuscation (HTO)\napproach to allow HTs to bypass this detection method. Rather than\ntheoretically misleading the model by simulated adversarial traces, a key\naspect of our approach is the design and implementation of adversarial noise as\npart of the circuitry, alongside the HT. We detail HTO methodologies for ASICs\nand FPGAs, and evaluate our approach using TrustHub benchmark. Interestingly,\nwe found that HTO can be implemented with only a single transistor for ASIC\ndesigns to generate adversarial power traces that can fool the defense with\n100% efficiency. We also efficiently implemented our approach on a Spartan 6\nXilinx FPGA using 2 different variants: (i) DSP slices-based, and (ii)\nring-oscillator-based design. Additionally, we assess the efficiency of\ncountermeasures like spectral domain analysis, and we show that an adaptive\nattacker can still design evasive HTOs by constraining the design with a\nspectral noise budget. In addition, while adversarial training (AT) offers\nhigher protection against evasive HTs, AT models suffer from a considerable\nutility loss, potentially rendering them unsuitable for such security\napplication. We believe this research represents a significant step in\nunderstanding and exploiting ML vulnerabilities in a hardware security context,\nand we make all resources and designs openly available online:\nhttps://dev.d18uu4lqwhbmka.amplifyapp.com", "published": "2024-01-04", "categories": ["cs.CR", "cs.AR", "cs.LG"], "links": "http://arxiv.org/abs/2401.02342v1"}
{"title": "Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models", "author": "Uday Allu, Biddwan Ahmed, Vishesh Tripathi", "abstract": "The conventional use of the Retrieval-Augmented Generation (RAG) architecture\nhas proven effective for retrieving information from diverse documents.\nHowever, challenges arise in handling complex table queries, especially within\nPDF documents containing intricate tabular structures.This research introduces\nan innovative approach to enhance the accuracy of complex table queries in\nRAG-based systems. Our methodology involves storing PDFs in the retrieval\ndatabase and extracting tabular content separately. The extracted tables\nundergo a process of context enrichment, concatenating headers with\ncorresponding values. To ensure a comprehensive understanding of the enriched\ndata, we employ a fine-tuned version of the Llama-2-chat language model for\nsummarisation within the RAG architecture. Furthermore, we augment the tabular\ndata with contextual sense using the ChatGPT 3.5 API through a one-shot prompt.\nThis enriched data is then fed into the retrieval database alongside other\nPDFs. Our approach aims to significantly improve the precision of complex table\nqueries, offering a promising solution to a longstanding challenge in\ninformation retrieval.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CL"], "links": "http://arxiv.org/abs/2401.02333v1"}
{"title": "Not all Minorities are Equal: Empty-Class-Aware Distillation for Heterogeneous Federated Learning", "author": "Kuangpu Guo, Yuhe Ding, Jian Liang, Ran He, Zilei Wang, Tieniu Tan", "abstract": "Data heterogeneity, characterized by disparities in local data distribution\nacross clients, poses a significant challenge in federated learning.\nSubstantial efforts have been devoted to addressing the heterogeneity in local\nlabel distribution. As minority classes suffer from worse accuracy due to\noverfitting on local imbalanced data, prior methods often incorporate\nclass-balanced learning techniques during local training. Despite the improved\nmean accuracy across all classes, we observe that empty classes-referring to\ncategories absent from a client's data distribution-are still not well\nrecognized. This paper introduces FedED, a novel approach in heterogeneous\nfederated learning that integrates both empty-class distillation and logit\nsuppression simultaneously. Specifically, empty-class distillation leverages\nknowledge distillation during local training on each client to retain essential\ninformation related to empty classes from the global model. Moreover, logit\nsuppression directly penalizes network logits for non-label classes,\neffectively addressing misclassifications in minority classes that may be\nbiased toward majority classes. Extensive experiments validate the efficacy of\nFedED, surpassing previous state-of-the-art methods across diverse datasets\nwith varying degrees of label distribution shift.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02329v1"}
{"title": "A Robust Quantile Huber Loss With Interpretable Parameter Adjustment In Distributional Reinforcement Learning", "author": "Parvin Malekzadeh, Konstantinos N. Plataniotis, Zissis Poulos, Zeyu Wang", "abstract": "Distributional Reinforcement Learning (RL) estimates return distribution\nmainly by learning quantile values via minimizing the quantile Huber loss\nfunction, entailing a threshold parameter often selected heuristically or via\nhyperparameter search, which may not generalize well and can be suboptimal.\nThis paper introduces a generalized quantile Huber loss function derived from\nWasserstein distance (WD) calculation between Gaussian distributions, capturing\nnoise in predicted (current) and target (Bellman-updated) quantile values.\nCompared to the classical quantile Huber loss, this innovative loss function\nenhances robustness against outliers. Notably, the classical Huber loss\nfunction can be seen as an approximation of our proposed loss, enabling\nparameter adjustment by approximating the amount of noise in the data during\nthe learning process. Empirical tests on Atari games, a common application in\ndistributional RL, and a recent hedging strategy using distributional RL,\nvalidate the effectiveness of our proposed loss function and its potential for\nparameter adjustments in distributional RL.", "published": "2024-01-04", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.02325v1"}
{"title": "Multi-Agent Context Learning Strategy for Interference-Aware Beam Allocation in mmWave Vehicular Communications", "author": "Abdulkadir Kose, Haeyoung Lee, Chuan Heng Foh, Mohammad Shojafar", "abstract": "Millimeter wave (mmWave) has been recognized as one of key technologies for\n5G and beyond networks due to its potential to enhance channel bandwidth and\nnetwork capacity. The use of mmWave for various applications including\nvehicular communications has been extensively discussed. However, applying\nmmWave to vehicular communications faces challenges of high mobility nodes and\nnarrow coverage along the mmWave beams. Due to high mobility in dense networks,\noverlapping beams can cause strong interference which leads to performance\ndegradation. As a remedy, beam switching capability in mmWave can be utilized.\nThen, frequent beam switching and cell change become inevitable to manage\ninterference, which increase computational and signalling complexity. In order\nto deal with the complexity in interference control, we develop a new strategy\ncalled Multi-Agent Context Learning (MACOL), which utilizes Contextual Bandit\nto manage interference while allocating mmWave beams to serve vehicles in the\nnetwork. Our approach demonstrates that by leveraging knowledge of neighbouring\nbeam status, the machine learning agent can identify and avoid potential\ninterfering transmissions to other ongoing transmissions. Furthermore, we show\nthat even under heavy traffic loads, our proposed MACOL strategy is able to\nmaintain low interference levels at around 10%.", "published": "2024-01-04", "categories": ["eess.SP", "cs.LG"], "links": "http://arxiv.org/abs/2401.02323v1"}
{"title": "Robust Physics Informed Neural Networks", "author": "Marcin Łoś, Maciej Paszyński", "abstract": "We introduce a Robust version of the Physics-Informed Neural Networks\n(RPINNs) to approximate the Partial Differential Equations (PDEs) solution.\nStandard Physics Informed Neural Networks (PINN) takes into account the\ngoverning physical laws described by PDE during the learning process. The\nnetwork is trained on a data set that consists of randomly selected points in\nthe physical domain and its boundary. PINNs have been successfully applied to\nsolve various problems described by PDEs with boundary conditions. The loss\nfunction in traditional PINNs is based on the strong residuals of the PDEs.\nThis loss function in PINNs is generally not robust with respect to the true\nerror. The loss function in PINNs can be far from the true error, which makes\nthe training process more difficult. In particular, we do not know if the\ntraining process has already converged to the solution with the required\naccuracy. This is especially true if we do not know the exact solution, so we\ncannot estimate the true error during the training. This paper introduces a\ndifferent way of defining the loss function. It incorporates the residual and\nthe inverse of the Gram matrix, computed using the energy norm. We test our\nRPINN algorithm on two Laplace problems and one advection-diffusion problem in\ntwo spatial dimensions. We conclude that RPINN is a robust method. The proposed\nloss coincides well with the true error of the solution, as measured in the\nenergy norm. Thus, we know if our training process goes well, and we know when\nto stop the training to obtain the neural network approximation of the solution\nof the PDE with the true error of required accuracy.", "published": "2024-01-04", "categories": ["cs.LG", "cs.NA", "math.NA", "65M99, 68T07", "G.1.8; I.2; I.m; G.1.10; J.2"], "links": "http://arxiv.org/abs/2401.02300v1"}
{"title": "Training Single-Layer Morphological Perceptron Using Convex-Concave Programming", "author": "Iara Cunha, Marcos Eduardo Valle", "abstract": "This paper concerns the training of a single-layer morphological perceptron\nusing disciplined convex-concave programming (DCCP). We introduce an algorithm\nreferred to as K-DDCCP, which combines the existing single-layer morphological\nperceptron (SLMP) model proposed by Ritter and Urcid with the weighted\ndisciplined convex-concave programming (WDCCP) algorithm by Charisopoulos and\nMaragos. The proposed training algorithm leverages the disciplined\nconvex-concave procedure (DCCP) and formulates a non-convex optimization\nproblem for binary classification. To tackle this problem, the constraints are\nexpressed as differences of convex functions, enabling the application of the\nDCCP package. The experimental results confirm the effectiveness of the K-DDCCP\nalgorithm in solving binary classification problems. Overall, this work\ncontributes to the field of morphological neural networks by proposing an\nalgorithm that extends the capabilities of the SLMP model.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02296v1"}
{"title": "Path-based Explanation for Knowledge Graph Completion", "author": "Heng Chang, Jiangnan Ye, Alejo Lopez Avila, Jinhua Du, Jia Li", "abstract": "Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph\nCompletion (KGC) by modelling how entities and relations interact in recent\nyears. However, the explanation of the predicted facts has not caught the\nnecessary attention. Proper explanations for the results of GNN-based KGC\nmodels increase model transparency and help researchers develop more reliable\nmodels. Existing practices for explaining KGC tasks rely on\ninstance/subgraph-based approaches, while in some scenarios, paths can provide\nmore user-friendly and interpretable explanations. Nonetheless, the methods for\ngenerating path-based explanations for KGs have not been well-explored. To\naddress this gap, we propose Power-Link, the first path-based KGC explainer\nthat explores GNN-based models. We design a novel simplified graph-powering\ntechnique, which enables the generation of path-based explanations with a fully\nparallelisable and memory-efficient training scheme. We further introduce three\nnew metrics for quantitative evaluation of the explanations, together with a\nqualitative human evaluation. Extensive experiments demonstrate that Power-Link\noutperforms the SOTA baselines in interpretability, efficiency, and\nscalability.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "cs.SI"], "links": "http://arxiv.org/abs/2401.02290v1"}
{"title": "DEM: A Method for Certifying Deep Neural Network Classifier Outputs in Aerospace", "author": "Guy Katz, Natan Levy, Idan Refaeli, Raz Yerushalmi", "abstract": "Software development in the aerospace domain requires adhering to strict,\nhigh-quality standards. While there exist regulatory guidelines for commercial\nsoftware in this domain (e.g., ARP-4754 and DO-178), these do not apply to\nsoftware with deep neural network (DNN) components. Consequently, it is unclear\nhow to allow aerospace systems to benefit from the deep learning revolution.\nOur work here seeks to address this challenge with a novel, output-centric\napproach for DNN certification. Our method employs statistical verification\ntechniques, and has the key advantage of being able to flag specific inputs for\nwhich the DNN's output may be unreliable - so that they may be later inspected\nby a human expert. To achieve this, our method conducts a statistical analysis\nof the DNN's predictions for other, nearby inputs, in order to detect\ninconsistencies. This is in contrast to existing techniques, which typically\nattempt to certify the entire DNN, as opposed to individual outputs. Our method\nuses the DNN as a black-box, and makes no assumptions about its topology. We\nhope that this work constitutes another step towards integrating DNNs in\nsafety-critical applications - especially in the aerospace domain, where high\nstandards of quality and reliability are crucial.", "published": "2024-01-04", "categories": ["cs.SE", "cs.LG"], "links": "http://arxiv.org/abs/2401.02283v1"}
{"title": "Lightweight Fish Classification Model for Sustainable Marine Management: Indonesian Case", "author": "Febrian Kurniawan, Gandeva Bayu Satrya, Firuz Kamalov", "abstract": "The enormous demand for seafood products has led to exploitation of marine\nresources and near-extinction of some species. In particular, overfishing is\none the main issues in sustainable marine development. In alignment with the\nprotection of marine resources and sustainable fishing, this study proposes to\nadvance fish classification techniques that support identifying protected fish\nspecies using state-of-the-art machine learning. We use a custom modification\nof the MobileNet model to design a lightweight classifier called M-MobileNet\nthat is capable of running on limited hardware. As part of the study, we\ncompiled a labeled dataset of 37,462 images of fish found in the waters of the\nIndonesian archipelago. The proposed model is trained on the dataset to\nclassify images of the captured fish into their species and give\nrecommendations on whether they are consumable or not. Our modified MobileNet\nmodel uses only 50\\% of the top layer parameters with about 42% GTX 860M\nutility and achieves up to 97% accuracy in fish classification and determining\nits consumability. Given the limited computing capacity available on many\nfishing vessels, the proposed model provides a practical solution to on-site\nfish classification. In addition, synchronized implementation of the proposed\nmodel on multiple vessels can supply valuable information about the movement\nand location of different species of fish.", "published": "2024-01-04", "categories": ["cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.02278v1"}
{"title": "Universal Approximation Theorem for Vector- and Hypercomplex-Valued Neural Networks", "author": "Marcos Eduardo Valle, Wington L. Vital, Guilherme Vieira", "abstract": "The universal approximation theorem states that a neural network with one\nhidden layer can approximate continuous functions on compact sets with any\ndesired precision. This theorem supports using neural networks for various\napplications, including regression and classification tasks. Furthermore, it is\nvalid for real-valued neural networks and some hypercomplex-valued neural\nnetworks such as complex-, quaternion-, tessarine-, and Clifford-valued neural\nnetworks. However, hypercomplex-valued neural networks are a type of\nvector-valued neural network defined on an algebra with additional algebraic or\ngeometric properties. This paper extends the universal approximation theorem\nfor a wide range of vector-valued neural networks, including\nhypercomplex-valued models as particular instances. Precisely, we introduce the\nconcept of non-degenerate algebra and state the universal approximation theorem\nfor neural networks defined on such algebras.", "published": "2024-01-04", "categories": ["cs.LG", "cs.NE"], "links": "http://arxiv.org/abs/2401.02277v1"}
{"title": "Uncertainty-Aware Deep Attention Recurrent Neural Network for Heterogeneous Time Series Imputation", "author": "Linglong Qian, Zina Ibrahim, Richard Dobson", "abstract": "Missingness is ubiquitous in multivariate time series and poses an obstacle\nto reliable downstream analysis. Although recurrent network imputation achieved\nthe SOTA, existing models do not scale to deep architectures that can\npotentially alleviate issues arising in complex data. Moreover, imputation\ncarries the risk of biased estimations of the ground truth. Yet, confidence in\nthe imputed values is always unmeasured or computed post hoc from model output.\nWe propose DEep Attention Recurrent Imputation (DEARI), which jointly estimates\nmissing values and their associated uncertainty in heterogeneous multivariate\ntime series. By jointly representing feature-wise correlations and temporal\ndynamics, we adopt a self attention mechanism, along with an effective residual\ncomponent, to achieve a deep recurrent neural network with good imputation\nperformance and stable convergence. We also leverage self-supervised metric\nlearning to boost performance by optimizing sample similarity. Finally, we\ntransform DEARI into a Bayesian neural network through a novel Bayesian\nmarginalization strategy to produce stochastic DEARI, which outperforms its\ndeterministic equivalent. Experiments show that DEARI surpasses the SOTA in\ndiverse imputation tasks using real-world datasets, namely air quality control,\nhealthcare and traffic.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.02258v1"}
{"title": "Balancing Continual Learning and Fine-tuning for Human Activity Recognition", "author": "Chi Ian Tang, Lorena Qendro, Dimitris Spathis, Fahim Kawsar, Akhil Mathur, Cecilia Mascolo", "abstract": "Wearable-based Human Activity Recognition (HAR) is a key task in\nhuman-centric machine learning due to its fundamental understanding of human\nbehaviours. Due to the dynamic nature of human behaviours, continual learning\npromises HAR systems that are tailored to users' needs. However, because of the\ndifficulty in collecting labelled data with wearable sensors, existing\napproaches that focus on supervised continual learning have limited\napplicability, while unsupervised continual learning methods only handle\nrepresentation learning while delaying classifier training to a later stage.\nThis work explores the adoption and adaptation of CaSSLe, a continual\nself-supervised learning model, and Kaizen, a semi-supervised continual\nlearning model that balances representation learning and down-stream\nclassification, for the task of wearable-based HAR. These schemes re-purpose\ncontrastive learning for knowledge retention and, Kaizen combines that with\nself-training in a unified scheme that can leverage unlabelled and labelled\ndata for continual learning. In addition to comparing state-of-the-art\nself-supervised continual learning schemes, we further investigated the\nimportance of different loss terms and explored the trade-off between knowledge\nretention and learning from new tasks. In particular, our extensive evaluation\ndemonstrated that the use of a weighting factor that reflects the ratio between\nlearned and new classes achieves the best overall trade-off in continual\nlearning.", "published": "2024-01-04", "categories": ["cs.LG", "eess.SP"], "links": "http://arxiv.org/abs/2401.02255v1"}
{"title": "L3Cube-IndicNews: News-based Short Text and Long Document Classification Datasets in Indic Languages", "author": "Aishwarya Mirashi, Srushti Sonavane, Purva Lingayat, Tejas Padhiyar, Raviraj Joshi", "abstract": "In this work, we introduce L3Cube-IndicNews, a multilingual text\nclassification corpus aimed at curating a high-quality dataset for Indian\nregional languages, with a specific focus on news headlines and articles. We\nhave centered our work on 10 prominent Indic languages, including Hindi,\nBengali, Marathi, Telugu, Tamil, Gujarati, Kannada, Odia, Malayalam, and\nPunjabi. Each of these news datasets comprises 10 or more classes of news\narticles. L3Cube-IndicNews offers 3 distinct datasets tailored to handle\ndifferent document lengths that are classified as: Short Headlines\nClassification (SHC) dataset containing the news headline and news category,\nLong Document Classification (LDC) dataset containing the whole news article\nand the news category, and Long Paragraph Classification (LPC) containing\nsub-articles of the news and the news category. We maintain consistent labeling\nacross all 3 datasets for in-depth length-based analysis. We evaluate each of\nthese Indic language datasets using 4 different models including monolingual\nBERT, multilingual Indic Sentence BERT (IndicSBERT), and IndicBERT. This\nresearch contributes significantly to expanding the pool of available text\nclassification datasets and also makes it possible to develop topic\nclassification models for Indian regional languages. This also serves as an\nexcellent resource for cross-lingual analysis owing to the high overlap of\nlabels among languages. The datasets and models are shared publicly at\nhttps://github.com/l3cube-pune/indic-nlp", "published": "2024-01-04", "categories": ["cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.02254v1"}
{"title": "Policy-regularized Offline Multi-objective Reinforcement Learning", "author": "Qian Lin, Chao Yu, Zongkai Liu, Zifan Wu", "abstract": "In this paper, we aim to utilize only offline trajectory data to train a\npolicy for multi-objective RL. We extend the offline policy-regularized method,\na widely-adopted approach for single-objective offline RL problems, into the\nmulti-objective setting in order to achieve the above goal. However, such\nmethods face a new challenge in offline MORL settings, namely the\npreference-inconsistent demonstration problem. We propose two solutions to this\nproblem: 1) filtering out preference-inconsistent demonstrations via\napproximating behavior preferences, and 2) adopting regularization techniques\nwith high policy expressiveness. Moreover, we integrate the\npreference-conditioned scalarized update method into policy-regularized offline\nRL, in order to simultaneously learn a set of policies using a single policy\nnetwork, thus reducing the computational cost induced by the training of a\nlarge number of individual policies for various preferences. Finally, we\nintroduce Regularization Weight Adaptation to dynamically determine appropriate\nregularization weights for arbitrary target preferences during deployment.\nEmpirical results on various multi-objective datasets demonstrate the\ncapability of our approach in solving offline MORL problems.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.02244v1"}
{"title": "U-Mixer: An Unet-Mixer Architecture with Stationarity Correction for Time Series Forecasting", "author": "Xiang Ma, Xuemei Li, Lexin Fang, Tianlong Zhao, Caiming Zhang", "abstract": "Time series forecasting is a crucial task in various domains. Caused by\nfactors such as trends, seasonality, or irregular fluctuations, time series\noften exhibits non-stationary. It obstructs stable feature propagation through\ndeep layers, disrupts feature distributions, and complicates learning data\ndistribution changes. As a result, many existing models struggle to capture the\nunderlying patterns, leading to degraded forecasting performance. In this\nstudy, we tackle the challenge of non-stationarity in time series forecasting\nwith our proposed framework called U-Mixer. By combining Unet and Mixer,\nU-Mixer effectively captures local temporal dependencies between different\npatches and channels separately to avoid the influence of distribution\nvariations among channels, and merge low- and high-levels features to obtain\ncomprehensive data representations. The key contribution is a novel\nstationarity correction method, explicitly restoring data distribution by\nconstraining the difference in stationarity between the data before and after\nmodel processing to restore the non-stationarity information, while ensuring\nthe temporal dependencies are preserved. Through extensive experiments on\nvarious real-world time series datasets, U-Mixer demonstrates its effectiveness\nand robustness, and achieves 14.5\\% and 7.7\\% improvements over\nstate-of-the-art (SOTA) methods.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02236v1"}
{"title": "Trajectory-Oriented Policy Optimization with Sparse Rewards", "author": "Guojian Wang, Faguo Wu, Xiao Zhang", "abstract": "Deep reinforcement learning (DRL) remains challenging in tasks with sparse\nrewards. These sparse rewards often only indicate whether the task is partially\nor fully completed, meaning that many exploration actions must be performed\nbefore the agent obtains useful feedback. Hence, most existing DRL algorithms\nfail to learn feasible policies within a reasonable time frame. To overcome\nthis problem, we develop an approach that exploits offline demonstration\ntrajectories for faster and more efficient online RL in sparse reward settings.\nOur key insight is that by regarding offline demonstration trajectories as\nguidance, instead of imitating them, our method learns a policy whose\nstate-action visitation marginal distribution matches that of offline\ndemonstrations. Specifically, we introduce a novel trajectory distance based on\nmaximum mean discrepancy (MMD) and formulate policy optimization as a\ndistance-constrained optimization problem. Then, we show that this\ndistance-constrained optimization problem can be reduced into a policy-gradient\nalgorithm with shaped rewards learned from offline demonstrations. The proposed\nalgorithm is evaluated on extensive discrete and continuous control tasks with\nsparse and deceptive rewards. The experimental results indicate that our\nproposed algorithm is significantly better than the baseline methods regarding\ndiverse exploration and learning the optimal policy.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02225v1"}
{"title": "Robust bilinear factor analysis based on the matrix-variate $t$ distribution", "author": "Xuan Ma, Jianhua Zhao, Changchun Shang, Fen Jiang, Philip L. H. Yu", "abstract": "Factor Analysis based on multivariate $t$ distribution ($t$fa) is a useful\nrobust tool for extracting common factors on heavy-tailed or contaminated data.\nHowever, $t$fa is only applicable to vector data. When $t$fa is applied to\nmatrix data, it is common to first vectorize the matrix observations. This\nintroduces two challenges for $t$fa: (i) the inherent matrix structure of the\ndata is broken, and (ii) robustness may be lost, as vectorized matrix data\ntypically results in a high data dimension, which could easily lead to the\nbreakdown of $t$fa. To address these issues, starting from the intrinsic matrix\nstructure of matrix data, a novel robust factor analysis model, namely bilinear\nfactor analysis built on the matrix-variate $t$ distribution ($t$bfa), is\nproposed in this paper. The novelty is that it is capable to simultaneously\nextract common factors for both row and column variables of interest on\nheavy-tailed or contaminated matrix data. Two efficient algorithms for maximum\nlikelihood estimation of $t$bfa are developed. Closed-form expression for the\nFisher information matrix to calculate the accuracy of parameter estimates are\nderived. Empirical studies are conducted to understand the proposed $t$bfa\nmodel and compare with related competitors. The results demonstrate the\nsuperiority and practicality of $t$bfa. Importantly, $t$bfa exhibits a\nsignificantly higher breakdown point than $t$fa, making it more suitable for\nmatrix data.", "published": "2024-01-04", "categories": ["stat.ML", "cs.LG"], "links": "http://arxiv.org/abs/2401.02203v1"}
{"title": "LADRI: LeArning-based Dynamic Risk Indicator in Automated Driving System", "author": "Anil Ranjitbhai Patel, Peter Liggesmeyer", "abstract": "As the horizon of intelligent transportation expands with the evolution of\nAutomated Driving Systems (ADS), ensuring paramount safety becomes more\nimperative than ever. Traditional risk assessment methodologies, primarily\ncrafted for human-driven vehicles, grapple to adequately adapt to the\nmultifaceted, evolving environments of ADS. This paper introduces a framework\nfor real-time Dynamic Risk Assessment (DRA) in ADS, harnessing the potency of\nArtificial Neural Networks (ANNs).\n  Our proposed solution transcends these limitations, drawing upon ANNs, a\ncornerstone of deep learning, to meticulously analyze and categorize risk\ndimensions using real-time On-board Sensor (OBS) data. This learning-centric\napproach not only elevates the ADS's situational awareness but also enriches\nits understanding of immediate operational contexts. By dissecting OBS data,\nthe system is empowered to pinpoint its current risk profile, thereby enhancing\nsafety prospects for onboard passengers and the broader traffic ecosystem.\n  Through this framework, we chart a direction in risk assessment, bridging the\nconventional voids and enhancing the proficiency of ADS. By utilizing ANNs, our\nmethodology offers a perspective, allowing ADS to adeptly navigate and react to\npotential risk factors, ensuring safer and more informed autonomous journeys.", "published": "2024-01-04", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SE", "cs.SY"], "links": "http://arxiv.org/abs/2401.02199v1"}
{"title": "Nodule detection and generation on chest X-rays: NODE21 Challenge", "author": "Ecem Sogancioglu, Bram van Ginneken, Finn Behrendt, Marcel Bengs, Alexander Schlaefer, Miron Radu, Di Xu, Ke Sheng, Fabien Scalzo, Eric Marcus, Samuele Papa, Jonas Teuwen, Ernst Th. Scholten, Steven Schalekamp, Nils Hendrix, Colin Jacobs, Ward Hendrix, Clara I Sánchez, Keelin Murphy", "abstract": "Pulmonary nodules may be an early manifestation of lung cancer, the leading\ncause of cancer-related deaths among both men and women. Numerous studies have\nestablished that deep learning methods can yield high-performance levels in the\ndetection of lung nodules in chest X-rays. However, the lack of gold-standard\npublic datasets slows down the progression of the research and prevents\nbenchmarking of methods for this task. To address this, we organized a public\nresearch challenge, NODE21, aimed at the detection and generation of lung\nnodules in chest X-rays. While the detection track assesses state-of-the-art\nnodule detection systems, the generation track determines the utility of nodule\ngeneration algorithms to augment training data and hence improve the\nperformance of the detection systems. This paper summarizes the results of the\nNODE21 challenge and performs extensive additional experiments to examine the\nimpact of the synthetically generated nodule training images on the detection\nalgorithm performance.", "published": "2024-01-04", "categories": ["eess.IV", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.02192v1"}
{"title": "FairGridSearch: A Framework to Compare Fairness-Enhancing Models", "author": "Shih-Chi Ma, Tatiana Ermakova, Benjamin Fabian", "abstract": "Machine learning models are increasingly used in critical decision-making\napplications. However, these models are susceptible to replicating or even\namplifying bias present in real-world data. While there are various bias\nmitigation methods and base estimators in the literature, selecting the optimal\nmodel for a specific application remains challenging.\n  This paper focuses on binary classification and proposes FairGridSearch, a\nnovel framework for comparing fairness-enhancing models. FairGridSearch enables\nexperimentation with different model parameter combinations and recommends the\nbest one. The study applies FairGridSearch to three popular datasets (Adult,\nCOMPAS, and German Credit) and analyzes the impacts of metric selection, base\nestimator choice, and classification threshold on model fairness.\n  The results highlight the significance of selecting appropriate accuracy and\nfairness metrics for model evaluation. Additionally, different base estimators\nand classification threshold values affect the effectiveness of bias mitigation\nmethods and fairness stability respectively, but the effects are not consistent\nacross all datasets. Based on these findings, future research on fairness in\nmachine learning should consider a broader range of factors when building fair\nmodels, going beyond bias mitigation methods alone.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "cs.CY"], "links": "http://arxiv.org/abs/2401.02183v1"}
{"title": "Disentangle Estimation of Causal Effects from Cross-Silo Data", "author": "Yuxuan Liu, Haozhao Wang, Shuang Wang, Zhiming He, Wenchao Xu, Jialiang Zhu, Fan Yang", "abstract": "Estimating causal effects among different events is of great importance to\ncritical fields such as drug development. Nevertheless, the data features\nassociated with events may be distributed across various silos and remain\nprivate within respective parties, impeding direct information exchange between\nthem. This, in turn, can result in biased estimations of local causal effects,\nwhich rely on the characteristics of only a subset of the covariates. To tackle\nthis challenge, we introduce an innovative disentangle architecture designed to\nfacilitate the seamless cross-silo transmission of model parameters, enriched\nwith causal mechanisms, through a combination of shared and private branches.\nBesides, we introduce global constraints into the equation to effectively\nmitigate bias within the various missing domains, thereby elevating the\naccuracy of our causal effect estimation. Extensive experiments conducted on\nnew semi-synthetic datasets show that our method outperforms state-of-the-art\nbaselines.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "cs.CR", "stat.ME"], "links": "http://arxiv.org/abs/2401.02154v1"}
{"title": "Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions", "author": "Cheng-Te Li, Yu-Che Tsai, Chih-Yao Chen, Jay Chiehen Liao", "abstract": "In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural\nNetworks (GNNs), a domain where deep learning-based approaches have\nincreasingly shown superior performance in both classification and regression\ntasks compared to traditional methods. The survey highlights a critical gap in\ndeep neural TDL methods: the underrepresentation of latent correlations among\ndata instances and feature values. GNNs, with their innate capability to model\nintricate relationships and interactions between diverse elements of tabular\ndata, have garnered significant interest and application across various TDL\ndomains. Our survey provides a systematic review of the methods involved in\ndesigning and implementing GNNs for TDL (GNN4TDL). It encompasses a detailed\ninvestigation into the foundational aspects and an overview of GNN-based TDL\nmethods, offering insights into their evolving landscape. We present a\ncomprehensive taxonomy focused on constructing graph structures and\nrepresentation learning within GNN-based TDL methods. In addition, the survey\nexamines various training plans, emphasizing the integration of auxiliary tasks\nto enhance the effectiveness of instance representations. A critical part of\nour discussion is dedicated to the practical application of GNNs across a\nspectrum of GNN4TDL scenarios, demonstrating their versatility and impact.\nLastly, we discuss the limitations and propose future research directions,\naiming to spur advancements in GNN4TDL. This survey serves as a resource for\nresearchers and practitioners, offering a thorough understanding of GNNs' role\nin revolutionizing TDL and pointing towards future innovations in this\npromising area.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.SI"], "links": "http://arxiv.org/abs/2401.02143v1"}
{"title": "PosCUDA: Position based Convolution for Unlearnable Audio Datasets", "author": "Vignesh Gokul, Shlomo Dubnov", "abstract": "Deep learning models require large amounts of clean data to acheive good\nperformance. To avoid the cost of expensive data acquisition, researchers use\nthe abundant data available on the internet. This raises significant privacy\nconcerns on the potential misuse of personal data for model training without\nauthorisation. Recent works such as CUDA propose solutions to this problem by\nadding class-wise blurs to make datasets unlearnable, i.e a model can never use\nthe acquired dataset for learning. However these methods often reduce the\nquality of the data making it useless for practical applications. We introduce\nPosCUDA, a position based convolution for creating unlearnable audio datasets.\nPosCUDA uses class-wise convolutions on small patches of audio. The location of\nthe patches are based on a private key for each class, hence the model learns\nthe relations between positional blurs and labels, while failing to generalize.\nWe empirically show that PosCUDA can achieve unlearnability while maintaining\nthe quality of the original audio datasets. Our proposed method is also robust\nto different audio feature representations such as MFCC, raw audio and\ndifferent architectures such as transformers, convolutional networks etc.", "published": "2024-01-04", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "links": "http://arxiv.org/abs/2401.02135v1"}
{"title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach", "author": "Zeynep Hilal Kilimci, Mustafa Yalcin", "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained\nsignificant attention in the field of cancer research and therapy. ACPs are\nshort chains of amino acids, the building blocks of proteins, and they possess\nthe ability to selectively target and kill cancer cells. One of the key\nadvantages of ACPs is their ability to selectively target cancer cells while\nsparing healthy cells to a greater extent. This selectivity is often attributed\nto differences in the surface properties of cancer cells compared to normal\ncells. That is why ACPs are being investigated as potential candidates for\ncancer therapy. ACPs may be used alone or in combination with other treatment\nmodalities like chemotherapy and radiation therapy. While ACPs hold promise as\na novel approach to cancer treatment, there are challenges to overcome,\nincluding optimizing their stability, improving selectivity, and enhancing\ntheir delivery to cancer cells, continuous increasing in number of peptide\nsequences, developing a reliable and precise prediction model. In this work, we\npropose an efficient transformer-based framework to identify anticancer\npeptides for by performing accurate a reliable and precise prediction model.\nFor this purpose, four different transformer models, namely ESM, ProtBert,\nBioBERT, and SciBERT are employed to detect anticancer peptides from amino acid\nsequences. To demonstrate the contribution of the proposed framework, extensive\nexperiments are carried on widely-used datasets in the literature, two versions\nof AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of\nproposed model enhances classification accuracy when compared to the\nstate-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of\naccuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and\n88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.", "published": "2024-01-04", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.LG"], "links": "http://arxiv.org/abs/2401.02124v1"}
{"title": "Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation", "author": "Zipeng Fu, Tony Z. Zhao, Chelsea Finn", "abstract": "Imitation learning from human demonstrations has shown impressive performance\nin robotics. However, most results focus on table-top manipulation, lacking the\nmobility and dexterity necessary for generally useful tasks. In this work, we\ndevelop a system for imitating mobile manipulation tasks that are bimanual and\nrequire whole-body control. We first present Mobile ALOHA, a low-cost and\nwhole-body teleoperation system for data collection. It augments the ALOHA\nsystem with a mobile base, and a whole-body teleoperation interface. Using data\ncollected with Mobile ALOHA, we then perform supervised behavior cloning and\nfind that co-training with existing static ALOHA datasets boosts performance on\nmobile manipulation tasks. With 50 demonstrations for each task, co-training\ncan increase success rates by up to 90%, allowing Mobile ALOHA to autonomously\ncomplete complex mobile manipulation tasks such as sauteing and serving a piece\nof shrimp, opening a two-door wall cabinet to store heavy cooking pots, calling\nand entering an elevator, and lightly rinsing a used pan using a kitchen\nfaucet. Project website: https://mobile-aloha.github.io", "published": "2024-01-04", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "links": "http://arxiv.org/abs/2401.02117v1"}
{"title": "Cadmium Zinc Telluride (CZT) photon counting detector Characterisation for soft tissue imaging", "author": "Kamran Hameed, Rafidah Zainon, Mahbubunnabi Tamal", "abstract": "The use of photon counting detection technology has resulted in significant\nX-ray imaging research interest in recent years. Computed Tomography (CT)\nscanners can benefit from photon-counting detectors, which are new technology\nwith the potential to overcome key limitations of conventional CT detectors.\nResearchers are still studying the effectiveness and sensitivity of\nsemiconductor detector materials in photon counting detectors for detecting\nsoft tissue contrasts. This study aimed to characterize the performance of the\nCadmium Zinc Telluride photon counting detector in identifying various tissues.\nAn optimal frame rate per second (FPS) of CZT detector was evaluated by setting\nthe X-ray tube voltage and current at 25 keV, 35 keV and 0.5 mA, 1.0 mA\nrespectively by keeping the optimum FPS fixed, the detector energy thresholds\nwere set in small steps from 15 keV to 35 keV and the Currents were set for\nX-ray tubes in ranges of 0.1 mA to 1.0 mA to find the relationship between\nvoltage and current of the X-ray source and counts per second (CPS). The\nsamples i.e., fat, liver, muscles, paraffin wax, and contrast media were\nstacked at six different thickness levels in a stair-step chamber made from\nPlexi-glass. X-ray transmission at six different thicknesses of tissue samples\nwas also examined for five different energy (regions) thresholds (21 keV, 25\nkeV, 29 keV, 31 keV, and 45 keV) to determine the effect on count per second\n(CPS). In this study, 12 frames per second is found to be the optimum frame\nrate per second (FPS) based on the spectral response of an X-ray source and CPS\nhas a linear relationship with X-ray tube current as well. It was also noted\nthat A sample's thickness also affects its X-ray transmission at different\nenergy thresholds. A high sensitivity and linearity of the detectors make them\nsuitable for use in both preclinical and medical applications.", "published": "2024-01-04", "categories": ["physics.ins-det", "cs.LG", "eess.IV", "physics.med-ph"], "links": "http://arxiv.org/abs/2401.02106v1"}
{"title": "Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe", "author": "Mincong Huang, Chao Wang, Chi Ma, Yineng Zhang, Peng Zhang, Lei Yu", "abstract": "Pipeline parallelism is an essential technique in the training of large-scale\nTransformer models. However, it suffers from imbalanced memory consumption,\nleading to insufficient memory utilization. The BPipe technique was proposed to\naddress this issue and has proven effective in the GPT-3 model. Nevertheless,\nour experiments have not yielded similar benefits for LLaMA training.\nAdditionally, BPipe only yields negligible benefits for GPT-3 training when\napplying flash attention. We analyze the underlying causes of the divergent\nperformance of BPipe on GPT-3 and LLaMA. Furthermore, we introduce a novel\nmethod to estimate the performance of BPipe.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CL", "cs.DC"], "links": "http://arxiv.org/abs/2401.02088v1"}
{"title": "View-based Explanations for Graph Neural Networks", "author": "Tingyang Chen, Dazhuo Qiu, Yinghui Wu, Arijit Khan, Xiangyu Ke, Yunjun Gao", "abstract": "Generating explanations for graph neural networks (GNNs) has been studied to\nunderstand their behavior in analytical tasks such as graph classification.\nExisting approaches aim to understand the overall results of GNNs rather than\nproviding explanations for specific class labels of interest, and may return\nexplanation structures that are hard to access, nor directly queryable.\n  We propose GVEX, a novel paradigm that generates Graph Views for EXplanation.\n(1) We design a two-tier explanation structure called explanation views. An\nexplanation view consists of a set of graph patterns and a set of induced\nexplanation subgraphs. Given a database G of multiple graphs and a specific\nclass label l assigned by a GNN-based classifier M, it concisely describes the\nfraction of G that best explains why l is assigned by M. (2) We propose quality\nmeasures and formulate an optimization problem to compute optimal explanation\nviews for GNN explanation. We show that the problem is $\\Sigma^2_P$-hard. (3)\nWe present two algorithms. The first one follows an explain-and-summarize\nstrategy that first generates high-quality explanation subgraphs which best\nexplain GNNs in terms of feature influence maximization, and then performs a\nsummarization step to generate patterns. We show that this strategy provides an\napproximation ratio of 1/2. Our second algorithm performs a single-pass to an\ninput node stream in batches to incrementally maintain explanation views,\nhaving an anytime quality guarantee of 1/4 approximation. Using real-world\nbenchmark data, we experimentally demonstrate the effectiveness, efficiency,\nand scalability of GVEX. Through case studies, we showcase the practical\napplications of GVEX.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02086v1"}
{"title": "Energy based diffusion generator for efficient sampling of Boltzmann distributions", "author": "Yan Wang, Ling Guo, Hao Wu, Tao Zhou", "abstract": "We introduce a novel sampler called the energy based diffusion generator for\ngenerating samples from arbitrary target distributions. The sampling model\nemploys a structure similar to a variational autoencoder, utilizing a decoder\nto transform latent variables from a simple distribution into random variables\napproximating the target distribution, and we design an encoder based on the\ndiffusion model. Leveraging the powerful modeling capacity of the diffusion\nmodel for complex distributions, we can obtain an accurate variational estimate\nof the Kullback-Leibler divergence between the distributions of the generated\nsamples and the target. Moreover, we propose a decoder based on generalized\nHamiltonian dynamics to further enhance sampling performance. Through empirical\nevaluation, we demonstrate the effectiveness of our method across various\ncomplex distribution functions, showcasing its superiority compared to existing\nmethods.", "published": "2024-01-04", "categories": ["cs.LG", "stat.CO", "stat.ML"], "links": "http://arxiv.org/abs/2401.02080v1"}
{"title": "U-Trustworthy Models.Reliability, Competence, and Confidence in Decision-Making", "author": "Ritwik Vashistha, Arya Farahi", "abstract": "With growing concerns regarding bias and discrimination in predictive models,\nthe AI community has increasingly focused on assessing AI system\ntrustworthiness. Conventionally, trustworthy AI literature relies on the\nprobabilistic framework and calibration as prerequisites for trustworthiness.\nIn this work, we depart from this viewpoint by proposing a novel trust\nframework inspired by the philosophy literature on trust. We present a precise\nmathematical definition of trustworthiness, termed\n$\\mathcal{U}$-trustworthiness, specifically tailored for a subset of tasks\naimed at maximizing a utility function. We argue that a model's\n$\\mathcal{U}$-trustworthiness is contingent upon its ability to maximize Bayes\nutility within this task subset. Our first set of results challenges the\nprobabilistic framework by demonstrating its potential to favor less\ntrustworthy models and introduce the risk of misleading trustworthiness\nassessments. Within the context of $\\mathcal{U}$-trustworthiness, we prove that\nproperly-ranked models are inherently $\\mathcal{U}$-trustworthy. Furthermore,\nwe advocate for the adoption of the AUC metric as the preferred measure of\ntrustworthiness. By offering both theoretical guarantees and experimental\nvalidation, AUC enables robust evaluation of trustworthiness, thereby enhancing\nmodel selection and hyperparameter tuning to yield more trustworthy outcomes.", "published": "2024-01-04", "categories": ["stat.ML", "cs.LG"], "links": "http://arxiv.org/abs/2401.02062v1"}
{"title": "Neural Collapse for Cross-entropy Class-Imbalanced Learning with Unconstrained ReLU Feature Model", "author": "Hien Dang, Tho Tran, Tan Nguyen, Nhat Ho", "abstract": "The current paradigm of training deep neural networks for classification\ntasks includes minimizing the empirical risk that pushes the training loss\nvalue towards zero, even after the training error has been vanished. In this\nterminal phase of training, it has been observed that the last-layer features\ncollapse to their class-means and these class-means converge to the vertices of\na simplex Equiangular Tight Frame (ETF). This phenomenon is termed as Neural\nCollapse (NC). To theoretically understand this phenomenon, recent works employ\na simplified unconstrained feature model to prove that NC emerges at the global\nsolutions of the training problem. However, when the training dataset is\nclass-imbalanced, some NC properties will no longer be true. For example, the\nclass-means geometry will skew away from the simplex ETF when the loss\nconverges. In this paper, we generalize NC to imbalanced regime for\ncross-entropy loss under the unconstrained ReLU feature model. We prove that,\nwhile the within-class features collapse property still holds in this setting,\nthe class-means will converge to a structure consisting of orthogonal vectors\nwith different lengths. Furthermore, we find that the classifier weights are\naligned to the scaled and centered class-means with scaling factors depend on\nthe number of training samples of each class, which generalizes NC in the\nclass-balanced setting. We empirically prove our results through experiments on\npractical architectures and dataset.", "published": "2024-01-04", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.02058v1"}
{"title": "Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket", "author": "Zhaokun Zhou, Kaiwei Che, Wei Fang, Keyu Tian, Yuesheng Zhu, Shuicheng Yan, Yonghong Tian, Li Yuan", "abstract": "Spiking Neural Networks (SNNs), known for their biologically plausible\narchitecture, face the challenge of limited performance. The self-attention\nmechanism, which is the cornerstone of the high-performance Transformer and\nalso a biologically inspired structure, is absent in existing SNNs. To this\nend, we explore the potential of leveraging both self-attention capability and\nbiological properties of SNNs, and propose a novel Spiking Self-Attention (SSA)\nand Spiking Transformer (Spikformer). The SSA mechanism eliminates the need for\nsoftmax and captures the sparse visual feature employing spike-based Query,\nKey, and Value. This sparse computation without multiplication makes SSA\nefficient and energy-saving. Further, we develop a Spiking Convolutional Stem\n(SCS) with supplementary convolutional layers to enhance the architecture of\nSpikformer. The Spikformer enhanced with the SCS is referred to as Spikformer\nV2. To train larger and deeper Spikformer V2, we introduce a pioneering\nexploration of Self-Supervised Learning (SSL) within the SNN. Specifically, we\npre-train Spikformer V2 with masking and reconstruction style inspired by the\nmainstream self-supervised Transformer, and then finetune the Spikformer V2 on\nthe image classification on ImageNet. Extensive experiments show that\nSpikformer V2 outperforms other previous surrogate training and ANN2SNN\nmethods. An 8-layer Spikformer V2 achieves an accuracy of 80.38% using 4 time\nsteps, and after SSL, a 172M 16-layer Spikformer V2 reaches an accuracy of\n81.10% with just 1 time step. To the best of our knowledge, this is the first\ntime that the SNN achieves 80+% accuracy on ImageNet. The code will be\navailable at Spikformer V2.", "published": "2024-01-04", "categories": ["cs.NE", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.02020v1"}
{"title": "From Function to Distribution Modeling: A PAC-Generative Approach to Offline Optimization", "author": "Qiang Zhang, Ruida Zhou, Yang Shen, Tie Liu", "abstract": "This paper considers the problem of offline optimization, where the objective\nfunction is unknown except for a collection of ``offline\" data examples. While\nrecent years have seen a flurry of work on applying various machine learning\ntechniques to the offline optimization problem, the majority of these work\nfocused on learning a surrogate of the unknown objective function and then\napplying existing optimization algorithms. While the idea of modeling the\nunknown objective function is intuitive and appealing, from the learning point\nof view it also makes it very difficult to tune the objective of the learner\naccording to the objective of optimization. Instead of learning and then\noptimizing the unknown objective function, in this paper we take on a less\nintuitive but more direct view that optimization can be thought of as a process\nof sampling from a generative model. To learn an effective generative model\nfrom the offline data examples, we consider the standard technique of\n``re-weighting\", and our main technical contribution is a probably\napproximately correct (PAC) lower bound on the natural optimization objective,\nwhich allows us to jointly learn a weight function and a score-based generative\nmodel. The robustly competitive performance of the proposed approach is\ndemonstrated via empirical studies using the standard offline optimization\nbenchmarks.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02019v1"}
{"title": "SwitchTab: Switched Autoencoders Are Effective Tabular Learners", "author": "Jing Wu, Suiyao Chen, Qi Zhao, Renat Sergazinov, Chen Li, Shengjie Liu, Chongchao Zhao, Tianpei Xie, Hanqing Guo, Cheng Ji, Daniel Cociorva, Hakan Brunzel", "abstract": "Self-supervised representation learning methods have achieved significant\nsuccess in computer vision and natural language processing, where data samples\nexhibit explicit spatial or semantic dependencies. However, applying these\nmethods to tabular data is challenging due to the less pronounced dependencies\namong data samples. In this paper, we address this limitation by introducing\nSwitchTab, a novel self-supervised method specifically designed to capture\nlatent dependencies in tabular data. SwitchTab leverages an asymmetric\nencoder-decoder framework to decouple mutual and salient features among data\npairs, resulting in more representative embeddings. These embeddings, in turn,\ncontribute to better decision boundaries and lead to improved results in\ndownstream tasks. To validate the effectiveness of SwitchTab, we conduct\nextensive experiments across various domains involving tabular data. The\nresults showcase superior performance in end-to-end prediction tasks with\nfine-tuning. Moreover, we demonstrate that pre-trained salient embeddings can\nbe utilized as plug-and-play features to enhance the performance of various\ntraditional classification methods (e.g., Logistic Regression, XGBoost, etc.).\nLastly, we highlight the capability of SwitchTab to create explainable\nrepresentations through visualization of decoupled mutual and salient features\nin the latent space.", "published": "2024-01-04", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.02013v1"}
{"title": "Fast & Fair: Efficient Second-Order Robust Optimization for Fairness in Machine Learning", "author": "Allen Minch, Hung Anh Vu, Anne Marie Warren", "abstract": "This project explores adversarial training techniques to develop fairer Deep\nNeural Networks (DNNs) to mitigate the inherent bias they are known to exhibit.\nDNNs are susceptible to inheriting bias with respect to sensitive attributes\nsuch as race and gender, which can lead to life-altering outcomes (e.g.,\ndemographic bias in facial recognition software used to arrest a suspect). We\npropose a robust optimization problem, which we demonstrate can improve\nfairness in several datasets, both synthetic and real-world, using an affine\nlinear model. Leveraging second order information, we are able to find a\nsolution to our optimization problem more efficiently than a purely first order\nmethod.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CY", "cs.NA", "math.NA", "65F10, 65F22, 65K05, 90C47"], "links": "http://arxiv.org/abs/2401.02012v1"}
{"title": "Decentralized Multi-Task Online Convex Optimization Under Random Link Failures", "author": "Wenjing Yan, Xuanyu Cao", "abstract": "Decentralized optimization methods often entail information exchange between\nneighbors. Transmission failures can happen due to network congestion,\nhardware/software issues, communication outage, and other factors. In this\npaper, we investigate the random link failure problem in decentralized\nmulti-task online convex optimization, where agents have individual decisions\nthat are coupled with each other via pairwise constraints. Although widely used\nin constrained optimization, conventional saddle-point algorithms are not\ndirectly applicable here because of random packet dropping. To address this\nissue, we develop a robust decentralized saddle-point algorithm against random\nlink failures with heterogeneous probabilities by replacing the missing\ndecisions of neighbors with their latest received values. Then, by judiciously\nbounding the accumulated deviation stemming from this replacement, we first\nestablish that our algorithm achieves $\\mathcal{O}(\\sqrt{T})$ regret and\n$\\mathcal{O}(T^\\frac{3}{4})$ constraint violations for the full information\nscenario, where the complete information on the local cost function is revealed\nto each agent at the end of each time slot. These two bounds match, in order\nsense, the performance bounds of algorithms with perfect communications.\nFurther, we extend our algorithm and analysis to the two-point bandit feedback\nscenario, where only the values of the local cost function at two random points\nare disclosed to each agent sequentially. Performance bounds of the same orders\nas the full information case are derived. Finally, we corroborate the efficacy\nof the proposed algorithms and the analytical results through numerical\nsimulations.", "published": "2024-01-04", "categories": ["cs.LG", "math.OC"], "links": "http://arxiv.org/abs/2401.02011v1"}
{"title": "Two-Stage Surrogate Modeling for Data-Driven Design Optimization with Application to Composite Microstructure Generation", "author": "Farhad Pourkamali-Anaraki, Jamal F. Husseini, Evan J. Pineda, Brett A. Bednarcyk, Scott E. Stapleton", "abstract": "This paper introduces a novel two-stage machine learning-based surrogate\nmodeling framework to address inverse problems in scientific and engineering\nfields. In the first stage of the proposed framework, a machine learning model\ntermed the \"learner\" identifies a limited set of candidates within the input\ndesign space whose predicted outputs closely align with desired outcomes.\nSubsequently, in the second stage, a separate surrogate model, functioning as\nan \"evaluator,\" is employed to assess the reduced candidate space generated in\nthe first stage. This evaluation process eliminates inaccurate and uncertain\nsolutions, guided by a user-defined coverage level. The framework's distinctive\ncontribution is the integration of conformal inference, providing a versatile\nand efficient approach that can be widely applicable. To demonstrate the\neffectiveness of the proposed framework compared to conventional single-stage\ninverse problems, we conduct several benchmark tests and investigate an\nengineering application focused on the micromechanical modeling of\nfiber-reinforced composites. The results affirm the superiority of our proposed\nframework, as it consistently produces more reliable solutions. Therefore, the\nintroduced framework offers a unique perspective on fostering interactions\nbetween machine learning-based surrogate models in real-world applications.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CE"], "links": "http://arxiv.org/abs/2401.02008v1"}
