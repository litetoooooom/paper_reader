{"title": "Mean-Field Assisted Deep Boltzmann Learning with Probabilistic Computers", "author": "Shuvro Chowdhury, Shaila Niazi, Kerem Y. Camsari", "abstract": "Despite their appeal as physics-inspired, energy-based and generative nature,\ngeneral Boltzmann Machines (BM) are considered intractable to train. This\nbelief led to simplified models of BMs with restricted intralayer connections\nor layer-by-layer training of deep BMs. Recent developments in domain-specific\nhardware -- specifically probabilistic computers (p-computer) with\nprobabilistic bits (p-bit) -- may change established wisdom on the tractability\nof deep BMs. In this paper, we show that deep and unrestricted BMs can be\ntrained using p-computers generating hundreds of billions of Markov Chain Monte\nCarlo (MCMC) samples per second, on sparse networks developed originally for\nuse in D-Wave's annealers. To maximize the efficiency of learning the\np-computer, we introduce two families of Mean-Field Theory assisted learning\nalgorithms, or xMFTs (x = Naive and Hierarchical). The xMFTs are used to\nestimate the averages and correlations during the positive phase of the\ncontrastive divergence (CD) algorithm and our custom-designed p-computer is\nused to estimate the averages and correlations in the negative phase. A custom\nField-Programmable-Gate Array (FPGA) emulation of the p-computer architecture\ntakes up to 45 billion flips per second, allowing the implementation of CD-$n$\nwhere $n$ can be of the order of millions, unlike RBMs where $n$ is typically 1\nor 2. Experiments on the full MNIST dataset with the combined algorithm show\nthat the positive phase can be efficiently computed by xMFTs without much\ndegradation when the negative phase is computed by the p-computer. Our\nalgorithm can be used in other scalable Ising machines and its variants can be\nused to train BMs, previously thought to be intractable.", "published": "2024-01-03", "categories": ["cs.ET", "cs.AR", "cs.LG", "cs.NE"], "links": "http://arxiv.org/abs/2401.01996v1"}
{"title": "GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning", "author": "Aarash Feizi, Randall Balestriero, Adriana Romero-Soriano, Reihaneh Rabbany", "abstract": "We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a\ngeneral method to inject a priori knowledge into Self-Supervised Learning (SSL)\npositive samples selection. Current SSL methods leverage Data-Augmentations\n(DA) for generating positive samples and incorporate prior knowledge - an\nincorrect, or too weak DA will drastically reduce the quality of the learned\nrepresentation. GPS-SSL proposes instead to design a metric space where\nEuclidean distances become a meaningful proxy for semantic relationship. In\nthat space, it is now possible to generate positive samples from nearest\nneighbor sampling. Any prior knowledge can now be embedded into that metric\nspace independently from the employed DA. From its simplicity, GPS-SSL is\napplicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is\nin reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches\n85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We\ntherefore move a step forward towards the goal of making SSL less reliant on\nDA. We also show that even when using strong DAs, GPS-SSL outperforms the\nbaselines on under-studied domains. We evaluate GPS-SSL along with multiple\nbaseline SSL methods on numerous downstream datasets from different domains\nwhen the models use strong or minimal data augmentations. We hope that GPS-SSL\nwill open new avenues in studying how to inject a priori knowledge into SSL in\na principled manner.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01990v1"}
{"title": "Representation Learning of Multivariate Time Series using Attention and Adversarial Training", "author": "Leon Scharwächter, Sebastian Otte", "abstract": "A critical factor in trustworthy machine learning is to develop robust\nrepresentations of the training data. Only under this guarantee methods are\nlegitimate to artificially generate data, for example, to counteract imbalanced\ndatasets or provide counterfactual explanations for blackbox decision-making\nsystems. In recent years, Generative Adversarial Networks (GANs) have shown\nconsiderable results in forming stable representations and generating realistic\ndata. While many applications focus on generating image data, less effort has\nbeen made in generating time series data, especially multivariate signals. In\nthis work, a Transformer-based autoencoder is proposed that is regularized\nusing an adversarial training scheme to generate artificial multivariate time\nseries signals. The representation is evaluated using t-SNE visualizations,\nDynamic Time Warping (DTW) and Entropy scores. Our results indicate that the\ngenerated signals exhibit higher similarity to an exemplary dataset than using\na convolutional network approach.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01987v1"}
{"title": "Beyond Regrets: Geometric Metrics for Bayesian Optimization", "author": "Jungtaek Kim", "abstract": "Bayesian optimization is a principled optimization strategy for a black-box\nobjective function. It shows its effectiveness in a wide variety of real-world\napplications such as scientific discovery and experimental design. In general,\nthe performance of Bayesian optimization is assessed by regret-based metrics\nsuch as instantaneous, simple, and cumulative regrets. These metrics only rely\non function evaluations, so that they do not consider geometric relationships\nbetween query points and global solutions, or query points themselves. Notably,\nthey cannot discriminate if multiple global solutions are successfully found.\nMoreover, they do not evaluate Bayesian optimization's abilities to exploit and\nexplore a search space given. To tackle these issues, we propose four new\ngeometric metrics, i.e., precision, recall, average degree, and average\ndistance. These metrics allow us to compare Bayesian optimization algorithms\nconsidering the geometry of both query points and global optima, or query\npoints. However, they are accompanied by an extra parameter, which needs to be\ncarefully determined. We therefore devise the parameter-free forms of the\nrespective metrics by integrating out the additional parameter. Finally, we\nempirically validate that our proposed metrics can provide more convincing\ninterpretation and understanding of Bayesian optimization algorithms from\ndistinct perspectives, compared to the conventional metrics.", "published": "2024-01-03", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.01981v1"}
{"title": "Tailor: Size Recommendations for High-End Fashion Marketplaces", "author": "Alexandre Candeias, Ivo Silva, Vitor Sousa, José Marcelino", "abstract": "In the ever-changing and dynamic realm of high-end fashion marketplaces,\nproviding accurate and personalized size recommendations has become a critical\naspect. Meeting customer expectations in this regard is not only crucial for\nensuring their satisfaction but also plays a pivotal role in driving customer\nretention, which is a key metric for the success of any fashion retailer. We\npropose a novel sequence classification approach to address this problem,\nintegrating implicit (Add2Bag) and explicit (ReturnReason) user signals. Our\napproach comprises two distinct models: one employs LSTMs to encode the user\nsignals, while the other leverages an Attention mechanism. Our best model\noutperforms SFNet, improving accuracy by 45.7%. By using Add2Bag interactions\nwe increase the user coverage by 24.5% when compared with only using Orders.\nMoreover, we evaluate the models' usability in real-time recommendation\nscenarios by conducting experiments to measure their latency performance.", "published": "2024-01-03", "categories": ["cs.IR", "cs.LG"], "links": "http://arxiv.org/abs/2401.01978v1"}
{"title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers", "author": "Aleksandar Stanić, Sergi Caelles, Michael Tschannen", "abstract": "Visual reasoning is dominated by end-to-end neural networks scaled to\nbillions of model parameters and training examples. However, even the largest\nmodels struggle with compositional reasoning, generalization, fine-grained\nspatial and temporal reasoning, and counting. Visual reasoning with large\nlanguage models (LLMs) as controllers can, in principle, address these\nlimitations by decomposing the task and solving subtasks by orchestrating a set\nof (visual) tools. Recently, these models achieved great performance on tasks\nsuch as compositional visual question answering, visual grounding, and video\ntemporal reasoning. Nevertheless, in their current form, these models heavily\nrely on human engineering of in-context examples in the prompt, which are often\ndataset- and task-specific and require significant labor by highly skilled\nprogrammers. In this work, we present a framework that mitigates these issues\nby introducing spatially and temporally abstract routines and by leveraging a\nsmall number of labeled examples to automatically generate in-context examples,\nthereby avoiding human-created in-context examples. On a number of visual\nreasoning tasks, we show that our framework leads to consistent gains in\nperformance, makes LLMs as controllers setup more robust, and removes the need\nfor human engineering of in-context examples.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01974v1"}
{"title": "Can We Generate Realistic Hands Only Using Convolution?", "author": "Mehran Hosseini, Peyman Hosseini", "abstract": "The enduring inability of image generative models to recreate intricate\ngeometric features, such as those present in human hands and fingers has been\nan ongoing problem in image generation for nearly a decade. While strides have\nbeen made by increasing model sizes and diversifying training datasets, this\nissue remains prevalent across all models, from denoising diffusion models to\nGenerative Adversarial Networks (GAN), pointing to a fundamental shortcoming in\nthe underlying architectures. In this paper, we demonstrate how this problem\ncan be mitigated by augmenting convolution layers geometric capabilities\nthrough providing them with a single input channel incorporating the relative\n$n$-dimensional Cartesian coordinate system. We show that this drastically\nimproves quality of hand and face images generated by GANs and Variational\nAutoEncoders (VAE).", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG", "51", "I.2.10; I.4.0; I.4.10"], "links": "http://arxiv.org/abs/2401.01951v1"}
{"title": "Mining Temporal Attack Patterns from Cyberthreat Intelligence Reports", "author": "Md Rayhanur Rahman, Brandon Wroblewski, Quinn Matthews, Brantley Morgan, Tim Menzies, Laurie Williams", "abstract": "Defending from cyberattacks requires practitioners to operate on high-level\nadversary behavior. Cyberthreat intelligence (CTI) reports on past cyberattack\nincidents describe the chain of malicious actions with respect to time. To\navoid repeating cyberattack incidents, practitioners must proactively identify\nand defend against recurring chain of actions - which we refer to as temporal\nattack patterns. Automatically mining the patterns among actions provides\nstructured and actionable information on the adversary behavior of past\ncyberattacks. The goal of this paper is to aid security practitioners in\nprioritizing and proactive defense against cyberattacks by mining temporal\nattack patterns from cyberthreat intelligence reports. To this end, we propose\nChronoCTI, an automated pipeline for mining temporal attack patterns from\ncyberthreat intelligence (CTI) reports of past cyberattacks. To construct\nChronoCTI, we build the ground truth dataset of temporal attack patterns and\napply state-of-the-art large language models, natural language processing, and\nmachine learning techniques. We apply ChronoCTI on a set of 713 CTI reports,\nwhere we identify 124 temporal attack patterns - which we categorize into nine\npattern categories. We identify that the most prevalent pattern category is to\ntrick victim users into executing malicious code to initiate the attack,\nfollowed by bypassing the anti-malware system in the victim network. Based on\nthe observed patterns, we advocate organizations to train users about\ncybersecurity best practices, introduce immutable operating systems with\nlimited functionalities, and enforce multi-user authentications. Moreover, we\nadvocate practitioners to leverage the automated mining capability of ChronoCTI\nand design countermeasures against the recurring attack patterns.", "published": "2024-01-03", "categories": ["cs.CR", "cs.IR", "cs.LG", "cs.SE"], "links": "http://arxiv.org/abs/2401.01883v1"}
{"title": "Theoretical guarantees on the best-of-n alignment policy", "author": "Ahmad Beirami, Alekh Agarwal, Jonathan Berant, Alexander D'Amour, Jacob Eisenstein, Chirag Nagpal, Ananda Theertha Suresh", "abstract": "A simple and effective method for the alignment of generative models is the\nbest-of-$n$ policy, where $n$ samples are drawn from a base policy, and ranked\nbased on a reward function, and the highest ranking one is selected. A commonly\nused analytical expression in the literature claims that the KL divergence\nbetween the best-of-$n$ policy and the base policy is equal to $\\log (n) -\n(n-1)/n.$ We disprove the validity of this claim, and show that it is an upper\nbound on the actual KL divergence. We also explore the tightness of this upper\nbound in different regimes. Finally, we propose a new estimator for the KL\ndivergence and empirically show that it provides a tight approximation through\na few examples.", "published": "2024-01-03", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "links": "http://arxiv.org/abs/2401.01879v1"}
{"title": "Graph Neural Networks for Surfactant Multi-Property Prediction", "author": "Christoforos Brozos, Jan G. Rittig, Sandip Bhattacharya, Elie Akanny, Christina Kohlmann, Alexander Mitsos", "abstract": "Surfactants are of high importance in different industrial sectors such as\ncosmetics, detergents, oil recovery and drug delivery systems. Therefore, many\nquantitative structure-property relationship (QSPR) models have been developed\nfor surfactants. Each predictive model typically focuses on one surfactant\nclass, mostly nonionics. Graph Neural Networks (GNNs) have exhibited a great\npredictive performance for property prediction of ionic liquids, polymers and\ndrugs in general. Specifically for surfactants, GNNs can successfully predict\ncritical micelle concentration (CMC), a key surfactant property associated with\nmicellization. A key factor in the predictive ability of QSPR and GNN models is\nthe data available for training. Based on extensive literature search, we\ncreate the largest available CMC database with 429 molecules and the first\nlarge data collection for surface excess concentration ($\\Gamma$$_{m}$),\nanother surfactant property associated with foaming, with 164 molecules. Then,\nwe develop GNN models to predict the CMC and $\\Gamma$$_{m}$ and we explore\ndifferent learning approaches, i.e., single- and multi-task learning, as well\nas different training strategies, namely ensemble and transfer learning. We\nfind that a multi-task GNN with ensemble learning trained on all $\\Gamma$$_{m}$\nand CMC data performs best. Finally, we test the ability of our CMC model to\ngeneralize on industrial grade pure component surfactants. The GNN yields\nhighly accurate predictions for CMC, showing great potential for future\nindustrial applications.", "published": "2024-01-03", "categories": ["physics.chem-ph", "cs.LG"], "links": "http://arxiv.org/abs/2401.01874v1"}
{"title": "On the hardness of learning under symmetries", "author": "Bobak T. Kiani, Thien Le, Hannah Lawrence, Stefanie Jegelka, Melanie Weber", "abstract": "We study the problem of learning equivariant neural networks via gradient\ndescent. The incorporation of known symmetries (\"equivariance\") into neural\nnets has empirically improved the performance of learning pipelines, in domains\nranging from biology to computer vision. However, a rich yet separate line of\nlearning theoretic research has demonstrated that actually learning shallow,\nfully-connected (i.e. non-symmetric) networks has exponential complexity in the\ncorrelational statistical query (CSQ) model, a framework encompassing gradient\ndescent. In this work, we ask: are known problem symmetries sufficient to\nalleviate the fundamental hardness of learning neural nets with gradient\ndescent? We answer this question in the negative. In particular, we give lower\nbounds for shallow graph neural networks, convolutional networks, invariant\npolynomials, and frame-averaged networks for permutation subgroups, which all\nscale either superpolynomially or exponentially in the relevant input\ndimension. Therefore, in spite of the significant inductive bias imparted via\nsymmetry, actually learning the complete classes of functions represented by\nequivariant neural networks via gradient descent remains hard.", "published": "2024-01-03", "categories": ["cs.LG", "cs.DS", "math.ST", "stat.ML", "stat.TH"], "links": "http://arxiv.org/abs/2401.01869v1"}
{"title": "Dataset Difficulty and the Role of Inductive Bias", "author": "Devin Kwok, Nikhil Anand, Jonathan Frankle, Gintare Karolina Dziugaite, David Rolnick", "abstract": "Motivated by the goals of dataset pruning and defect identification, a\ngrowing body of methods have been developed to score individual examples within\na dataset. These methods, which we call \"example difficulty scores\", are\ntypically used to rank or categorize examples, but the consistency of rankings\nbetween different training runs, scoring methods, and model architectures is\ngenerally unknown. To determine how example rankings vary due to these random\nand controlled effects, we systematically compare different formulations of\nscores over a range of runs and model architectures. We find that scores\nlargely share the following traits: they are noisy over individual runs of a\nmodel, strongly correlated with a single notion of difficulty, and reveal\nexamples that range from being highly sensitive to insensitive to the inductive\nbiases of certain model architectures. Drawing from statistical genetics, we\ndevelop a simple method for fingerprinting model architectures using a few\nsensitive examples. These findings guide practitioners in maximizing the\nconsistency of their scores (e.g. by choosing appropriate scoring methods,\nnumber of runs, and subsets of examples), and establishes comprehensive\nbaselines for evaluating scores in the future.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01867v1"}
{"title": "A Vision Check-up for Language Models", "author": "Pratyusha Sharma, Tamar Rott Shaham, Manel Baradad, Stephanie Fu, Adrian Rodriguez-Munoz, Shivam Duggal, Phillip Isola, Antonio Torralba", "abstract": "What does learning to model relationships between strings teach large\nlanguage models (LLMs) about the visual world? We systematically evaluate LLMs'\nabilities to generate and recognize an assortment of visual concepts of\nincreasing complexity and then demonstrate how a preliminary visual\nrepresentation learning system can be trained using models of text. As language\nmodels lack the ability to consume or output visual information as pixels, we\nuse code to represent images in our study. Although LLM-generated images do not\nlook like natural images, results on image generation and the ability of models\nto correct these generated images indicate that precise modeling of strings can\nteach language models about numerous aspects of the visual world. Furthermore,\nexperiments on self-supervised visual representation learning, utilizing images\ngenerated with text models, highlight the potential to train vision models\ncapable of making semantic assessments of natural images using just LLMs.", "published": "2024-01-03", "categories": ["cs.CV", "cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.01862v1"}
{"title": "IoT in the Era of Generative AI: Vision and Challenges", "author": "Xin Wang, Zhongwei Wan, Arvin Hekmati, Mingyu Zong, Samiul Alam, Mi Zhang, Bhaskar Krishnamachari", "abstract": "Equipped with sensing, networking, and computing capabilities, Internet of\nThings (IoT) such as smartphones, wearables, smart speakers, and household\nrobots have been seamlessly weaved into our daily lives. Recent advancements in\nGenerative AI exemplified by GPT, LLaMA, DALL-E, and Stable Difussion hold\nimmense promise to push IoT to the next level. In this article, we share our\nvision and views on the benefits that Generative AI brings to IoT, and discuss\nsome of the most important applications of Generative AI in IoT-related\ndomains. Fully harnessing Generative AI in IoT is a complex challenge. We\nidentify some of the most critical challenges including high resource demands\nof the Generative AI models, prompt engineering, on-device inference,\noffloading, on-device fine-tuning, federated learning, security, as well as\ndevelopment tools and benchmarks, and discuss current gaps as well as promising\nopportunities on enabling Generative AI for IoT. We hope this article can\ninspire new research on IoT in the era of Generative AI.", "published": "2024-01-03", "categories": ["cs.DC", "cs.LG", "cs.NI"], "links": "http://arxiv.org/abs/2401.01923v1"}
{"title": "Optimal cross-learning for contextual bandits with unknown context distributions", "author": "Jon Schneider, Julian Zimmert", "abstract": "We consider the problem of designing contextual bandit algorithms in the\n``cross-learning'' setting of Balseiro et al., where the learner observes the\nloss for the action they play in all possible contexts, not just the context of\nthe current round. We specifically consider the setting where losses are chosen\nadversarially and contexts are sampled i.i.d. from an unknown distribution. In\nthis setting, we resolve an open problem of Balseiro et al. by providing an\nefficient algorithm with a nearly tight (up to logarithmic factors) regret\nbound of $\\widetilde{O}(\\sqrt{TK})$, independent of the number of contexts. As\na consequence, we obtain the first nearly tight regret bounds for the problems\nof learning to bid in first-price auctions (under unknown value distributions)\nand sleeping bandits with a stochastic action set.\n  At the core of our algorithm is a novel technique for coordinating the\nexecution of a learning algorithm over multiple epochs in such a way to remove\ncorrelations between estimation of the unknown distribution and the actions\nplayed by the algorithm. This technique may be of independent interest for\nother learning problems involving estimation of an unknown context\ndistribution.", "published": "2024-01-03", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.01857v1"}
{"title": "Transformer Neural Autoregressive Flows", "author": "Massimiliano Patacchiola, Aliaksandra Shysheya, Katja Hofmann, Richard E. Turner", "abstract": "Density estimation, a central problem in machine learning, can be performed\nusing Normalizing Flows (NFs). NFs comprise a sequence of invertible\ntransformations, that turn a complex target distribution into a simple one, by\nexploiting the change of variables theorem. Neural Autoregressive Flows (NAFs)\nand Block Neural Autoregressive Flows (B-NAFs) are arguably the most perfomant\nmembers of the NF family. However, they suffer scalability issues and training\ninstability due to the constraints imposed on the network structure. In this\npaper, we propose a novel solution to these challenges by exploiting\ntransformers to define a new class of neural flows called Transformer Neural\nAutoregressive Flows (T-NAFs). T-NAFs treat each dimension of a random variable\nas a separate input token, using attention masking to enforce an autoregressive\nconstraint. We take an amortization-inspired approach where the transformer\noutputs the parameters of an invertible transformation. The experimental\nresults demonstrate that T-NAFs consistently match or outperform NAFs and\nB-NAFs across multiple datasets from the UCI benchmark. Remarkably, T-NAFs\nachieve these results using an order of magnitude fewer parameters than\nprevious approaches, without composing multiple flows.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01855v1"}
{"title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality", "author": "Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, Matan Eyal", "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. One promising approach is cross-lingual transfer, where a model\nacquires specific functionality on some language by finetuning on another\nlanguage. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages. We\nfirst show that many languages transfer some instruction-following capabilities\nto other languages from even monolingual tuning. Furthermore, we find that only\n40 multilingual examples in an English tuning set substantially improve\nmultilingual instruction-following, both in seen and unseen languages during\ntuning. In general, we observe that models tuned on multilingual mixtures\nexhibit comparable or superior performance in several languages compared to\nmonolingually tuned models, despite training on 10x fewer examples in those\nlanguages. Finally, we find that increasing the number of languages in the\ninstruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual\ngeneralization. Our results suggest that building massively multilingual\ninstruction-tuned models can be done with only a very small set of multilingual\ninstruction-responses.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01854v1"}
{"title": "The Power of Training: How Different Neural Network Setups Influence the Energy Demand", "author": "Daniel Geißler, Bo Zhou, Mengxi Liu, Sungho Suh, Paul Lukowicz", "abstract": "This work examines the effects of variations in machine learning training\nregimes and learning paradigms on the corresponding energy consumption. While\nincreasing data availability and innovation in high-performance hardware fuels\nthe training of sophisticated models, it also supports the fading perception of\nenergy consumption and carbon emission. Therefore, the goal of this work is to\ncreate awareness about the energy impact of general training parameters and\nprocesses, from learning rate over batch size to knowledge transfer. Multiple\nsetups with different hyperparameter initializations are evaluated on two\ndifferent hardware configurations to obtain meaningful results. Experiments on\npretraining and multitask training are conducted on top of the baseline results\nto determine their potential towards sustainable machine learning.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.PF"], "links": "http://arxiv.org/abs/2401.01851v1"}
{"title": "DGDNN: Decoupled Graph Diffusion Neural Network for Stock Movement Prediction", "author": "Zinuo You, Zijian Shi, Hongbo Bo, John Cartlidge, Li Zhang, Yan Ge", "abstract": "Forecasting future stock trends remains challenging for academia and industry\ndue to stochastic inter-stock dynamics and hierarchical intra-stock dynamics\ninfluencing stock prices. In recent years, graph neural networks have achieved\nremarkable performance in this problem by formulating multiple stocks as\ngraph-structured data. However, most of these approaches rely on artificially\ndefined factors to construct static stock graphs, which fail to capture the\nintrinsic interdependencies between stocks that rapidly evolve. In addition,\nthese methods often ignore the hierarchical features of the stocks and lose\ndistinctive information within. In this work, we propose a novel graph learning\napproach implemented without expert knowledge to address these issues. First,\nour approach automatically constructs dynamic stock graphs by entropy-driven\nedge generation from a signal processing perspective. Then, we further learn\ntask-optimal dependencies between stocks via a generalized graph diffusion\nprocess on constructed stock graphs. Last, a decoupled representation learning\nscheme is adopted to capture distinctive hierarchical intra-stock features.\nExperimental results demonstrate substantial improvements over state-of-the-art\nbaselines on real-world datasets. Moreover, the ablation study and sensitivity\nstudy further illustrate the effectiveness of the proposed method in modeling\nthe time-evolving inter-stock and intra-stock dynamics.", "published": "2024-01-03", "categories": ["cs.LG", "cs.NE"], "links": "http://arxiv.org/abs/2401.01846v1"}
{"title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets", "author": "Himmet Toprak Kesgin, Mehmet Fatih Amasyali", "abstract": "Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01843v1"}
{"title": "Wasserstein Nonnegative Tensor Factorization with Manifold Regularization", "author": "Jianyu Wang, Linruize Tang", "abstract": "Nonnegative tensor factorization (NTF) has become an important tool for\nfeature extraction and part-based representation with preserved intrinsic\nstructure information from nonnegative high-order data. However, the original\nNTF methods utilize Euclidean or Kullback-Leibler divergence as the loss\nfunction which treats each feature equally leading to the neglect of the\nside-information of features. To utilize correlation information of features\nand manifold information of samples, we introduce Wasserstein manifold\nnonnegative tensor factorization (WMNTF), which minimizes the Wasserstein\ndistance between the distribution of input tensorial data and the distribution\nof reconstruction. Although some researches about Wasserstein distance have\nbeen proposed in nonnegative matrix factorization (NMF), they ignore the\nspatial structure information of higher-order data. We use Wasserstein distance\n(a.k.a Earth Mover's distance or Optimal Transport distance) as a metric and\nadd a graph regularizer to a latent factor. Experimental results demonstrate\nthe effectiveness of the proposed method compared with other NMF and NTF\nmethods.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01842v1"}
{"title": "Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes", "author": "Baiting Luo, Yunuo Zhang, Abhishek Dubey, Ayan Mukhopadhyay", "abstract": "A fundamental (and largely open) challenge in sequential decision-making is\ndealing with non-stationary environments, where exogenous environmental\nconditions change over time. Such problems are traditionally modeled as\nnon-stationary Markov decision processes (NSMDP). However, existing approaches\nfor decision-making in NSMDPs have two major shortcomings: first, they assume\nthat the updated environmental dynamics at the current time are known (although\nfuture dynamics can change); and second, planning is largely pessimistic, i.e.,\nthe agent acts ``safely'' to account for the non-stationary evolution of the\nenvironment. We argue that both these assumptions are invalid in practice --\nupdated environmental conditions are rarely known, and as the agent interacts\nwith the environment, it can learn about the updated dynamics and avoid being\npessimistic, at least in states whose dynamics it is confident about. We\npresent a heuristic search algorithm called \\textit{Adaptive Monte Carlo Tree\nSearch (ADA-MCTS)} that addresses these challenges. We show that the agent can\nlearn the updated dynamics of the environment over time and then act as it\nlearns, i.e., if the agent is in a region of the state space about which it has\nupdated knowledge, it can avoid being pessimistic. To quantify ``updated\nknowledge,'' we disintegrate the aleatoric and epistemic uncertainty in the\nagent's updated belief and show how the agent can use these estimates for\ndecision-making. We compare the proposed approach with the multiple\nstate-of-the-art approaches in decision-making across multiple well-established\nopen-source problems and empirically show that our approach is faster and\nhighly adaptive without sacrificing safety.", "published": "2024-01-03", "categories": ["cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01841v1"}
{"title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling", "author": "Himmet Toprak Kesgin, Mehmet Fatih Amasyali", "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01830v1"}
{"title": "Signal Processing in the Retina: Interpretable Graph Classifier to Predict Ganglion Cell Responses", "author": "Yasaman Parhizkar, Gene Cheung, Andrew W. Eckford", "abstract": "It is a popular hypothesis in neuroscience that ganglion cells in the retina\nare activated by selectively detecting visual features in an observed scene.\nWhile ganglion cell firings can be predicted via data-trained deep neural nets,\nthe networks remain indecipherable, thus providing little understanding of the\ncells' underlying operations. To extract knowledge from the cell firings, in\nthis paper we learn an interpretable graph-based classifier from data to\npredict the firings of ganglion cells in response to visual stimuli.\nSpecifically, we learn a positive semi-definite (PSD) metric matrix $\\mathbf{M}\n\\succeq 0$ that defines Mahalanobis distances between graph nodes (visual\nevents) endowed with pre-computed feature vectors; the computed inter-node\ndistances lead to edge weights and a combinatorial graph that is amenable to\nbinary classification. Mathematically, we define the objective of metric matrix\n$\\mathbf{M}$ optimization using a graph adaptation of large margin nearest\nneighbor (LMNN), which is rewritten as a semi-definite programming (SDP)\nproblem. We solve it efficiently via a fast approximation called Gershgorin\ndisc perfect alignment (GDPA) linearization. The learned metric matrix\n$\\mathbf{M}$ provides interpretability: important features are identified along\n$\\mathbf{M}$'s diagonal, and their mutual relationships are inferred from\noff-diagonal terms. Our fast metric learning framework can be applied to other\nbiological systems with pre-chosen features that require interpretation.", "published": "2024-01-03", "categories": ["cs.LG", "eess.IV", "q-bio.NC", "q-bio.QM"], "links": "http://arxiv.org/abs/2401.01813v1"}
{"title": "A quatum inspired neural network for geometric modeling", "author": "Weitao Du, Shengchao Liu, Hongyu Guo", "abstract": "By conceiving physical systems as 3D many-body point clouds, geometric graph\nneural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased\npromising performance. In particular, their effective message-passing mechanics\nmake them adept at modeling molecules and crystalline materials. However,\ncurrent geometric GNNs only offer a mean-field approximation of the many-body\nsystem, encapsulated within two-body message passing, thus falling short in\ncapturing intricate relationships within these geometric graphs. To address\nthis limitation, tensor networks, widely employed by computational physics to\nhandle manybody systems using high-order tensors, have been introduced.\nNevertheless, integrating these tensorized networks into the message-passing\nframework of GNNs faces scalability and symmetry conservation (e.g.,\npermutation and rotation) challenges. In response, we introduce an innovative\nequivariant Matrix Product State (MPS)-based message-passing strategy, through\nachieving an efficient implementation of the tensor contraction operation. Our\nmethod effectively models complex many-body relationships, suppressing\nmean-field approximations, and captures symmetries within geometric graphs.\nImportantly, it seamlessly replaces the standard message-passing and\nlayer-aggregation modules intrinsic to geometric GNNs. We empirically validate\nthe superior accuracy of our approach on benchmark tasks, including predicting\nclassical Newton systems and quantum tensor Hamiltonian matrices. To our\nknowledge, our approach represents the inaugural utilization of parameterized\ngeometric tensor networks.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "links": "http://arxiv.org/abs/2401.01801v1"}
{"title": "CoMoSVC: Consistency Model-based Singing Voice Conversion", "author": "Yiwen Lu, Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, Yike Guo", "abstract": "The diffusion-based Singing Voice Conversion (SVC) methods have achieved\nremarkable performances, producing natural audios with high similarity to the\ntarget timbre. However, the iterative sampling process results in slow\ninference speed, and acceleration thus becomes crucial. In this paper, we\npropose CoMoSVC, a consistency model-based SVC method, which aims to achieve\nboth high-quality generation and high-speed sampling. A diffusion-based teacher\nmodel is first specially designed for SVC, and a student model is further\ndistilled under self-consistency properties to achieve one-step sampling.\nExperiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a\nsignificantly faster inference speed than the state-of-the-art (SOTA)\ndiffusion-based SVC system, it still achieves comparable or superior conversion\nperformance based on both subjective and objective metrics. Audio samples and\ncodes are available at https://comosvc.github.io/.", "published": "2024-01-03", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.01792v1"}
{"title": "Deep learning the Hurst parameter of linear fractional processes and assessing its reliability", "author": "Dániel Boros, Bálint Csanády, Iván Ivkovic, Lóránt Nagy, András Lukács, László Márkus", "abstract": "This research explores the reliability of deep learning, specifically Long\nShort-Term Memory (LSTM) networks, for estimating the Hurst parameter in\nfractional stochastic processes. The study focuses on three types of processes:\nfractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process,\nand linear fractional stable motions (lfsm). The work involves a fast\ngeneration of extensive datasets for fBm and fOU to train the LSTM network on a\nlarge volume of data in a feasible time. The study analyses the accuracy of the\nLSTM network's Hurst parameter estimation regarding various performance\nmeasures like RMSE, MAE, MRE, and quantiles of the absolute and relative\nerrors. It finds that LSTM outperforms the traditional statistical methods in\nthe case of fBm and fOU processes; however, it has limited accuracy on lfsm\nprocesses. The research also delves into the implications of training length\nand valuation sequence length on the LSTM's performance. The methodology is\napplied by estimating the Hurst parameter in Li-ion battery degradation data\nand obtaining confidence bounds for the estimation. The study concludes that\nwhile deep learning methods show promise in parameter estimation of fractional\nprocesses, their effectiveness is contingent on the process type and the\nquality of training data.", "published": "2024-01-03", "categories": ["stat.ML", "cs.AI", "cs.LG", "68T07"], "links": "http://arxiv.org/abs/2401.01789v1"}
{"title": "Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review", "author": "Ihsane Gryech, Chaimae Assad, Mounir Ghogho, Abdellatif Kobbane", "abstract": "According to the World Health Organization (WHO), air pollution kills seven\nmillion people every year. Outdoor air pollution is a major environmental\nhealth problem affecting low, middle, and high-income countries. In the past\nfew years, the research community has explored IoT-enabled machine learning\napplications for outdoor air pollution prediction. The general objective of\nthis paper is to systematically review applications of machine learning and\nInternet of Things (IoT) for outdoor air pollution prediction and the\ncombination of monitoring sensors and input features used. Two research\nquestions were formulated for this review. 1086 publications were collected in\nthe initial PRISMA stage. After the screening and eligibility phases, 37 papers\nwere selected for inclusion. A cost-based analysis was conducted on the\nfindings to highlight high-cost monitoring, low-cost IoT and hybrid enabled\nprediction. Three methods of prediction were identified: time series,\nfeature-based and spatio-temporal. This review's findings identify major\nlimitations in applications found in the literature, namely lack of coverage,\nlack of diversity of data and lack of inclusion of context-specific features.\nThis review proposes directions for future research and underlines practical\nimplications in healthcare, urban planning, global synergy and smart cities.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01788v1"}
{"title": "Approximating Numerical Flux by Fourier Neural Operators for the Hyperbolic Conservation Laws", "author": "Taeyoung Kim, Myungjoo Kang", "abstract": "Classical numerical schemes exist for solving PDEs numerically, and recently,\nneural network-based methods have been developed. However, methodologies using\nneural networks, such as PINN and neural operators, lack robustness and\ngeneralization power. To compensate for such drawbacks, there are many types of\nresearch combining classical numerical schemes and machine learning methods by\nreplacing a small portion of the numerical schemes with neural networks. In\nthis work, we focus on hyperbolic conservation laws and replace numerical\nfluxes in the numerical schemes by neural operator. For this, we construct\nlosses that are motivated by numerical schemes for conservation laws and\napproximate numerical flux by FNO. Through experiments, we show that our\nmethodology has advantages of both numerical schemes and FNO by comparing with\noriginal methods. For instance, we demonstrate our method gains robustness,\nresolution invariance property, and feasibility of a data-driven method. Our\nmethod especially has the ability to predict continuously in time and\ngeneralization power on the out-of-distribution samples, which are challenges\nto be tackled for existing neural operator methods.", "published": "2024-01-03", "categories": ["math.NA", "cs.LG", "cs.NA"], "links": "http://arxiv.org/abs/2401.01783v2"}
{"title": "Unsupervised Object-Centric Learning from Multiple Unspecified Viewpoints", "author": "Jinyang Yuan, Tonglin Chen, Zhimeng Shen, Bin Li, Xiangyang Xue", "abstract": "Visual scenes are extremely diverse, not only because there are infinite\npossible combinations of objects and backgrounds but also because the\nobservations of the same scene may vary greatly with the change of viewpoints.\nWhen observing a multi-object visual scene from multiple viewpoints, humans can\nperceive the scene compositionally from each viewpoint while achieving the\nso-called ``object constancy'' across different viewpoints, even though the\nexact viewpoints are untold. This ability is essential for humans to identify\nthe same object while moving and to learn from vision efficiently. It is\nintriguing to design models that have a similar ability. In this paper, we\nconsider a novel problem of learning compositional scene representations from\nmultiple unspecified (i.e., unknown and unrelated) viewpoints without using any\nsupervision and propose a deep generative model which separates latent\nrepresentations into a viewpoint-independent part and a viewpoint-dependent\npart to solve this problem. During the inference, latent representations are\nrandomly initialized and iteratively updated by integrating the information in\ndifferent viewpoints with neural networks. Experiments on several specifically\ndesigned synthetic datasets have shown that the proposed method can effectively\nlearn from multiple unspecified viewpoints.", "published": "2024-01-03", "categories": ["cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01922v1"}
{"title": "Investigating the Suitability of Concept Drift Detection for Detecting Leakages in Water Distribution Networks", "author": "Valerie Vaquet, Fabian Hinder, Barbara Hammer", "abstract": "Leakages are a major risk in water distribution networks as they cause water\nloss and increase contamination risks. Leakage detection is a difficult task\ndue to the complex dynamics of water distribution networks. In particular,\nsmall leakages are hard to detect. From a machine-learning perspective,\nleakages can be modeled as concept drift. Thus, a wide variety of drift\ndetection schemes seems to be a suitable choice for detecting leakages. In this\nwork, we explore the potential of model-loss-based and distribution-based drift\ndetection methods to tackle leakage detection. We additionally discuss the\nissue of temporal dependencies in the data and propose a way to cope with it\nwhen applying distribution-based detection. We evaluate different methods\nsystematically for leakages of different sizes and detection times.\nAdditionally, we propose a first drift-detection-based technique for localizing\nleakages.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01733v1"}
{"title": "Task and Explanation Network", "author": "Moshe Sipper", "abstract": "Explainability in deep networks has gained increased importance in recent\nyears. We argue herein that an AI must be tasked not just with a task but also\nwith an explanation of why said task was accomplished as such. We present a\nbasic framework -- Task and Explanation Network (TENet) -- which fully\nintegrates task completion and its explanation. We believe that the field of AI\nas a whole should insist -- quite emphatically -- on explainability.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.NE"], "links": "http://arxiv.org/abs/2401.01732v1"}
{"title": "Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices", "author": "Anirudh Rajiv Menon, Unnikrishnan Menon, Kailash Ahirwar", "abstract": "Modern deep learning models, growing larger and more complex, have\ndemonstrated exceptional generalization and accuracy due to training on huge\ndatasets. This trend is expected to continue. However, the increasing size of\nthese models poses challenges in training, as traditional centralized methods\nare limited by memory constraints at such scales. This paper proposes an\nasynchronous decentralized training paradigm for large modern deep learning\nmodels that harnesses the compute power of regular heterogeneous PCs with\nlimited resources connected across the internet to achieve favourable\nperformance metrics. Ravnest facilitates decentralized training by efficiently\norganizing compute nodes into clusters with similar data transfer rates and\ncompute capabilities, without necessitating that each node hosts the entire\nmodel. These clusters engage in $\\textit{Zero-Bubble Asynchronous Model\nParallel}$ training, and a $\\textit{Parallel Multi-Ring All-Reduce}$ method is\nemployed to effectively execute global parameter averaging across all clusters.\nWe have framed our asynchronous SGD loss function as a block structured\noptimization problem with delayed updates and derived an optimal convergence\nrate of $O\\left(\\frac{1}{\\sqrt{K}}\\right)$. We further discuss linear speedup\nwith respect to the number of participating clusters and the bound on the\nstaleness parameter.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.DC"], "links": "http://arxiv.org/abs/2401.01728v1"}
{"title": "EPA: Neural Collapse Inspired Robust Out-of-Distribution Detector", "author": "Jiawei Zhang, Yufan Chen, Cheng Jin, Lei Zhu, Yuantao Gu", "abstract": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the\nsecurity of neural networks. Existing works have leveraged the fact that\nIn-distribution (ID) samples form a subspace in the feature space, achieving\nstate-of-the-art (SOTA) performance. However, the comprehensive characteristics\nof the ID subspace still leave under-explored. Recently, the discovery of\nNeural Collapse ($\\mathcal{NC}$) sheds light on novel properties of the ID\nsubspace. Leveraging insight from $\\mathcal{NC}$, we observe that the Principal\nAngle between the features and the ID feature subspace forms a superior\nrepresentation for measuring the likelihood of OOD. Building upon this\nobservation, we propose a novel $\\mathcal{NC}$-inspired OOD scoring function,\nnamed Entropy-enhanced Principal Angle (EPA), which integrates both the global\ncharacteristic of the ID subspace and its inner property. We experimentally\ncompare EPA with various SOTA approaches, validating its superior performance\nand robustness across different network architectures and OOD datasets.", "published": "2024-01-03", "categories": ["cs.LG", "cs.CR"], "links": "http://arxiv.org/abs/2401.01710v1"}
{"title": "Zero-shot Active Learning Using Self Supervised Learning", "author": "Abhishek Sinha, Shreya Singh", "abstract": "Deep learning algorithms are often said to be data hungry. The performance of\nsuch algorithms generally improve as more and more annotated data is fed into\nthe model. While collecting unlabelled data is easier (as they can be scraped\neasily from the internet), annotating them is a tedious and expensive task.\nGiven a fixed budget available for data annotation, Active Learning helps\nselecting the best subset of data for annotation, such that the deep learning\nmodel when trained over that subset will have maximum generalization\nperformance under this budget. In this work, we aim to propose a new Active\nLearning approach which is model agnostic as well as one doesn't require an\niterative process. We aim to leverage self-supervised learnt features for the\ntask of Active Learning. The benefit of self-supervised learning, is that one\ncan get useful feature representation of the input data, without having any\nannotation.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01690v1"}
{"title": "LESEN: Label-Efficient deep learning for Multi-parametric MRI-based Visual Pathway Segmentation", "author": "Alou Diakite, Cheng Li, Lei Xie, Yuanjing Feng, Hua Han, Shanshan Wang", "abstract": "Recent research has shown the potential of deep learning in multi-parametric\nMRI-based visual pathway (VP) segmentation. However, obtaining labeled data for\ntraining is laborious and time-consuming. Therefore, it is crucial to develop\neffective algorithms in situations with limited labeled samples. In this work,\nwe propose a label-efficient deep learning method with self-ensembling (LESEN).\nLESEN incorporates supervised and unsupervised losses, enabling the student and\nteacher models to mutually learn from each other, forming a self-ensembling\nmean teacher framework. Additionally, we introduce a reliable unlabeled sample\nselection (RUSS) mechanism to further enhance LESEN's effectiveness. Our\nexperiments on the human connectome project (HCP) dataset demonstrate the\nsuperior performance of our method when compared to state-of-the-art\ntechniques, advancing multimodal VP segmentation for comprehensive analysis in\nclinical and research settings. The implementation code will be available at:\nhttps://github.com/aldiak/Semi-Supervised-Multimodal-Visual-Pathway-\nDelineation.", "published": "2024-01-03", "categories": ["eess.IV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01654v1"}
{"title": "Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences", "author": "Piotr Skalski, David Sutton, Stuart Burrell, Iker Perez, Jason Wong", "abstract": "Machine learning models underpin many modern financial systems for use cases\nsuch as fraud detection and churn prediction. Most are based on supervised\nlearning with hand-engineered features, which relies heavily on the\navailability of labelled data. Large self-supervised generative models have\nshown tremendous success in natural language processing and computer vision,\nyet so far they haven't been adapted to multivariate time series of financial\ntransactions. In this paper, we present a generative pretraining method that\ncan be used to obtain contextualised embeddings of financial transactions.\nBenchmarks on public datasets demonstrate that it outperforms state-of-the-art\nself-supervised methods on a range of downstream tasks. We additionally perform\nlarge-scale pretraining of an embedding model using a corpus of data from 180\nissuing banks containing 5.1 billion transactions and apply it to the card\nfraud detection problem on hold-out datasets. The embedding model significantly\nimproves value detection rate at high precision thresholds and transfers well\nto out-of-domain distributions.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01641v2"}
{"title": "Evaluating Fairness in Self-supervised and Supervised Models for Sequential Data", "author": "Sofia Yfantidou, Dimitris Spathis, Marios Constantinides, Athena Vakali, Daniele Quercia, Fahim Kawsar", "abstract": "Self-supervised learning (SSL) has become the de facto training paradigm of\nlarge models where pre-training is followed by supervised fine-tuning using\ndomain-specific data and labels. Hypothesizing that SSL models would learn more\ngeneric, hence less biased, representations, this study explores the impact of\npre-training and fine-tuning strategies on fairness (i.e., performing equally\non different demographic breakdowns). Motivated by human-centric applications\non real-world timeseries data, we interpret inductive biases on the model,\nlayer, and metric levels by systematically comparing SSL models to their\nsupervised counterparts. Our findings demonstrate that SSL has the capacity to\nachieve performance on par with supervised methods while significantly\nenhancing fairness--exhibiting up to a 27% increase in fairness with a mere 1%\nloss in performance through self-supervision. Ultimately, this work underscores\nSSL's potential in human-centric computing, particularly high-stakes,\ndata-scarce application domains like healthcare.", "published": "2024-01-03", "categories": ["cs.LG", "cs.CY"], "links": "http://arxiv.org/abs/2401.01640v1"}
{"title": "Synthetic Data in AI: Challenges, Applications, and Ethical Implications", "author": "Shuang Hao, Wenfeng Han, Tao Jiang, Yiping Li, Haonan Wu, Chunlin Zhong, Zhangjun Zhou, He Tang", "abstract": "In the rapidly evolving field of artificial intelligence, the creation and\nutilization of synthetic datasets have become increasingly significant. This\nreport delves into the multifaceted aspects of synthetic data, particularly\nemphasizing the challenges and potential biases these datasets may harbor. It\nexplores the methodologies behind synthetic data generation, spanning\ntraditional statistical models to advanced deep learning techniques, and\nexamines their applications across diverse domains. The report also critically\naddresses the ethical considerations and legal implications associated with\nsynthetic datasets, highlighting the urgent need for mechanisms to ensure\nfairness, mitigate biases, and uphold ethical standards in AI development.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.CY"], "links": "http://arxiv.org/abs/2401.01629v1"}
{"title": "On the Expressive Power of Graph Neural Networks", "author": "Ashwin Nalwade, Kelly Marshall, Axel Eladi, Umang Sharma", "abstract": "The study of Graph Neural Networks has received considerable interest in the\npast few years. By extending deep learning to graph-structured data, GNNs can\nsolve a diverse set of tasks in fields including social science, chemistry, and\nmedicine. The development of GNN architectures has largely been focused on\nimproving empirical performance on tasks like node or graph classification.\nHowever, a line of recent work has instead sought to find GNN architectures\nthat have desirable theoretical properties - by studying their expressive power\nand designing architectures that maximize this expressiveness.\n  While there is no consensus on the best way to define the expressiveness of a\nGNN, it can be viewed from several well-motivated perspectives. Perhaps the\nmost natural approach is to study the universal approximation properties of\nGNNs, much in the way that this has been studied extensively for MLPs. Another\ndirection focuses on the extent to which GNNs can distinguish between different\ngraph structures, relating this to the graph isomorphism test. Besides, a GNN's\nability to compute graph properties such as graph moments has been suggested as\nanother form of expressiveness. All of these different definitions are\ncomplementary and have yielded different recommendations for GNN architecture\nchoices. In this paper, we would like to give an overview of the notion of\n\"expressive power\" of GNNs and provide some valuable insights regarding the\ndesign choices of GNNs.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01626v1"}
{"title": "SCALA: Sparsification-based Contrastive Learning for Anomaly Detection on Attributed Networks", "author": "Enbo He, Yitong Hao, Yue Zhang, Guisheng Yin, Lina Yao", "abstract": "Anomaly detection on attributed networks aims to find the nodes whose\nbehaviors are significantly different from other majority nodes. Generally,\nnetwork data contains information about relationships between entities, and the\nanomaly is usually embodied in these relationships. Therefore, how to\ncomprehensively model complex interaction patterns in networks is still a major\nfocus. It can be observed that anomalies in networks violate the homophily\nassumption. However, most existing studies only considered this phenomenon\nobliquely rather than explicitly. Besides, the node representation of normal\nentities can be perturbed easily by the noise relationships introduced by\nanomalous nodes. To address the above issues, we present a novel contrastive\nlearning framework for anomaly detection on attributed networks,\n\\textbf{SCALA}, aiming to improve the embedding quality of the network and\nprovide a new measurement of qualifying the anomaly score for each node by\nintroducing sparsification into the conventional method. Extensive experiments\nare conducted on five benchmark real-world datasets and the results show that\nSCALA consistently outperforms all baseline methods significantly.", "published": "2024-01-03", "categories": ["cs.SI", "cs.CY", "cs.LG"], "links": "http://arxiv.org/abs/2401.01625v1"}
{"title": "PLLaMa: An Open-source Large Language Model for Plant Science", "author": "Xianjun Yang, Junfeng Gao, Wenxin Xue, Erik Alexandersson", "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "links": "http://arxiv.org/abs/2401.01600v1"}
{"title": "Generalization Error Curves for Analytic Spectral Algorithms under Power-law Decay", "author": "Yicheng Li, Weiye Gan, Zuoqiang Shi, Qian Lin", "abstract": "The generalization error curve of certain kernel regression method aims at\ndetermining the exact order of generalization error with various source\ncondition, noise level and choice of the regularization parameter rather than\nthe minimax rate. In this work, under mild assumptions, we rigorously provide a\nfull characterization of the generalization error curves of the kernel gradient\ndescent method (and a large class of analytic spectral algorithms) in kernel\nregression. Consequently, we could sharpen the near inconsistency of kernel\ninterpolation and clarify the saturation effects of kernel regression\nalgorithms with higher qualification, etc. Thanks to the neural tangent kernel\ntheory, these results greatly improve our understanding of the generalization\nbehavior of training the wide neural networks. A novel technical contribution,\nthe analytic functional argument, might be of independent interest.", "published": "2024-01-03", "categories": ["cs.LG", "math.ST", "stat.TH"], "links": "http://arxiv.org/abs/2401.01599v1"}
{"title": "An Invariant Information Geometric Method for High-Dimensional Online Optimization", "author": "Zhengfei Zhang, Yunyue Wei, Yanan Sui", "abstract": "Sample efficiency is crucial in optimization, particularly in black-box\nscenarios characterized by expensive evaluations and zeroth-order feedback.\nWhen computing resources are plentiful, Bayesian optimization is often favored\nover evolution strategies. In this paper, we introduce a full invariance\noriented evolution strategies algorithm, derived from its corresponding\nframework, that effectively rivals the leading Bayesian optimization method in\ntasks with dimensions at the upper limit of Bayesian capability. Specifically,\nwe first build the framework InvIGO that fully incorporates historical\ninformation while retaining the full invariant and computational complexity. We\nthen exemplify InvIGO on multi-dimensional Gaussian, which gives an invariant\nand scalable optimizer SynCMA . The theoretical behavior and advantages of our\nalgorithm over other Gaussian-based evolution strategies are further analyzed.\nFinally, We benchmark SynCMA against leading algorithms in Bayesian\noptimization and evolution strategies on various high dimension tasks, in\ncluding Mujoco locomotion tasks, rover planning task and synthetic functions.\nIn all scenarios, SynCMA demonstrates great competence, if not dominance, over\nother algorithms in sample efficiency, showing the underdeveloped potential of\nproperty oriented evolution strategies.", "published": "2024-01-03", "categories": ["cs.LG", "cs.NE"], "links": "http://arxiv.org/abs/2401.01579v1"}
{"title": "Towards Modeling Uncertainties of Self-explaining Neural Networks via Conformal Prediction", "author": "Wei Qian, Chenxu Zhao, Yangyi Li, Fenglong Ma, Chao Zhang, Mengdi Huai", "abstract": "Despite the recent progress in deep neural networks (DNNs), it remains\nchallenging to explain the predictions made by DNNs. Existing explanation\nmethods for DNNs mainly focus on post-hoc explanations where another\nexplanatory model is employed to provide explanations. The fact that post-hoc\nmethods can fail to reveal the actual original reasoning process of DNNs raises\nthe need to build DNNs with built-in interpretability. Motivated by this, many\nself-explaining neural networks have been proposed to generate not only\naccurate predictions but also clear and intuitive insights into why a\nparticular decision was made. However, existing self-explaining networks are\nlimited in providing distribution-free uncertainty quantification for the two\nsimultaneously generated prediction outcomes (i.e., a sample's final prediction\nand its corresponding explanations for interpreting that prediction).\nImportantly, they also fail to establish a connection between the confidence\nvalues assigned to the generated explanations in the interpretation layer and\nthose allocated to the final predictions in the ultimate prediction layer. To\ntackle the aforementioned challenges, in this paper, we design a novel\nuncertainty modeling framework for self-explaining networks, which not only\ndemonstrates strong distribution-free uncertainty modeling performance for the\ngenerated explanations in the interpretation layer but also excels in producing\nefficient and effective prediction sets for the final predictions based on the\ninformative high-level basis explanations. We perform the theoretical analysis\nfor the proposed framework. Extensive experimental evaluation demonstrates the\neffectiveness of the proposed uncertainty framework.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01549v1"}
{"title": "AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets", "author": "Ernest Perkowski, Rui Pan, Tuan Dung Nguyen, Yuan-Sen Ting, Sandor Kruk, Tong Zhang, Charlie O'Neill, Maja Jablonska, Michael J. Smith, Kevin Schawinski, Kartheik Iyer, Ioana Ciucă for UniverseTBD", "abstract": "We explore the potential of enhancing LLM performance in astronomy-focused\nquestion-answering through targeted, continual pre-training. By employing a\ncompact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of\nastronomy corpus -- comprising abstracts, introductions, and conclusions -- we\nachieve notable improvements in specialized topic comprehension. While general\nLLMs like GPT-4 outperform in broader question-answering scenarios due to\nsuperior reasoning capabilities, our findings suggest that continual\npre-training with limited resources can still enhance model performance on\nspecialized topics. Additionally, we present an extension of AstroLLaMA: the\nfine-tuning of the 7B LLaMA model on a domain-specific conversational dataset,\nculminating in the release of the chat-enabled AstroLLaMA for community use.\nComprehensive quantitative benchmarking is currently in progress and will be\ndetailed in an upcoming full paper. The model, AstroLLaMA-Chat, is now\navailable at https://huggingface.co/universeTBD, providing the first\nopen-source conversational AI tool tailored for the astronomy community.", "published": "2024-01-03", "categories": ["astro-ph.IM", "astro-ph.CO", "astro-ph.GA", "astro-ph.SR", "cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.01916v1"}
{"title": "The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers", "author": "Orson Mengara", "abstract": "The area of Machine Learning as a Service (MLaaS) is experiencing increased\nimplementation due to recent advancements in the AI (Artificial Intelligence)\nindustry. However, this spike has prompted concerns regarding AI defense\nmechanisms, specifically regarding potential covert attacks from third-party\nproviders that cannot be entirely trusted. Recent research has uncovered that\nauditory backdoors may use certain modifications as their initiating mechanism.\nDynamicTrigger is introduced as a methodology for carrying out dynamic backdoor\nattacks that use cleverly designed tweaks to ensure that corrupted samples are\nindistinguishable from clean. By utilizing fluctuating signal sampling rates\nand masking speaker identities through dynamic sound triggers (such as the\nclapping of hands), it is possible to deceive speech recognition systems (ASR).\nOur empirical testing demonstrates that DynamicTrigger is both potent and\nstealthy, achieving impressive success rates during covert attacks while\nmaintaining exceptional accuracy with non-poisoned datasets.", "published": "2024-01-03", "categories": ["cs.CR", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01537v1"}
{"title": "Will 6G be Semantic Communications? Opportunities and Challenges from Task Oriented and Secure Communications to Integrated Sensing", "author": "Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus", "abstract": "This paper explores opportunities and challenges of task (goal)-oriented and\nsemantic communications for next-generation (NextG) communication networks\nthrough the integration of multi-task learning. This approach employs deep\nneural networks representing a dedicated encoder at the transmitter and\nmultiple task-specific decoders at the receiver, collectively trained to handle\ndiverse tasks including semantic information preservation, source input\nreconstruction, and integrated sensing and communications. To extend the\napplicability from point-to-point links to multi-receiver settings, we envision\nthe deployment of decoders at various receivers, where decentralized learning\naddresses the challenges of communication load and privacy concerns, leveraging\nfederated learning techniques that distribute model updates across\ndecentralized nodes. However, the efficacy of this approach is contingent on\nthe robustness of the employed deep learning models. We scrutinize potential\nvulnerabilities stemming from adversarial attacks during both training and\ntesting phases. These attacks aim to manipulate both the inputs at the encoder\nat the transmitter and the signals received over the air on the receiver side,\nhighlighting the importance of fortifying semantic communications against\npotential multi-domain exploits. Overall, the joint and robust design of\ntask-oriented communications, semantic communications, and integrated sensing\nand communications in a multi-task learning framework emerges as the key\nenabler for context-aware, resource-efficient, and secure communications\nultimately needed in NextG network systems.", "published": "2024-01-03", "categories": ["cs.NI", "cs.CR", "cs.IT", "cs.LG", "eess.SP", "math.IT"], "links": "http://arxiv.org/abs/2401.01531v1"}
{"title": "Improved Bandits in Many-to-one Matching Markets with Incentive Compatibility", "author": "Fang Kong, Shuai Li", "abstract": "Two-sided matching markets have been widely studied in the literature due to\ntheir rich applications. Since participants are usually uncertain about their\npreferences, online algorithms have recently been adopted to learn them through\niterative interactions. \\citet{wang2022bandit} initiate the study of this\nproblem in a many-to-one setting with \\textit{responsiveness}. However, their\nresults are far from optimal and lack guarantees of incentive compatibility. An\nextension of \\citet{kong2023player} to this more general setting achieves a\nnear-optimal bound for player-optimal regret. Nevertheless, due to the\nsubstantial requirement for collaboration, a single player's deviation could\nlead to a huge increase in its own cumulative rewards and an $O(T)$ regret for\nothers. In this paper, we aim to enhance the regret bound in many-to-one\nmarkets while ensuring incentive compatibility. We first propose the adaptively\nexplore-then-deferred-acceptance (AETDA) algorithm for responsiveness setting\nand derive an $O(N\\min\\left\\{N,K\\right\\}C\\log T/\\Delta^2)$ upper bound for\nplayer-optimal stable regret while demonstrating its guarantee of incentive\ncompatibility, where $N$ represents the number of players, $K$ is the number of\narms, $T$ denotes the time horizon, $C$ is arms' total capacities and $\\Delta$\nsignifies the minimum preference gap among players. This result is a\nsignificant improvement over \\citet{wang2022bandit}. And to the best of our\nknowledge, it constitutes the first player-optimal guarantee in matching\nmarkets that offers such robust assurances. We also consider broader\n\\textit{substitutable} preferences, one of the most general conditions to\nensure the existence of a stable matching and cover responsiveness. We devise\nan online DA (ODA) algorithm and establish an $O(NK\\log T/\\Delta^2)$\nplayer-pessimal stable regret bound for this setting.", "published": "2024-01-03", "categories": ["cs.LG", "cs.GT"], "links": "http://arxiv.org/abs/2401.01528v1"}
{"title": "S$^{2}$-DMs:Skip-Step Diffusion Models", "author": "Yixuan Wang, Shuangyin Li", "abstract": "Diffusion models have emerged as powerful generative tools, rivaling GANs in\nsample quality and mirroring the likelihood scores of autoregressive models. A\nsubset of these models, exemplified by DDIMs, exhibit an inherent asymmetry:\nthey are trained over $T$ steps but only sample from a subset of $T$ during\ngeneration. This selective sampling approach, though optimized for speed,\ninadvertently misses out on vital information from the unsampled steps, leading\nto potential compromises in sample quality. To address this issue, we present\nthe S$^{2}$-DMs, which is a new training method by using an innovative\n$L_{skip}$, meticulously designed to reintegrate the information omitted during\nthe selective sampling phase. The benefits of this approach are manifold: it\nnotably enhances sample quality, is exceptionally simple to implement, requires\nminimal code modifications, and is flexible enough to be compatible with\nvarious sampling algorithms. On the CIFAR10 dataset, models trained using our\nalgorithm showed an improvement of 3.27% to 14.06% over models trained with\ntraditional methods across various sampling algorithms (DDIMs, PNDMs, DEIS) and\ndifferent numbers of sampling steps (10, 20, ..., 1000). On the CELEBA dataset,\nthe improvement ranged from 8.97% to 27.08%. Access to the code and additional\nresources is provided in the github.", "published": "2024-01-03", "categories": ["cs.CV", "cs.LG", "eess.IV"], "links": "http://arxiv.org/abs/2401.01520v1"}
{"title": "Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review", "author": "Luoma Ke, Song Tong, Peng Chen, Kaiping Peng", "abstract": "This paper explores the frontiers of large language models (LLMs) in\npsychology applications. Psychology has undergone several theoretical changes,\nand the current use of Artificial Intelligence (AI) and Machine Learning,\nparticularly LLMs, promises to open up new research directions. We provide a\ndetailed exploration of how LLMs like ChatGPT are transforming psychological\nresearch. It discusses the impact of LLMs across various branches of\npsychology, including cognitive and behavioral, clinical and counseling,\neducational and developmental, and social and cultural psychology, highlighting\ntheir potential to simulate aspects of human cognition and behavior. The paper\ndelves into the capabilities of these models to emulate human-like text\ngeneration, offering innovative tools for literature review, hypothesis\ngeneration, experimental design, experimental subjects, data analysis, academic\nwriting, and peer review in psychology. While LLMs are essential in advancing\nresearch methodologies in psychology, the paper also cautions about their\ntechnical and ethical challenges. There are issues like data privacy, the\nethical implications of using LLMs in psychological research, and the need for\na deeper understanding of these models' limitations. Researchers should\nresponsibly use LLMs in psychological studies, adhering to ethical standards\nand considering the potential consequences of deploying these technologies in\nsensitive areas. Overall, the article provides a comprehensive overview of the\ncurrent state of LLMs in psychology, exploring potential benefits and\nchallenges. It serves as a call to action for researchers to leverage LLLs'\nadvantages responsibly while addressing associated risks.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01519v1"}
{"title": "AIRI: Predicting Retention Indices and their Uncertainties using Artificial Intelligence", "author": "Lewis Y. Geer, Stephen E. Stein, William Gary Mallard, Douglas J. Slotta", "abstract": "The Kov\\'ats Retention index (RI) is a quantity measured using gas\nchromatography and commonly used in the identification of chemical structures.\nCreating libraries of observed RI values is a laborious task, so we explore the\nuse of a deep neural network for predicting RI values from structure for\nstandard semipolar columns. This network generated predictions with a mean\nabsolute error of 15.1 and, in a quantification of the tail of the error\ndistribution, a 95th percentile absolute error of 46.5. Because of the\nArtificial Intelligence Retention Indices (AIRI) network's accuracy, it was\nused to predict RI values for the NIST EI-MS spectral libraries. These RI\nvalues are used to improve chemical identification methods and the quality of\nthe library. Estimating uncertainty is an important practical need when using\nprediction models. To quantify the uncertainty of our network for each\nindividual prediction, we used the outputs of an ensemble of 8 networks to\ncalculate a predicted standard deviation for each RI value prediction. This\npredicted standard deviation was corrected to follow the error between observed\nand predicted RI values. The Z scores using these predicted standard deviations\nhad a standard deviation of 1.52 and a 95th percentile absolute Z score\ncorresponding to a mean RI value of 42.6.", "published": "2024-01-03", "categories": ["cs.LG", "q-bio.QM"], "links": "http://arxiv.org/abs/2401.01506v1"}
{"title": "Pontryagin Neural Operator for Solving Parametric General-Sum Differential Games", "author": "Lei Zhang, Mukesh Ghimire, Zhe Xu, Wenlong Zhang, Yi Ren", "abstract": "The values of two-player general-sum differential games are viscosity\nsolutions to Hamilton-Jacobi-Isaacs (HJI) equations. Value and policy\napproximations for such games suffer from the curse of dimensionality (CoD).\nAlleviating CoD through physics-informed neural networks (PINN) encounters\nconvergence issues when value discontinuity is present due to state\nconstraints. On top of these challenges, it is often necessary to learn\ngeneralizable values and policies across a parametric space of games, e.g., for\ngame parameter inference when information is incomplete. To address these\nchallenges, we propose in this paper a Pontryagin-mode neural operator that\noutperforms existing state-of-the-art (SOTA) on safety performance across games\nwith parametric state constraints. Our key contribution is the introduction of\na costate loss defined on the discrepancy between forward and backward costate\nrollouts, which are computationally cheap. We show that the discontinuity of\ncostate dynamics (in the presence of state constraints) effectively enables the\nlearning of discontinuous values, without requiring manually supervised data as\nsuggested by the current SOTA. More importantly, we show that the close\nrelationship between costates and policies makes the former critical in\nlearning feedback control policies with generalizable safety performance.", "published": "2024-01-03", "categories": ["cs.LG", "cs.GT", "cs.RO"], "links": "http://arxiv.org/abs/2401.01502v1"}
{"title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction", "author": "Minchan Kim, Myeonghun Jeong, Byoung Jin Choi, Semin Kim, Joun Yeop Lee, Nam Soo Kim", "abstract": "We propose a novel text-to-speech (TTS) framework centered around a neural\ntransducer. Our approach divides the whole TTS pipeline into semantic-level\nsequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling\nstages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings.\nFor a robust and efficient alignment modeling, we employ a neural transducer\nnamed token transducer for the semantic token prediction, benefiting from its\nhard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR)\nspeech generator efficiently synthesizes waveforms from these semantic tokens.\nAdditionally, a reference speech controls temporal dynamics and acoustic\nconditions at each stage. This decoupled framework reduces the training\ncomplexity of TTS while allowing each stage to focus on semantic and acoustic\nmodeling. Our experimental results on zero-shot adaptive TTS demonstrate that\nour model surpasses the baseline in terms of speech quality and speaker\nsimilarity, both objectively and subjectively. We also delve into the inference\nspeed and prosody control capabilities of our approach, highlighting the\npotential of neural transducers in TTS frameworks.", "published": "2024-01-03", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.01498v1"}
{"title": "Free Lunch for Federated Remote Sensing Target Fine-Grained Classification: A Parameter-Efficient Framework", "author": "Shengchao Chen, Ting Shu, Huan Zhao, Jiahao Wang, Sufen Ren, Lina Yang", "abstract": "Remote Sensing Target Fine-grained Classification (TFGC) is of great\nsignificance in both military and civilian fields. Due to location differences,\ngrowth in data size, and centralized server storage constraints, these data are\nusually stored under different databases across regions/countries. However,\nprivacy laws and national security concerns constrain researchers from\naccessing these sensitive remote sensing images for further analysis.\nAdditionally, low-resource remote sensing devices encounter challenges in terms\nof communication overhead and efficiency when dealing with the ever-increasing\ndata and model scales. To solve the above challenges, this paper proposes a\nnovel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed\nPRFL. The proposed framework allows each client to learn global and local\nknowledge to enhance the local representation of private data in environments\nwith extreme statistical heterogeneity (non. Independent and Identically\nDistributed, IID). Thus, it provides highly customized models to clients with\ndifferentiated data distributions. Moreover, the framework minimizes\ncommunication overhead and improves efficiency while ensuring satisfactory\nperformance, thereby enhancing robustness and practical applicability under\nresource-scarce conditions. We demonstrate the effectiveness of the proposed\nPRFL on the classical TFGC task by leveraging four public datasets.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI", "cs.CR"], "links": "http://arxiv.org/abs/2401.01493v1"}
{"title": "Natural Language Processing and Multimodal Stock Price Prediction", "author": "Kevin Taylor, Jerry Ng", "abstract": "In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.", "published": "2024-01-03", "categories": ["cs.LG", "cs.CL"], "links": "http://arxiv.org/abs/2401.01487v1"}
{"title": "Uncertainty Regularized Evidential Regression", "author": "Kai Ye, Tiejin Chen, Hua Wei, Liang Zhan", "abstract": "The Evidential Regression Network (ERN) represents a novel approach that\nintegrates deep learning with Dempster-Shafer's theory to predict a target and\nquantify the associated uncertainty. Guided by the underlying theory, specific\nactivation functions must be employed to enforce non-negative values, which is\na constraint that compromises model performance by limiting its ability to\nlearn from all samples. This paper provides a theoretical analysis of this\nlimitation and introduces an improvement to overcome it. Initially, we define\nthe region where the models can't effectively learn from the samples. Following\nthis, we thoroughly analyze the ERN and investigate this constraint. Leveraging\nthe insights from our analysis, we address the limitation by introducing a\nnovel regularization term that empowers the ERN to learn from the whole\ntraining set. Our extensive experiments substantiate our theoretical findings\nand demonstrate the effectiveness of the proposed solution.", "published": "2024-01-03", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01484v1"}
{"title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition", "author": "Kyle Buettner, Sina Malakouti, Xiang Lorraine Li, Adriana Kovashka", "abstract": "Existing object recognition models have been shown to lack robustness in\ndiverse geographical scenarios due to significant domain shifts in design and\ncontext. Class representations need to be adapted to more accurately reflect an\nobject concept under these shifts. In the absence of training data from target\ngeographies, we hypothesize that geography-specific descriptive knowledge of\nobject categories can be leveraged to enhance robustness. For this purpose, we\nexplore the feasibility of probing a large-language model for\ngeography-specific object knowledge, and we investigate integrating knowledge\nin zero-shot and learnable soft prompting with the CLIP vision-language model.\nIn particular, we propose a geography knowledge regularization method to ensure\nthat soft prompts trained on a source set of geographies generalize to an\nunseen target set of geographies. Our gains on DollarStreet when generalizing\nfrom a model trained only on data from Europe are as large as +2.8 on countries\nfrom Africa, and +4.6 on the hardest classes. We further show competitive\nperformance vs. few-shot target training, and provide insights into how\ndescriptive knowledge captures geographical differences.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01482v1"}
{"title": "Kernel-U-Net: Hierarchical and Symmetrical Framework for Multivariate Time Series Forecasting", "author": "Jiang You, Reńe Natowicz, Arben Cela, Jacob Ouanounou, Patrick Siarry", "abstract": "Time series forecasting task predicts future trends based on historical\ninformation. Recent U-Net-based methods have demonstrated superior performance\nin predicting real-world datasets. However, the performance of these models is\nlower than patch-based models or linear models. In this work, we propose a\nsymmetric and hierarchical framework, Kernel-U-Net, which cuts the input\nsequence into slices at each layer of the network and then computes them using\nkernels. Furthermore, it generalizes the concept of convolutional kernels in\nclassic U-Net to accept custom kernels that follow the same design pattern.\nCompared to the existing linear or transformer-based solution, our model\ncontains 3 advantages: 1) A small number of parameters: the parameters size is\n$O(log(L)^2)$ where $L$ is the look-back window size, 2) Flexibility: its\nkernels can be customized and fitted to the datasets, 3) Computation\nefficiency: the computation complexity of transformer modules is reduced to\n$O(log(L)^2)$ if they are placed close to the latent vector. Kernel-U-Net\naccuracy was greater than or equal to the state-of-the-art model on six (out of\nseven) real-world datasets.", "published": "2024-01-03", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01479v1"}
{"title": "A First Look at Information Highlighting in Stack Overflow Answers", "author": "Shahla Shaan Ahmed, Shaowei Wang, Yuan Tian, Tse-Hsun, Chen, Haoxiang Zhang", "abstract": "Context: Navigating the knowledge of Stack Overflow (SO) remains challenging.\nTo make the posts vivid to users, SO allows users to write and edit posts with\nMarkdown or HTML so that users can leverage various formatting styles (e.g.,\nbold, italic, and code) to highlight the important information. Nonetheless,\nthere have been limited studies on the highlighted information. Objective: We\ncarried out the first large-scale exploratory study on the information\nhighlighted in SO answers in our recent study. To extend our previous study, we\ndevelop approaches to automatically recommend highlighted content with\nformatting styles using neural network architectures initially designed for the\nNamed Entity Recognition task. Method: In this paper, we studied 31,169,429\nanswers of Stack Overflow. For training recommendation models, we choose CNN\nand BERT models for each type of formatting (i.e., Bold, Italic, Code, and\nHeading) using the information highlighting dataset we collected from SO\nanswers. Results: Our models based on CNN architecture achieve precision\nranging from 0.71 to 0.82. The trained model for automatic code content\nhighlighting achieves a recall of 0.73 and an F1 score of 0.71, outperforming\nthe trained models for other formatting styles. The BERT models have even lower\nrecalls and F1 scores than the CNN models. Our analysis of failure cases\nindicates that the majority of the failure cases are missing identification\n(i.e., the model misses the content that is supposed to be highlighted) due to\nthe models tend to learn the frequently highlighted words while struggling to\nlearn less frequent words. Conclusion: Our findings suggest that it is possible\nto develop recommendation models for highlighting information for answers with\ndifferent formatting styles on Stack Overflow.", "published": "2024-01-03", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SE"], "links": "http://arxiv.org/abs/2401.01472v1"}
{"title": "Token Propagation Controller for Efficient Vision Transformer", "author": "Wentao Zhu", "abstract": "Vision transformers (ViTs) have achieved promising results on a variety of\nComputer Vision tasks, however their quadratic complexity in the number of\ninput tokens has limited their application specially in resource-constrained\nsettings. Previous approaches that employ gradual token reduction to address\nthis challenge assume that token redundancy in one layer implies redundancy in\nall the following layers. We empirically demonstrate that this assumption is\noften not correct, i.e., tokens that are redundant in one layer can be useful\nin later layers. We employ this key insight to propose a novel token\npropagation controller (TPC) that incorporates two different\ntoken-distributions, i.e., pause probability and restart probability to control\nthe reduction and reuse of tokens respectively, which results in more efficient\ntoken utilization. To improve the estimates of token distributions, we propose\na smoothing mechanism that acts as a regularizer and helps remove noisy\noutliers. Furthermore, to improve the training-stability of our proposed TPC,\nwe introduce a model stabilizer that is able to implicitly encode local image\nstructures and minimize accuracy fluctuations during model training. We present\nextensive experimental results on the ImageNet-1K dataset using DeiT, LV-ViT\nand Swin models to demonstrate the effectiveness of our proposed method. For\nexample, compared to baseline models, our proposed method improves the\ninference speed of the DeiT-S by 250% while increasing the classification\naccuracy by 1.0%.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.NE"], "links": "http://arxiv.org/abs/2401.01470v1"}
