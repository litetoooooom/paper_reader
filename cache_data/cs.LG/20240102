{"title": "Point Cloud Classification via Deep Set Linearized Optimal Transport", "author": "Scott Mahan, Caroline Moosm√ºller, Alexander Cloninger", "abstract": "We introduce Deep Set Linearized Optimal Transport, an algorithm designed for\nthe efficient simultaneous embedding of point clouds into an $L^2-$space. This\nembedding preserves specific low-dimensional structures within the Wasserstein\nspace while constructing a classifier to distinguish between various classes of\npoint clouds. Our approach is motivated by the observation that $L^2-$distances\nbetween optimal transport maps for distinct point clouds, originating from a\nshared fixed reference distribution, provide an approximation of the\nWasserstein-2 distance between these point clouds, under certain assumptions.\nTo learn approximations of these transport maps, we employ input convex neural\nnetworks (ICNNs) and establish that, under specific conditions, Euclidean\ndistances between samples from these ICNNs closely mirror Wasserstein-2\ndistances between the true distributions. Additionally, we train a\ndiscriminator network that attaches weights these samples and creates a\npermutation invariant classifier to differentiate between different classes of\npoint clouds. We showcase the advantages of our algorithm over the standard\ndeep set approach through experiments on a flow cytometry dataset with a\nlimited number of labeled point clouds.", "published": "2024-01-02", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.01460v1"}
{"title": "Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint", "author": "Soyed Tuhin Ahmed, Mehdi B. tahoori", "abstract": "Neural networks (NNs) are increasingly used in always-on safety-critical\napplications deployed on hardware accelerators (NN-HAs) employing various\nmemory technologies. Reliable continuous operation of NN is essential for\nsafety-critical applications. During online operation, NNs are susceptible to\nsingle and multiple permanent and soft errors due to factors such as radiation,\naging, and thermal effects. Explicit NN-HA testing methods cannot detect\ntransient faults during inference, are unsuitable for always-on applications,\nand require extensive test vector generation and storage. Therefore, in this\npaper, we propose the \\emph{uncertainty fingerprint} approach representing the\nonline fault status of NN. Furthermore, we propose a dual head NN topology\nspecifically designed to produce uncertainty fingerprints and the primary\nprediction of the NN in \\emph{a single shot}. During the online operation, by\nmatching the uncertainty fingerprint, we can concurrently self-test NNs with up\nto $100\\%$ coverage with a low false positive rate while maintaining a similar\nperformance of the primary task. Compared to existing works, memory overhead is\nreduced by up to $243.7$ MB, multiply and accumulate (MAC) operation is reduced\nby up to $10000\\times$, and false-positive rates are reduced by up to $89\\%$.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.ET"], "links": "http://arxiv.org/abs/2401.01458v1"}
{"title": "ProbMCL: Simple Probabilistic Contrastive Learning for Multi-label Visual Classification", "author": "Ahmad Sajedi, Samir Khaki, Yuri A. Lawryshyn, Konstantinos N. Plataniotis", "abstract": "Multi-label image classification presents a challenging task in many domains,\nincluding computer vision and medical imaging. Recent advancements have\nintroduced graph-based and transformer-based methods to improve performance and\ncapture label dependencies. However, these methods often include complex\nmodules that entail heavy computation and lack interpretability. In this paper,\nwe propose Probabilistic Multi-label Contrastive Learning (ProbMCL), a novel\nframework to address these challenges in multi-label image classification\ntasks. Our simple yet effective approach employs supervised contrastive\nlearning, in which samples that share enough labels with an anchor image based\non a decision threshold are introduced as a positive set. This structure\ncaptures label dependencies by pulling positive pair embeddings together and\npushing away negative samples that fall below the threshold. We enhance\nrepresentation learning by incorporating a mixture density network into\ncontrastive learning and generating Gaussian mixture distributions to explore\nthe epistemic uncertainty of the feature encoder. We validate the effectiveness\nof our framework through experimentation with datasets from the computer vision\nand medical imaging domains. Our method outperforms the existing\nstate-of-the-art methods while achieving a low computational footprint on both\ndatasets. Visualization analyses also demonstrate that ProbMCL-learned\nclassifiers maintain a meaningful semantic topology.", "published": "2024-01-02", "categories": ["cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01448v1"}
{"title": "Hierarchical Over-the-Air Federated Learning with Awareness of Interference and Data Heterogeneity", "author": "Seyed Mohammad Azimi-Abarghouyi, Viktoria Fodor", "abstract": "When implementing hierarchical federated learning over wireless networks,\nscalability assurance and the ability to handle both interference and device\ndata heterogeneity are crucial. This work introduces a learning method designed\nto address these challenges, along with a scalable transmission scheme that\nefficiently uses a single wireless resource through over-the-air computation.\nTo provide resistance against data heterogeneity, we employ gradient\naggregations. Meanwhile, the impact of interference is minimized through\noptimized receiver normalizing factors. For this, we model a multi-cluster\nwireless network using stochastic geometry, and characterize the mean squared\nerror of the aggregation estimations as a function of the network parameters.\nWe show that despite the interference and the data heterogeneity, the proposed\nscheme achieves high learning accuracy and can significantly outperform the\nconventional hierarchical algorithm.", "published": "2024-01-02", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "links": "http://arxiv.org/abs/2401.01442v1"}
{"title": "Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference", "author": "Md Musfiqur Rahman, Murat Kocaoglu", "abstract": "Pearl's causal hierarchy establishes a clear separation between\nobservational, interventional, and counterfactual questions. Researchers\nproposed sound and complete algorithms to compute identifiable causal queries\nat a given level of the hierarchy using the causal structure and data from the\nlower levels of the hierarchy. However, most of these algorithms assume that we\ncan accurately estimate the probability distribution of the data, which is an\nimpractical assumption for high-dimensional variables such as images. On the\nother hand, modern generative deep learning architectures can be trained to\nlearn how to accurately sample from such high-dimensional distributions.\nEspecially with the recent rise of foundation models for images, it is\ndesirable to leverage pre-trained models to answer causal queries with such\nhigh-dimensional data. To address this, we propose a sequential training\nalgorithm that, given the causal structure and a pre-trained conditional\ngenerative model, can train a deep causal generative model, which utilizes the\npre-trained model and can provably sample from identifiable interventional and\ncounterfactual distributions. Our algorithm, called Modular-DCM, uses\nadversarial training to learn the network weights, and to the best of our\nknowledge, is the first algorithm that can make use of pre-trained models and\nprovably sample from any identifiable causal query in the presence of latent\nconfounders with high-dimensional data. We demonstrate the utility of our\nalgorithm using semi-synthetic and real-world datasets containing images as\nvariables in the causal structure.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ME", "stat.ML"], "links": "http://arxiv.org/abs/2401.01426v1"}
{"title": "SwapTransformer: highway overtaking tactical planner model via imitation learning on OSHA dataset", "author": "Alireza Shamsoshoara, Safin B Salih, Pedram Aghazadeh", "abstract": "This paper investigates the high-level decision-making problem in highway\nscenarios regarding lane changing and over-taking other slower vehicles. In\nparticular, this paper aims to improve the Travel Assist feature for automatic\novertaking and lane changes on highways. About 9 million samples including lane\nimages and other dynamic objects are collected in simulation. This data;\nOvertaking on Simulated HighwAys (OSHA) dataset is released to tackle this\nchallenge. To solve this problem, an architecture called SwapTransformer is\ndesigned and implemented as an imitation learning approach on the OSHA dataset.\nMoreover, auxiliary tasks such as future points and car distance network\npredictions are proposed to aid the model in better understanding the\nsurrounding environment. The performance of the proposed solution is compared\nwith a multi-layer perceptron (MLP) and multi-head self-attention networks as\nbaselines in a simulation environment. We also demonstrate the performance of\nthe model with and without auxiliary tasks. All models are evaluated based on\ndifferent metrics such as time to finish each lap, number of overtakes, and\nspeed difference with speed limit. The evaluation shows that the\nSwapTransformer model outperforms other models in different traffic densities\nin the inference phase.", "published": "2024-01-02", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "links": "http://arxiv.org/abs/2401.01425v1"}
{"title": "VALD-MD: Visual Attribution via Latent Diffusion for Medical Diagnostics", "author": "Ammar A. Siddiqui, Santosh Tirunagari, Tehseen Zia, David Windridge", "abstract": "Visual attribution in medical imaging seeks to make evident the\ndiagnostically-relevant components of a medical image, in contrast to the more\ncommon detection of diseased tissue deployed in standard machine vision\npipelines (which are less straightforwardly interpretable/explainable to\nclinicians). We here present a novel generative visual attribution technique,\none that leverages latent diffusion models in combination with domain-specific\nlarge language models, in order to generate normal counterparts of abnormal\nimages. The discrepancy between the two hence gives rise to a mapping\nindicating the diagnostically-relevant image components. To achieve this, we\ndeploy image priors in conjunction with appropriate conditioning mechanisms in\norder to control the image generative process, including natural language text\nprompts acquired from medical science and applied radiology. We perform\nexperiments and quantitatively evaluate our results on the COVID-19 Radiography\nDatabase containing labelled chest X-rays with differing pathologies via the\nFrechet Inception Distance (FID), Structural Similarity (SSIM) and Multi Scale\nStructural Similarity Metric (MS-SSIM) metrics obtained between real and\ngenerated images. The resulting system also exhibits a range of latent\ncapabilities including zero-shot localized disease induction, which are\nevaluated with real examples from the cheXpert dataset.", "published": "2024-01-02", "categories": ["eess.IV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01414v1"}
{"title": "Scalable network reconstruction in subquadratic time", "author": "Tiago P. Peixoto", "abstract": "Network reconstruction consists in determining the unobserved pairwise\ncouplings between $N$ nodes given only observational data on the resulting\nbehavior that is conditioned on those couplings -- typically a time-series or\nindependent samples from a graphical model. A major obstacle to the scalability\nof algorithms proposed for this problem is a seemingly unavoidable quadratic\ncomplexity of $O(N^2)$, corresponding to the requirement of each possible\npairwise coupling being contemplated at least once, despite the fact that most\nnetworks of interest are sparse, with a number of non-zero couplings that is\nonly $O(N)$. Here we present a general algorithm applicable to a broad range of\nreconstruction problems that achieves its result in subquadratic time, with a\ndata-dependent complexity loosely upper bounded by $O(N^{3/2}\\log N)$, but with\na more typical log-linear complexity of $O(N\\log^2N)$. Our algorithm relies on\na stochastic second neighbor search that produces the best edge candidates with\nhigh probability, thus bypassing an exhaustive quadratic search. In practice,\nour algorithm achieves a performance that is many orders of magnitude faster\nthan the quadratic baseline, allows for easy parallelization, and thus enables\nthe reconstruction of networks with hundreds of thousands and even millions of\nnodes and edges.", "published": "2024-01-02", "categories": ["cs.DS", "cs.LG", "physics.data-an", "stat.CO", "stat.ML"], "links": "http://arxiv.org/abs/2401.01404v1"}
{"title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models", "author": "Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, Quanquan Gu", "abstract": "Harnessing the power of human-annotated data through Supervised Fine-Tuning\n(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we\ndelve into the prospect of growing a strong LLM out of a weak one without the\nneed for acquiring additional human-annotated data. We propose a new\nfine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a\nsupervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,\nwhere the LLM refines its capability by playing against instances of itself.\nMore specifically, the LLM generates its own training data from its previous\niterations, refining its policy by discerning these self-generated responses\nfrom those obtained from human-annotated data. Our method progressively\nelevates the LLM from a nascent model to a formidable one, unlocking the full\npotential of human-annotated demonstration data for SFT. Theoretically, we\nprove that the global optimum to the training objective function of our method\nis achieved only when the LLM policy aligns with the target data distribution.\nEmpirically, we evaluate our method on several benchmark datasets including the\nHuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our\nresults show that SPIN can significantly improve the LLM's performance across a\nvariety of benchmarks and even outperform models trained through direct\npreference optimization (DPO) supplemented with extra GPT-4 preference data.\nThis sheds light on the promise of self-play, enabling the achievement of\nhuman-level performance in LLMs without the need for expert opponents.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "links": "http://arxiv.org/abs/2401.01335v1"}
{"title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces", "author": "Farshud Sorourifar, Thomas Banker, Joel A. Paulson", "abstract": "Molecular property optimization (MPO) problems are inherently challenging\nsince they are formulated over discrete, unstructured spaces and the labeling\nprocess involves expensive simulations or experiments, which fundamentally\nlimits the amount of available data. Bayesian optimization (BO) is a powerful\nand popular framework for efficient optimization of noisy, black-box objective\nfunctions (e.g., measured property values), thus is a potentially attractive\nframework for MPO. To apply BO to MPO problems, one must select a structured\nmolecular representation that enables construction of a probabilistic surrogate\nmodel. Many molecular representations have been developed, however, they are\nall high-dimensional, which introduces important challenges in the BO process\n-- mainly because the curse of dimensionality makes it difficult to define and\nperform inference over a suitable class of surrogate models. This challenge has\nbeen recently addressed by learning a lower-dimensional encoding of a SMILE or\ngraph representation of a molecule in an unsupervised manner and then\nperforming BO in the encoded space. In this work, we show that such methods\nhave a tendency to \"get stuck,\" which we hypothesize occurs since the mapping\nfrom the encoded space to property values is not necessarily well-modeled by a\nGaussian process. We argue for an alternative approach that combines numerical\nmolecular descriptors with a sparse axis-aligned Gaussian process model, which\nis capable of rapidly identifying sparse subspaces that are most relevant to\nmodeling the unknown property function. We demonstrate that our proposed method\nsubstantially outperforms existing MPO methods on a variety of benchmark and\nreal-world problems. Specifically, we show that our method can routinely find\nnear-optimal molecules out of a set of more than $>100$k alternatives within\n100 or fewer expensive queries.", "published": "2024-01-02", "categories": ["q-bio.BM", "cs.CE", "cs.LG"], "links": "http://arxiv.org/abs/2401.01398v1"}
{"title": "An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction", "author": "Zaratiana Urchade, Nadi Tomeh, Pierre Holat, Thierry Charnois", "abstract": "In this paper, we propose a novel method for joint entity and relation\nextraction from unstructured text by framing it as a conditional sequence\ngeneration problem. In contrast to conventional generative information\nextraction models that are left-to-right token-level generators, our approach\nis \\textit{span-based}. It generates a linearized graph where nodes represent\ntext spans and edges represent relation triplets. Our method employs a\ntransformer encoder-decoder architecture with pointing mechanism on a dynamic\nvocabulary of spans and relation types. Our model can capture the structural\ncharacteristics and boundaries of entities and relations through span\nrepresentations while simultaneously grounding the generated output in the\noriginal text thanks to the pointing mechanism. Evaluation on benchmark\ndatasets validates the effectiveness of our approach, demonstrating competitive\nresults. Code is available at https://github.com/urchade/ATG.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01326v1"}
{"title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning", "author": "Hongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng Jiang, Zirui Liu, Chia-Yuan Chang, Huiyuan Chen, Xia Hu", "abstract": "This work elicits LLMs' inherent ability to handle long contexts without\nfine-tuning. The limited length of the training sequence during training may\nlimit the application of Large Language Models (LLMs) on long input sequences\nfor inference. In this work, we argue that existing LLMs themselves have\ninherent capabilities for handling long contexts. Based on this argument, we\nsuggest extending LLMs' context window by themselves to fully utilize the\ninherent ability.We propose Self-Extend to stimulate LLMs' long context\nhandling potential. The basic idea is to construct bi-level attention\ninformation: the group level and the neighbor level. The two levels are\ncomputed by the original model's self-attention, which means the proposed does\nnot require any training. With only four lines of code modification, the\nproposed method can effortlessly extend existing LLMs' context window without\nany fine-tuning. We conduct comprehensive experiments and the results show that\nthe proposed method can effectively extend existing LLMs' context window's\nlength.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01325v1"}
{"title": "Deep autoregressive modeling for land use land cover", "author": "Christopher Krapu, Mark Borsuk, Ryan Calder", "abstract": "Land use / land cover (LULC) modeling is a challenging task due to long-range\ndependencies between geographic features and distinct spatial patterns related\nto topography, ecology, and human development. We identify a close connection\nbetween modeling of spatial patterns of land use and the task of image\ninpainting from computer vision and conduct a study of a modified PixelCNN\narchitecture with approximately 19 million parameters for modeling LULC. In\ncomparison with a benchmark spatial statistical model, we find that the former\nis capable of capturing much richer spatial correlation patterns such as roads\nand water bodies but does not produce a calibrated predictive distribution,\nsuggesting the need for additional tuning. We find evidence of predictive\nunderdispersion with regard to important ecologically-relevant land use\nstatistics such as patch count and adjacency which can be ameliorated to some\nextent by manipulating sampling variability.", "published": "2024-01-02", "categories": ["cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01395v1"}
{"title": "Learning solutions to some toy constrained optimization problems in infinite dimensional Hilbert spaces", "author": "Pinak Mandal", "abstract": "In this work we present deep learning implementations of two popular\ntheoretical constrained optimization algorithms in infinite dimensional Hilbert\nspaces, namely, the penalty and the augmented Lagrangian methods. We test these\nalgorithms on some toy problems originating in either calculus of variations or\nphysics. We demonstrate that both methods are able to produce decent\napproximations for the test problems and are comparable in terms of different\nerrors. Leveraging the common occurrence of the Lagrange multiplier update rule\nbeing computationally less expensive than solving subproblems in the penalty\nmethod, we achieve significant speedups in cases when the output of the\nconstraint function is itself a function.", "published": "2024-01-02", "categories": ["math.OC", "cs.LG"], "links": "http://arxiv.org/abs/2401.01306v1"}
{"title": "Integrating Edges into U-Net Models with Explainable Activation Maps for Brain Tumor Segmentation using MR Images", "author": "Subin Sahayam, Umarani Jayaraman", "abstract": "Manual delineation of tumor regions from magnetic resonance (MR) images is\ntime-consuming, requires an expert, and is prone to human error. In recent\nyears, deep learning models have been the go-to approach for the segmentation\nof brain tumors. U-Net and its' variants for semantic segmentation of medical\nimages have achieved good results in the literature. However, U-Net and its'\nvariants tend to over-segment tumor regions and may not accurately segment the\ntumor edges. The edges of the tumor are as important as the tumor regions for\naccurate diagnosis, surgical precision, and treatment planning. In the proposed\nwork, the authors aim to extract edges from the ground truth using a\nderivative-like filter followed by edge reconstruction to obtain an edge ground\ntruth in addition to the brain tumor ground truth. Utilizing both ground\ntruths, the author studies several U-Net and its' variant architectures with\nand without tumor edges ground truth as a target along with the tumor ground\ntruth for brain tumor segmentation. The author used the BraTS2020 benchmark\ndataset to perform the study and the results are tabulated for the dice and\nHausdorff95 metrics. The mean and median metrics are calculated for the whole\ntumor (WT), tumor core (TC), and enhancing tumor (ET) regions. Compared to the\nbaseline U-Net and its variants, the models that learned edges along with the\ntumor regions performed well in core tumor regions in both training and\nvalidation datasets. The improved performance of edge-trained models trained on\nbaseline models like U-Net and V-Net achieved performance similar to baseline\nstate-of-the-art models like Swin U-Net and hybrid MR-U-Net. The edge-target\ntrained models are capable of generating edge maps that can be useful for\ntreatment planning. Additionally, for further explainability of the results,\nthe activation map generated by the hybrid MR-U-Net has been studied.", "published": "2024-01-02", "categories": ["eess.IV", "cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01303v1"}
{"title": "Efficient Sparse Least Absolute Deviation Regression with Differential Privacy", "author": "Weidong Liu, Xiaojun Mao, Xiaofei Zhang, Xin Zhang", "abstract": "In recent years, privacy-preserving machine learning algorithms have\nattracted increasing attention because of their important applications in many\nscientific fields. However, in the literature, most privacy-preserving\nalgorithms demand learning objectives to be strongly convex and Lipschitz\nsmooth, which thus cannot cover a wide class of robust loss functions (e.g.,\nquantile/least absolute loss). In this work, we aim to develop a fast\nprivacy-preserving learning solution for a sparse robust regression problem.\nOur learning loss consists of a robust least absolute loss and an $\\ell_1$\nsparse penalty term. To fast solve the non-smooth loss under a given privacy\nbudget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE)\nalgorithm for least absolute deviation regression. Our algorithm achieves a\nfast estimation by reformulating the sparse LAD problem as a penalized least\nsquare estimation problem and adopts a three-stage noise injection to guarantee\nthe $(\\epsilon,\\delta)$-differential privacy. We show that our algorithm can\nachieve better privacy and statistical accuracy trade-off compared with the\nstate-of-the-art privacy-preserving regression algorithms. In the end, we\nconduct experiments to verify the efficiency of our proposed FRAPPE algorithm.", "published": "2024-01-02", "categories": ["stat.ML", "cs.LG", "stat.ME", "62J07"], "links": "http://arxiv.org/abs/2401.01294v1"}
{"title": "A Comprehensive Study of Knowledge Editing for Large Language Models", "author": "Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, Siyuan Cheng, Ziwen Xu, Xin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen", "abstract": "Large Language Models (LLMs) have shown extraordinary capabilities in\nunderstanding and generating text that closely mirrors human communication.\nHowever, a primary limitation lies in the significant computational demands\nduring training, arising from their extensive parameterization. This challenge\nis further intensified by the dynamic nature of the world, necessitating\nfrequent updates to LLMs to correct outdated information or integrate new\nknowledge, thereby ensuring their continued relevance. Note that many\napplications demand continual model adjustments post-training to address\ndeficiencies or undesirable behaviors. There is an increasing interest in\nefficient, lightweight methods for on-the-fly model modifications. To this end,\nrecent years have seen a burgeoning in the techniques of knowledge editing for\nLLMs, which aim to efficiently modify LLMs' behaviors within specific domains\nwhile preserving overall performance across various inputs. In this paper, we\nfirst define the knowledge editing problem and then provide a comprehensive\nreview of cutting-edge approaches. Drawing inspiration from educational and\ncognitive research theories, we propose a unified categorization criterion that\nclassifies knowledge editing methods into three groups: resorting to external\nknowledge, merging knowledge into the model, and editing intrinsic knowledge.\nFurthermore, we introduce a new benchmark, KnowEdit, for a comprehensive\nempirical evaluation of representative knowledge editing approaches.\nAdditionally, we provide an in-depth analysis of knowledge location, which can\nprovide a deeper understanding of the knowledge structures inherent within\nLLMs. Finally, we discuss several potential applications of knowledge editing,\noutlining its broad and impactful implications.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "links": "http://arxiv.org/abs/2401.01286v1"}
{"title": "GEqO: ML-Accelerated Semantic Equivalence Detection", "author": "Brandon Haynes, Rana Alotaibi, Anna Pavlenko, Jyoti Leeka, Alekh Jindal, Yuanyuan Tian", "abstract": "Large scale analytics engines have become a core dependency for modern\ndata-driven enterprises to derive business insights and drive actions. These\nengines support a large number of analytic jobs processing huge volumes of data\non a daily basis, and workloads are often inundated with overlapping\ncomputations across multiple jobs. Reusing common computation is crucial for\nefficient cluster resource utilization and reducing job execution time.\nDetecting common computation is the first and key step for reducing this\ncomputational redundancy. However, detecting equivalence on large-scale\nanalytics engines requires efficient and scalable solutions that are fully\nautomated. In addition, to maximize computation reuse, equivalence needs to be\ndetected at the semantic level instead of just the syntactic level (i.e., the\nability to detect semantic equivalence of seemingly different-looking queries).\nUnfortunately, existing solutions fall short of satisfying these requirements.\n  In this paper, we take a major step towards filling this gap by proposing\nGEqO, a portable and lightweight machine-learning-based framework for\nefficiently identifying semantically equivalent computations at scale. GEqO\nintroduces two machine-learning-based filters that quickly prune out\nnonequivalent subexpressions and employs a semi-supervised learning feedback\nloop to iteratively improve its model with an intelligent sampling mechanism.\nFurther, with its novel database-agnostic featurization method, GEqO can\ntransfer the learning from one workload and database to another. Our extensive\nempirical evaluation shows that, on TPC-DS-like queries, GEqO yields\nsignificant performance gains-up to 200x faster than automated verifiers-and\nfinds up to 2x more equivalences than optimizer and signature-based equivalence\ndetection approaches.", "published": "2024-01-02", "categories": ["cs.DB", "cs.LG"], "links": "http://arxiv.org/abs/2401.01280v1"}
{"title": "Learning-based agricultural management in partially observable environments subject to climate variability", "author": "Zhaoan Wang, Shaoping Xiao, Junchao Li, Jun Wang", "abstract": "Agricultural management, with a particular focus on fertilization strategies,\nholds a central role in shaping crop yield, economic profitability, and\nenvironmental sustainability. While conventional guidelines offer valuable\ninsights, their efficacy diminishes when confronted with extreme weather\nconditions, such as heatwaves and droughts. In this study, we introduce an\ninnovative framework that integrates Deep Reinforcement Learning (DRL) with\nRecurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train\nan intelligent agent to master optimal nitrogen fertilization management.\nThrough a series of simulation experiments conducted on corn crops in Iowa, we\ncompare Partially Observable Markov Decision Process (POMDP) models with Markov\nDecision Process (MDP) models. Our research underscores the advantages of\nutilizing sequential observations in developing more efficient nitrogen input\npolicies. Additionally, we explore the impact of climate variability,\nparticularly during extreme weather events, on agricultural outcomes and\nmanagement. Our findings demonstrate the adaptability of fertilization policies\nto varying climate conditions. Notably, a fixed policy exhibits resilience in\nthe face of minor climate fluctuations, leading to commendable corn yields,\ncost-effectiveness, and environmental conservation. However, our study\nilluminates the need for agent retraining to acquire new optimal policies under\nextreme weather events. This research charts a promising course toward\nadaptable fertilization strategies that can seamlessly align with dynamic\nclimate scenarios, ultimately contributing to the optimization of crop\nmanagement practices.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01273v1"}
{"title": "Optimal Rates of Kernel Ridge Regression under Source Condition in Large Dimensions", "author": "Haobo Zhang, Yicheng Li, Weihao Lu, Qian Lin", "abstract": "Motivated by the studies of neural networks (e.g.,the neural tangent kernel\ntheory), we perform a study on the large-dimensional behavior of kernel ridge\nregression (KRR) where the sample size $n \\asymp d^{\\gamma}$ for some $\\gamma >\n0$. Given an RKHS $\\mathcal{H}$ associated with an inner product kernel defined\non the sphere $\\mathbb{S}^{d}$, we suppose that the true function $f_{\\rho}^{*}\n\\in [\\mathcal{H}]^{s}$, the interpolation space of $\\mathcal{H}$ with source\ncondition $s>0$. We first determined the exact order (both upper and lower\nbound) of the generalization error of kernel ridge regression for the optimally\nchosen regularization parameter $\\lambda$. We then further showed that when\n$0<s\\le1$, KRR is minimax optimal; and when $s>1$, KRR is not minimax optimal\n(a.k.a. he saturation effect). Our results illustrate that the curves of rate\nvarying along $\\gamma$ exhibit the periodic plateau behavior and the multiple\ndescent behavior and show how the curves evolve with $s>0$. Interestingly, our\nwork provides a unified viewpoint of several recent works on kernel regression\nin the large-dimensional setting, which correspond to $s=0$ and $s=1$\nrespectively.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01270v1"}
{"title": "$f$-Divergence Based Classification: Beyond the Use of Cross-Entropy", "author": "Nicola Novello, Andrea M. Tonello", "abstract": "In deep learning, classification tasks are formalized as optimization\nproblems solved via the minimization of the cross-entropy. However, recent\nadvancements in the design of objective functions allow the $f$-divergence\nmeasure to generalize the formulation of the optimization problem for\nclassification. With this goal in mind, we adopt a Bayesian perspective and\nformulate the classification task as a maximum a posteriori probability\nproblem. We propose a class of objective functions based on the variational\nrepresentation of the $f$-divergence, from which we extract a list of five\nposterior probability estimators leveraging well-known $f$-divergences. In\naddition, driven by the challenge of improving the state-of-the-art approach,\nwe propose a bottom-up method that leads us to the formulation of a new\nobjective function (and posterior probability estimator) corresponding to a\nnovel $f$-divergence referred to as shifted log (SL). First, we theoretically\nprove the convergence property of the posterior probability estimators. Then,\nwe numerically test the set of proposed objective functions in three\napplication scenarios: toy examples, image data sets, and signal\ndetection/decoding problems. The analyzed tasks demonstrate the effectiveness\nof the proposed estimators and that the SL divergence achieves the highest\nclassification accuracy in almost all the scenarios.", "published": "2024-01-02", "categories": ["cs.LG", "eess.SP"], "links": "http://arxiv.org/abs/2401.01268v1"}
{"title": "Fairness Certification for Natural Language Processing and Large Language Models", "author": "Vincent Freiberger, Erik Buchmann", "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives,\nparticularly due to the enormous progress of Large Language Models (LLM).\nHowever, NLP has many fairness-critical use cases, e.g., as an expert system in\nrecruitment or as an LLM-based tutor in education. Since NLP is based on human\nlanguage, potentially harmful biases can diffuse into NLP systems and produce\nunfair results, discriminate against minorities or generate legal issues.\nHence, it is important to develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certification for\nNLP. In particular, we have reviewed a large body of literature on algorithmic\nfairness, and we have conducted semi-structured expert interviews with a wide\nrange of experts from that area. We have systematically devised six fairness\ncriteria for NLP, which can be further refined into 18 sub-categories. Our\ncriteria offer a foundation for operationalizing and testing processes to\ncertify fairness, both from the perspective of the auditor and the audited\norganization.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "68T50", "I.2.7"], "links": "http://arxiv.org/abs/2401.01262v2"}
{"title": "Do Concept Bottleneck Models Obey Locality?", "author": "Naveen Raman, Mateo Espinosa Zarlenga, Juyeon Heo, Mateja Jamnik", "abstract": "Concept-based learning improves a deep learning model's interpretability by\nexplaining its predictions via human-understandable concepts. Deep learning\nmodels trained under this paradigm heavily rely on the assumption that neural\nnetworks can learn to predict the presence or absence of a given concept\nindependently of other concepts. Recent work, however, strongly suggests that\nthis assumption may fail to hold in Concept Bottleneck Models (CBMs), a\nquintessential family of concept-based interpretable architectures. In this\npaper, we investigate whether CBMs correctly capture the degree of conditional\nindependence across concepts when such concepts are localised both spatially,\nby having their values entirely defined by a fixed subset of features, and\nsemantically, by having their values correlated with only a fixed subset of\npredefined concepts. To understand locality, we analyse how changes to features\noutside of a concept's spatial or semantic locality impact concept predictions.\nOur results suggest that even in well-defined scenarios where the presence of a\nconcept is localised to a fixed feature subspace, or whose semantics are\ncorrelated to a small subset of other concepts, CBMs fail to learn this\nlocality. These results cast doubt upon the quality of concept representations\nlearnt by CBMs and strongly suggest that concept-based explanations may be\nfragile to changes outside their localities.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01259v1"}
{"title": "Towards Model-Free LQR Control over Rate-Limited Channels", "author": "Aritra Mitra, Lintao Ye, Vijay Gupta", "abstract": "Given the success of model-free methods for control design in many problem\nsettings, it is natural to ask how things will change if realistic\ncommunication channels are utilized for the transmission of gradients or\npolicies. While the resulting problem has analogies with the formulations\nstudied under the rubric of networked control systems, the rich literature in\nthat area has typically assumed that the model of the system is known. As a\nstep towards bridging the fields of model-free control design and networked\ncontrol systems, we ask: \\textit{Is it possible to solve basic control problems\n- such as the linear quadratic regulator (LQR) problem - in a model-free manner\nover a rate-limited channel?} Toward answering this question, we study a\nsetting where a worker agent transmits quantized policy gradients (of the LQR\ncost) to a server over a noiseless channel with a finite bit-rate. We propose a\nnew algorithm titled Adaptively Quantized Gradient Descent (\\texttt{AQGD}), and\nprove that above a certain finite threshold bit-rate, \\texttt{AQGD} guarantees\nexponentially fast convergence to the globally optimal policy, with \\textit{no\ndeterioration of the exponent relative to the unquantized setting}. More\ngenerally, our approach reveals the benefits of adaptive quantization in\npreserving fast linear convergence rates, and, as such, may be of independent\ninterest to the literature on compressed optimization.", "published": "2024-01-02", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "links": "http://arxiv.org/abs/2401.01258v1"}
{"title": "Backtracking New Q-Newton's method, Newton's flow, Voronoi's diagram and Stochastic root finding", "author": "John Erik Fornaess, Mi Hu, Tuyen Trung Truong, Takayuki Watanabe", "abstract": "A new variant of Newton's method - named Backtracking New Q-Newton's method\n(BNQN) - which has strong theoretical guarantee, is easy to implement, and has\ngood experimental performance, was recently introduced by the third author.\n  Experiments performed previously showed some remarkable properties of the\nbasins of attractions for finding roots of polynomials and meromorphic\nfunctions, with BNQN. In general, they look more smooth than that of Newton's\nmethod.\n  In this paper, we continue to experimentally explore in depth this remarkable\nphenomenon, and connect BNQN to Newton's flow and Voronoi's diagram. This link\nposes a couple of challenging puzzles to be explained. Experiments also\nindicate that BNQN is more robust against random perturbations than Newton's\nmethod and Random Relaxed Newton's method.", "published": "2024-01-02", "categories": ["math.OC", "cs.LG", "cs.NA", "math.CV", "math.DS", "math.NA"], "links": "http://arxiv.org/abs/2401.01393v1"}
{"title": "Contrastive Sequential Interaction Network Learning on Co-Evolving Riemannian Spaces", "author": "Li Sun, Junda Ye, Jiawei Zhang, Yong Yang, Mingsheng Liu, Feiyang Wang, Philip S. Yu", "abstract": "The sequential interaction network usually find itself in a variety of\napplications, e.g., recommender system. Herein, inferring future interaction is\nof fundamental importance, and previous efforts are mainly focused on the\ndynamics in the classic zero-curvature Euclidean space. Despite the promising\nresults achieved by previous methods, a range of significant issues still\nlargely remains open: On the bipartite nature, is it appropriate to place user\nand item nodes in one identical space regardless of their inherent difference?\nOn the network dynamics, instead of a fixed curvature space, will the\nrepresentation spaces evolve when new interactions arrive continuously? On the\nlearning paradigm, can we get rid of the label information costly to acquire?\nTo address the aforementioned issues, we propose a novel Contrastive model for\nSequential Interaction Network learning on Co-Evolving RiEmannian spaces,\nCSINCERE. To the best of our knowledge, we are the first to introduce a couple\nof co-evolving representation spaces, rather than a single or static space, and\npropose a co-contrastive learning for the sequential interaction network. In\nCSINCERE, we formulate a Cross-Space Aggregation for message-passing across\nrepresentation spaces of different Riemannian geometries, and design a Neural\nCurvature Estimator based on Ricci curvatures for modeling the space evolvement\nover time. Thereafter, we present a Reweighed Co-Contrast between the temporal\nviews of the sequential network, so that the couple of Riemannian spaces\ninteract with each other for the interaction prediction without labels.\nEmpirical results on 5 public datasets show the superiority of CSINCERE over\nthe state-of-the-art methods.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01243v1"}
{"title": "Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning", "author": "Tobias Engelhardt Rasmussen, Siv S√∏rensen", "abstract": "Broadband infrastructure owners do not always know how their customers are\nconnected in the local networks, which are structured as rooted trees. A recent\nstudy is able to infer the topology of a local network using discrete time\nseries data from the leaves of the tree (customers). In this study we propose a\ncontrastive approach for learning a binary event encoder from continuous time\nseries data. As a preliminary result, we show that our approach has some\npotential in learning a valuable encoder.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.SI", "stat.ML"], "links": "http://arxiv.org/abs/2401.01242v1"}
{"title": "Graph Elimination Networks", "author": "Shuo Wang, Ge Cheng, Yun Zhang", "abstract": "Graph Neural Networks (GNNs) are widely applied across various domains, yet\nthey perform poorly in deep layers. Existing research typically attributes this\nproblem to node over-smoothing, where node representations become\nindistinguishable after multiple rounds of propagation. In this paper, we delve\ninto the neighborhood propagation mechanism of GNNs and discover that the real\nroot cause of GNNs' performance degradation in deep layers lies in ineffective\nneighborhood feature propagation. This propagation leads to an exponential\ngrowth of a node's current representation at every propagation step, making it\nextremely challenging to capture valuable dependencies between long-distance\nnodes. To address this issue, we introduce Graph Elimination Networks (GENs),\nwhich employ a specific algorithm to eliminate redundancies during neighborhood\npropagation. We demonstrate that GENs can enhance nodes' perception of distant\nneighborhoods and extend the depth of network propagation. Extensive\nexperiments show that GENs outperform the state-of-the-art methods on various\ngraph-level and node-level datasets.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01233v1"}
{"title": "Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning", "author": "Li Sun, Zhenhao Huang, Zixi Wang, Feiyang Wang, Hao Peng, Philip Yu", "abstract": "Graphs are typical non-Euclidean data of complex structures. In recent years,\nRiemannian graph representation learning has emerged as an exciting alternative\nto Euclidean ones. However, Riemannian methods are still in an early stage:\nmost of them present a single curvature (radius) regardless of structural\ncomplexity, suffer from numerical instability due to the\nexponential/logarithmic map, and lack the ability to capture motif regularity.\nIn light of the issues above, we propose the problem of \\emph{Motif-aware\nRiemannian Graph Representation Learning}, seeking a numerically stable encoder\nto capture motif regularity in a diverse-curvature manifold without labels. To\nthis end, we present a novel Motif-aware Riemannian model with\nGenerative-Contrastive learning (MotifRGC), which conducts a minmax game in\nRiemannian manifold in a self-supervised manner. First, we propose a new type\nof Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold\nby a product layer with the diversified factor, and replace the\nexponential/logarithmic map by a stable kernel layer. Second, we introduce a\nmotif-aware Riemannian generative-contrastive learning to capture motif\nregularity in the constructed manifold and learn motif-aware node\nrepresentation without external labels. Empirical results show the superiority\nof MofitRGC.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01232v1"}
{"title": "Zero-Shot Position Debiasing for Large Language Models", "author": "Zhongkun Liu, Zheng Chen, Mengqi Zhang, Zhaochun Ren, Zhumin Chen, Pengjie Ren", "abstract": "Fine-tuning has been demonstrated to be an effective method to improve the\ndomain performance of large language models (LLMs). However, LLMs might fit the\ndataset bias and shortcuts for prediction, leading to poor generation\nperformance. Experimental result shows that LLMs are prone to exhibit position\nbias, i.e., leveraging information positioned at the beginning or end, or\nspecific positional cues within the input. Existing works on mitigating\nposition bias require external bias knowledge or annotated non-biased samples,\nwhich is unpractical in reality. In this work, we propose a zero-shot position\ndebiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages\nunsupervised responses from pre-trained LLMs for debiasing, thus without any\nexternal knowledge or datasets. To improve the quality of unsupervised\nresponses, we propose a master-slave alignment (MSA) module to prune these\nresponses. Experiments on eight datasets and five tasks show that ZOE\nconsistently outperforms existing methods in mitigating four types of position\nbiases. Besides, ZOE achieves this by sacrificing only a small performance on\nbiased samples, which is simple and effective.", "published": "2024-01-02", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "links": "http://arxiv.org/abs/2401.01218v1"}
{"title": "Whole-examination AI estimation of fetal biometrics from 20-week ultrasound scans", "author": "Lorenzo Venturini, Samuel Budd, Alfonso Farruggia, Robert Wright, Jacqueline Matthew, Thomas G. Day, Bernhard Kainz, Reza Razavi, Jo V. Hajnal", "abstract": "The current approach to fetal anomaly screening is based on biometric\nmeasurements derived from individually selected ultrasound images. In this\npaper, we introduce a paradigm shift that attains human-level performance in\nbiometric measurement by aggregating automatically extracted biometrics from\nevery frame across an entire scan, with no need for operator intervention. We\nuse a convolutional neural network to classify each frame of an ultrasound\nvideo recording. We then measure fetal biometrics in every frame where\nappropriate anatomy is visible. We use a Bayesian method to estimate the true\nvalue of each biometric from a large number of measurements and\nprobabilistically reject outliers. We performed a retrospective experiment on\n1457 recordings (comprising 48 million frames) of 20-week ultrasound scans,\nestimated fetal biometrics in those scans and compared our estimates to the\nmeasurements sonographers took during the scan. Our method achieves human-level\nperformance in estimating fetal biometrics and estimates well-calibrated\ncredible intervals in which the true biometric value is expected to lie.", "published": "2024-01-02", "categories": ["cs.CV", "cs.LG", "I.4.7; J.3"], "links": "http://arxiv.org/abs/2401.01201v1"}
{"title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example", "author": "Benedetta Tondi, Wei Guo, Mauro Barni", "abstract": "Most of the approaches proposed so far to craft targeted adversarial examples\nagainst Deep Learning classifiers are highly suboptimal and typically rely on\nincreasing the likelihood of the target class, thus implicitly focusing on\none-hot encoding settings. In this paper, we propose a more general,\ntheoretically sound, targeted attack that resorts to the minimization of a\nJacobian-induced MAhalanobis distance (JMA) term, taking into account the\neffort (in the input space) required to move the latent space representation of\nthe input sample in a given direction. The minimization is solved by exploiting\nthe Wolfe duality theorem, reducing the problem to the solution of a\nNon-Negative Least Square (NNLS) problem. The proposed algorithm provides an\noptimal solution to a linearized version of the adversarial example problem\noriginally introduced by Szegedy et al. \\cite{szegedy2013intriguing}. The\nexperiments we carried out confirm the generality of the proposed attack which\nis proven to be effective under a wide variety of output encoding schemes.\nNoticeably, the JMA attack is also effective in a multi-label classification\nscenario, being capable to induce a targeted modification of up to half the\nlabels in a complex multilabel classification scenario with 20 labels, a\ncapability that is out of reach of all the attacks proposed so far. As a\nfurther advantage, the JMA attack usually requires very few iterations, thus\nresulting more efficient than existing methods.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.CV"], "links": "http://arxiv.org/abs/2401.01199v1"}
{"title": "Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems", "author": "Moritz Vinzent Seiler, Pascal Kerschke, Heike Trautmann", "abstract": "In many recent works, the potential of Exploratory Landscape Analysis (ELA)\nfeatures to numerically characterize, in particular, single-objective\ncontinuous optimization problems has been demonstrated. These numerical\nfeatures provide the input for all kinds of machine learning tasks on\ncontinuous optimization problems, ranging, i.a., from High-level Property\nPrediction to Automated Algorithm Selection and Automated Algorithm\nConfiguration. Without ELA features, analyzing and understanding the\ncharacteristics of single-objective continuous optimization problems would be\nimpossible.\n  Yet, despite their undisputed usefulness, ELA features suffer from several\ndrawbacks. These include, in particular, (1.) a strong correlation between\nmultiple features, as well as (2.) its very limited applicability to\nmulti-objective continuous optimization problems. As a remedy, recent works\nproposed deep learning-based approaches as alternatives to ELA. In these works,\ne.g., point-cloud transformers were used to characterize an optimization\nproblem's fitness landscape. However, these approaches require a large amount\nof labeled training data.\n  Within this work, we propose a hybrid approach, Deep-ELA, which combines (the\nbenefits of) deep learning and ELA features. Specifically, we pre-trained four\ntransformers on millions of randomly generated optimization problems to learn\ndeep representations of the landscapes of continuous single- and\nmulti-objective optimization problems. Our proposed framework can either be\nused out-of-the-box for analyzing single- and multi-objective continuous\noptimization problems, or subsequently fine-tuned to various tasks focussing on\nalgorithm behavior and problem understanding.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01192v1"}
{"title": "Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training", "author": "Jiuming Qin, Che Liu, Sibo Cheng, Yike Guo, Rossella Arcucci", "abstract": "Modern healthcare often utilises radiographic images alongside textual\nreports for diagnostics, encouraging the use of Vision-Language Self-Supervised\nLearning (VL-SSL) with large pre-trained models to learn versatile medical\nvision representations. However, most existing VL-SSL frameworks are trained\nend-to-end, which is computation-heavy and can lose vital prior information\nembedded in pre-trained encoders. To address both issues, we introduce the\nbackbone-agnostic Adaptor framework, which preserves medical knowledge in\npre-trained image and text encoders by keeping them frozen, and employs a\nlightweight Adaptor module for cross-modal learning. Experiments on medical\nimage classification and segmentation tasks across three datasets reveal that\nour framework delivers competitive performance while cutting trainable\nparameters by over 90% compared to current pre-training approaches. Notably,\nwhen fine-tuned with just 1% of data, Adaptor outperforms several\nTransformer-based methods trained on full datasets in medical image\nsegmentation.", "published": "2024-01-02", "categories": ["cs.CV", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01179v1"}
{"title": "Fundamental Limitation of Semantic Communications: Neural Estimation for Rate-Distortion", "author": "Dongxu Li, Jianhao Huang, Chuan Huang, Xiaoqi Qin, Han Zhang, Ping Zhang", "abstract": "This paper studies the fundamental limit of semantic communications over the\ndiscrete memoryless channel. We consider the scenario to send a semantic source\nconsisting of an observation state and its corresponding semantic state, both\nof which are recovered at the receiver. To derive the performance limitation,\nwe adopt the semantic rate-distortion function (SRDF) to study the relationship\namong the minimum compression rate, observation distortion, semantic\ndistortion, and channel capacity. For the case with unknown semantic source\ndistribution, while only a set of the source samples is available, we propose a\nneural-network-based method by leveraging the generative networks to learn the\nsemantic source distribution. Furthermore, for a special case where the\nsemantic state is a deterministic function of the observation, we design a\ncascade neural network to estimate the SRDF. For the case with perfectly known\nsemantic source distribution, we propose a general Blahut-Arimoto algorithm to\neffectively compute the SRDF. Finally, experimental results validate our\nproposed algorithms for the scenarios with ideal Gaussian semantic source and\nsome practical datasets.", "published": "2024-01-02", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "links": "http://arxiv.org/abs/2401.01176v1"}
{"title": "Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults", "author": "Mohammad Al-Sa'd, Tuomas Jalonen, Serkan Kiranyaz, Moncef Gabbouj", "abstract": "Diagnosis of bearing faults is paramount to reducing maintenance costs and\noperational breakdowns. Bearing faults are primary contributors to machine\nvibrations, and analyzing their signal morphology offers insights into their\nhealth status. Unfortunately, existing approaches are optimized for controlled\nenvironments, neglecting realistic conditions such as time-varying rotational\nspeeds and the vibration's non-stationary nature. This paper presents a fusion\nof time-frequency analysis and deep learning techniques to diagnose bearing\nfaults under time-varying speeds and varying noise levels. First, we formulate\nthe bearing fault-induced vibrations and discuss the link between their\nnon-stationarity and the bearing's inherent and operational parameters. We also\nelucidate quadratic time-frequency distributions and validate their\neffectiveness in resolving distinctive dynamic patterns associated with\ndifferent bearing faults. Based on this, we design a time-frequency\nconvolutional neural network (TF-CNN) to diagnose various faults in\nrolling-element bearings. Our experimental findings undeniably demonstrate the\nsuperior performance of TF-CNN in comparison to recently developed techniques.\nThey also assert its versatility in capturing fault-relevant non-stationary\nfeatures that couple with speed changes and show its exceptional resilience to\nnoise, consistently surpassing competing methods across various signal-to-noise\nratios and performance metrics. Altogether, the TF-CNN achieves substantial\naccuracy improvements up to 15%, in severe noise conditions.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "links": "http://arxiv.org/abs/2401.01172v1"}
{"title": "FedQV: Leveraging Quadratic Voting in Federated Learning", "author": "Tianyue Chu, Nikolaos Laoutaris", "abstract": "Federated Learning (FL) permits different parties to collaboratively train a\nglobal model without disclosing their respective local labels. A crucial step\nof FL, that of aggregating local models to produce the global one, shares many\nsimilarities with public decision-making, and elections in particular. In that\ncontext, a major weakness of FL, namely its vulnerability to poisoning attacks,\ncan be interpreted as a consequence of the one person one vote (henceforth\n1p1v) principle underpinning most contemporary aggregation rules. In this\npaper, we propose FedQV, a novel aggregation algorithm built upon the quadratic\nvoting scheme, recently proposed as a better alternative to 1p1v-based\nelections. Our theoretical analysis establishes that FedQV is a truthful\nmechanism in which bidding according to one's true valuation is a dominant\nstrategy that achieves a convergence rate that matches those of\nstate-of-the-art methods. Furthermore, our empirical analysis using multiple\nreal-world datasets validates the superior performance of FedQV against\npoisoning attacks. It also shows that combining FedQV with unequal voting\n``budgets'' according to a reputation score increases its performance benefits\neven further. Finally, we show that FedQV can be easily combined with\nByzantine-robust privacy-preserving mechanisms to enhance its robustness\nagainst both poisoning and privacy attacks.", "published": "2024-01-02", "categories": ["cs.CR", "cs.LG"], "links": "http://arxiv.org/abs/2401.01168v1"}
{"title": "Reinforcement Learning for SAR View Angle Inversion with Differentiable SAR Renderer", "author": "Yanni Wang, Hecheng Jia, Shilei Fu, Huiping Lin, Feng Xu", "abstract": "The electromagnetic inverse problem has long been a research hotspot. This\nstudy aims to reverse radar view angles in synthetic aperture radar (SAR)\nimages given a target model. Nonetheless, the scarcity of SAR data, combined\nwith the intricate background interference and imaging mechanisms, limit the\napplications of existing learning-based approaches. To address these\nchallenges, we propose an interactive deep reinforcement learning (DRL)\nframework, where an electromagnetic simulator named differentiable SAR render\n(DSR) is embedded to facilitate the interaction between the agent and the\nenvironment, simulating a human-like process of angle prediction. Specifically,\nDSR generates SAR images at arbitrary view angles in real-time. And the\ndifferences in sequential and semantic aspects between the view\nangle-corresponding images are leveraged to construct the state space in DRL,\nwhich effectively suppress the complex background interference, enhance the\nsensitivity to temporal variations, and improve the capability to capture\nfine-grained information. Additionally, in order to maintain the stability and\nconvergence of our method, a series of reward mechanisms, such as memory\ndifference, smoothing and boundary penalty, are utilized to form the final\nreward function. Extensive experiments performed on both simulated and real\ndatasets demonstrate the effectiveness and robustness of our proposed method.\nWhen utilized in the cross-domain area, the proposed method greatly mitigates\ninconsistency between simulated and real domains, outperforming reference\nmethods significantly.", "published": "2024-01-02", "categories": ["cs.LG", "eess.SP"], "links": "http://arxiv.org/abs/2401.01165v1"}
{"title": "Train-Free Segmentation in MRI with Cubical Persistent Homology", "author": "Anton Fran√ßois, Rapha√´l Tinarrage", "abstract": "We describe a new general method for segmentation in MRI scans using\nTopological Data Analysis (TDA), offering several advantages over traditional\nmachine learning approaches. It works in three steps, first identifying the\nwhole object to segment via automatic thresholding, then detecting a\ndistinctive subset whose topology is known in advance, and finally deducing the\nvarious components of the segmentation. Although convoking classical ideas of\nTDA, such an algorithm has never been proposed separately from deep learning\nmethods. To achieve this, our approach takes into account, in addition to the\nhomology of the image, the localization of representative cycles, a piece of\ninformation that seems never to have been exploited in this context. In\nparticular, it offers the ability to perform segmentation without the need for\nlarge annotated data sets. TDA also provides a more interpretable and stable\nframework for segmentation by explicitly mapping topological features to\nsegmentation components. By adapting the geometric object to be detected, the\nalgorithm can be adjusted to a wide range of data segmentation challenges. We\ncarefully study the examples of glioblastoma segmentation in brain MRI, where a\nsphere is to be detected, as well as myocardium in cardiac MRI, involving a\ncylinder, and cortical plate detection in fetal brain MRI, whose 2D slices are\ncircles. We compare our method to state-of-the-art algorithms.", "published": "2024-01-02", "categories": ["eess.IV", "cs.CG", "cs.CV", "cs.LG", "55N31, 68-04, 92-08, 68U10"], "links": "http://arxiv.org/abs/2401.01160v1"}
{"title": "Deep Learning-Based Detection for Marker Codes over Insertion and Deletion Channels", "author": "Guochen Ma, Xiaopeng Jiao, Jianjun Mu, Hui Han, Yaming Yang", "abstract": "Marker code is an effective coding scheme to protect data from insertions and\ndeletions. It has potential applications in future storage systems, such as DNA\nstorage and racetrack memory. When decoding marker codes, perfect channel state\ninformation (CSI), i.e., insertion and deletion probabilities, are required to\ndetect insertion and deletion errors. Sometimes, the perfect CSI is not easy to\nobtain or the accurate channel model is unknown. Therefore, it is deserved to\ndevelop detecting algorithms for marker code without the knowledge of perfect\nCSI. In this paper, we propose two CSI-agnostic detecting algorithms for marker\ncode based on deep learning. The first one is a model-driven deep learning\nmethod, which deep unfolds the original iterative detecting algorithm of marker\ncode. In this method, CSI become weights in neural networks and these weights\ncan be learned from training data. The second one is a data-driven method which\nis an end-to-end system based on the deep bidirectional gated recurrent unit\nnetwork. Simulation results show that error performances of the proposed\nmethods are significantly better than that of the original detection algorithm\nwith CSI uncertainty. Furthermore, the proposed data-driven method exhibits\nbetter error performances than other methods for unknown channel models.", "published": "2024-01-02", "categories": ["cs.IT", "cs.LG", "math.IT"], "links": "http://arxiv.org/abs/2401.01155v1"}
{"title": "PAC-Bayes-Chernoff bounds for unbounded losses", "author": "Ioar Casado, Luis A. Ortega, Andr√©s R. Masegosa, Aritz P√©rez", "abstract": "We present a new high-probability PAC-Bayes oracle bound for unbounded\nlosses. This result can be understood as a PAC-Bayes version of the Chernoff\nbound. The proof technique relies on uniformly bounding the tail of certain\nrandom variable based on the Cram\\'er transform of the loss. We highlight two\napplications of our main result. First, we show that our bound solves the open\nproblem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we\nshow that our approach allows working with flexible assumptions on the loss\nfunction, resulting in novel bounds that generalize previous ones and can be\nminimized to obtain Gibbs-like posteriors.", "published": "2024-01-02", "categories": ["stat.ML", "cs.LG"], "links": "http://arxiv.org/abs/2401.01148v1"}
{"title": "HAAQI-Net: A non-intrusive neural music quality assessment model for hearing aids", "author": "Dyah A. M. G. Wisnu, Epri Pratiwi, Stefano Rini, Ryandhimas E. Zezario, Hsin-Min Wang, Yu Tsao", "abstract": "This paper introduces HAAQI-Net, a non-intrusive deep learning model for\nmusic quality assessment tailored to hearing aid users. In contrast to\ntraditional methods like the Hearing Aid Audio Quality Index (HAAQI), HAAQI-Net\nutilizes a Bidirectional Long Short-Term Memory (BLSTM) with attention. It\ntakes an assessed music sample and a hearing loss pattern as input, generating\na predicted HAAQI score. The model employs the pre-trained Bidirectional\nEncoder representation from Audio Transformers (BEATs) for acoustic feature\nextraction. Comparing predicted scores with ground truth, HAAQI-Net achieves a\nLongitudinal Concordance Correlation (LCC) of 0.9257, Spearman's Rank\nCorrelation Coefficient (SRCC) of 0.9394, and Mean Squared Error (MSE) of\n0.0080. Notably, this high performance comes with a substantial reduction in\ninference time: from 62.52 seconds (by HAAQI) to 2.71 seconds (by HAAQI-Net),\nserving as an efficient music quality assessment model for hearing aid users.", "published": "2024-01-02", "categories": ["eess.AS", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.01145v1"}
{"title": "On Optimal Sampling for Learning SDF Using MLPs Equipped with Positional Encoding", "author": "Guying Lin, Lei Yang, Yuan Liu, Congyi Zhang, Junhui Hou, Xiaogang Jin, Taku Komura, John Keyser, Wenping Wang", "abstract": "Neural implicit fields, such as the neural signed distance field (SDF) of a\nshape, have emerged as a powerful representation for many applications, e.g.,\nencoding a 3D shape and performing collision detection. Typically, implicit\nfields are encoded by Multi-layer Perceptrons (MLP) with positional encoding\n(PE) to capture high-frequency geometric details. However, a notable side\neffect of such PE-equipped MLPs is the noisy artifacts present in the learned\nimplicit fields. While increasing the sampling rate could in general mitigate\nthese artifacts, in this paper we aim to explain this adverse phenomenon\nthrough the lens of Fourier analysis. We devise a tool to determine the\nappropriate sampling rate for learning an accurate neural implicit field\nwithout undesirable side effects. Specifically, we propose a simple yet\neffective method to estimate the intrinsic frequency of a given network with\nrandomized weights based on the Fourier analysis of the network's responses. It\nis observed that a PE-equipped MLP has an intrinsic frequency much higher than\nthe highest frequency component in the PE layer. Sampling against this\nintrinsic frequency following the Nyquist-Sannon sampling theorem allows us to\ndetermine an appropriate training sampling rate. We empirically show in the\nsetting of SDF fitting that this recommended sampling rate is sufficient to\nsecure accurate fitting results, while further increasing the sampling rate\nwould not further noticeably reduce the fitting error. Training PE-equipped\nMLPs simply with our sampling strategy leads to performances superior to the\nexisting methods.", "published": "2024-01-02", "categories": ["cs.CV", "cs.GR", "cs.LG"], "links": "http://arxiv.org/abs/2401.01391v1"}
{"title": "Explainable Adaptive Tree-based Model Selection for Time Series Forecasting", "author": "Matthias Jakobs, Amal Saadallah", "abstract": "Tree-based models have been successfully applied to a wide variety of tasks,\nincluding time series forecasting. They are increasingly in demand and widely\naccepted because of their comparatively high level of interpretability.\nHowever, many of them suffer from the overfitting problem, which limits their\napplication in real-world decision-making. This problem becomes even more\nsevere in online-forecasting settings where time series observations are\nincrementally acquired, and the distributions from which they are drawn may\nkeep changing over time. In this context, we propose a novel method for the\nonline selection of tree-based models using the TreeSHAP explainability method\nin the task of time series forecasting. We start with an arbitrary set of\ndifferent tree-based models. Then, we outline a performance-based ranking with\na coherent design to make TreeSHAP able to specialize the tree-based\nforecasters across different regions in the input time series. In this\nframework, adequate model selection is performed online, adaptively following\ndrift detection in the time series. In addition, explainability is supported on\nthree levels, namely online input importance, model selection, and model output\nexplanation. An extensive empirical study on various real-world datasets\ndemonstrates that our method achieves excellent or on-par results in comparison\nto the state-of-the-art approaches as well as several baselines.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01124v1"}
{"title": "Utilizing Autoregressive Networks for Full Lifecycle Data Generation of Rolling Bearings for RUL Prediction", "author": "Junliang Wang, Qinghua Zhang, Guanhua Zhu, Guoxi Sun", "abstract": "The prediction of rolling bearing lifespan is of significant importance in\nindustrial production. However, the scarcity of high-quality, full lifecycle\ndata has been a major constraint in achieving precise predictions. To address\nthis challenge, this paper introduces the CVGAN model, a novel framework\ncapable of generating one-dimensional vibration signals in both horizontal and\nvertical directions, conditioned on historical vibration data and remaining\nuseful life. In addition, we propose an autoregressive generation method that\ncan iteratively utilize previously generated vibration information to guide the\ngeneration of current signals. The effectiveness of the CVGAN model is\nvalidated through experiments conducted on the PHM 2012 dataset. Our findings\ndemonstrate that the CVGAN model, in terms of both MMD and FID metrics,\noutperforms many advanced methods in both autoregressive and non-autoregressive\ngeneration modes. Notably, training using the full lifecycle data generated by\nthe CVGAN model significantly improves the performance of the predictive model.\nThis result highlights the effectiveness of the data generated by CVGans in\nenhancing the predictive power of these models.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01119v1"}
{"title": "Scalable manifold learning by uniform landmark sampling and constrained locally linear embedding", "author": "Dehua Peng, Zhipeng Gui, Wenzhang Wei, Huayi Wu", "abstract": "As a pivotal approach in machine learning and data science, manifold learning\naims to uncover the intrinsic low-dimensional structure within complex\nnonlinear manifolds in high-dimensional space. By exploiting the manifold\nhypothesis, various techniques for nonlinear dimension reduction have been\ndeveloped to facilitate visualization, classification, clustering, and gaining\nkey insights. Although existing manifold learning methods have achieved\nremarkable successes, they still suffer from extensive distortions incurred in\nthe global structure, which hinders the understanding of underlying patterns.\nScalability issues also limit their applicability for handling large-scale\ndata. Here, we propose a scalable manifold learning (scML) method that can\nmanipulate large-scale and high-dimensional data in an efficient manner. It\nstarts by seeking a set of landmarks to construct the low-dimensional skeleton\nof the entire data and then incorporates the non-landmarks into the landmark\nspace based on the constrained locally linear embedding (CLLE). We empirically\nvalidated the effectiveness of scML on synthetic datasets and real-world\nbenchmarks of different types, and applied it to analyze the single-cell\ntranscriptomics and detect anomalies in electrocardiogram (ECG) signals. scML\nscales well with increasing data sizes and exhibits promising performance in\npreserving the global structure. The experiments demonstrate notable robustness\nin embedding quality as the sample rate decreases.", "published": "2024-01-02", "categories": ["cs.LG", "I.5.3"], "links": "http://arxiv.org/abs/2401.01100v1"}
{"title": "Efficient Parallel Audio Generation using Group Masked Language Modeling", "author": "Myeonghun Jeong, Minchan Kim, Joun Yeop Lee, Nam Soo Kim", "abstract": "We present a fast and high-quality codec language model for parallel audio\ngeneration. While SoundStorm, a state-of-the-art parallel audio generation\nmodel, accelerates inference speed compared to autoregressive models, it still\nsuffers from slow inference due to iterative sampling. To resolve this problem,\nwe propose Group-Masked Language Modeling~(G-MLM) and Group Iterative Parallel\nDecoding~(G-IPD) for efficient parallel audio generation. Both the training and\nsampling schemes enable the model to synthesize high-quality audio with a small\nnumber of iterations by effectively modeling the group-wise conditional\ndependencies. In addition, our model employs a cross-attention-based\narchitecture to capture the speaker style of the prompt voice and improves\ncomputational efficiency. Experimental results demonstrate that our proposed\nmodel outperforms the baselines in prompt-based audio generation.", "published": "2024-01-02", "categories": ["eess.AS", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01099v1"}
{"title": "Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control", "author": "Ka-Ho Chow, Wenqi Wei, Lei Yu", "abstract": "Revolutionized by the transformer architecture, natural language processing\n(NLP) has received unprecedented attention. While advancements in NLP models\nhave led to extensive research into their backdoor vulnerabilities, the\npotential for these advancements to introduce new backdoor threats remains\nunexplored. This paper proposes Imperio, which harnesses the language\nunderstanding capabilities of NLP models to enrich backdoor attacks. Imperio\nprovides a new model control experience. It empowers the adversary to control\nthe victim model with arbitrary output through language-guided instructions.\nThis is achieved using a language model to fuel a conditional trigger\ngenerator, with optimizations designed to extend its language understanding\ncapabilities to backdoor instruction interpretation and execution. Our\nexperiments across three datasets, five attacks, and nine defenses confirm\nImperio's effectiveness. It can produce contextually adaptive triggers from\ntext descriptions and control the victim model with desired outputs, even in\nscenarios not encountered during training. The attack maintains a high success\nrate across complex datasets without compromising the accuracy of clean inputs\nand also exhibits resilience against representative defenses. The source code\nis available at \\url{https://khchow.com/Imperio}.", "published": "2024-01-02", "categories": ["cs.CR", "cs.LG"], "links": "http://arxiv.org/abs/2401.01085v1"}
{"title": "Global Convergence of Natural Policy Gradient with Hessian-aided Momentum Variance Reduction", "author": "Jie Feng, Ke Wei, Jinchi Chen", "abstract": "Natural policy gradient (NPG) and its variants are widely-used policy search\nmethods in reinforcement learning. Inspired by prior work, a new NPG variant\ncoined NPG-HM is developed in this paper, which utilizes the Hessian-aided\nmomentum technique for variance reduction, while the sub-problem is solved via\nthe stochastic gradient descent method. It is shown that NPG-HM can achieve the\nglobal last iterate $\\epsilon$-optimality with a sample complexity of\n$\\mathcal{O}(\\epsilon^{-2})$, which is the best known result for natural policy\ngradient type methods under the generic Fisher non-degenerate policy\nparameterizations. The convergence analysis is built upon a relaxed weak\ngradient dominance property tailored for NPG under the compatible function\napproximation framework, as well as a neat way to decompose the error when\nhandling the sub-problem. Moreover, numerical experiments on Mujoco-based\nenvironments demonstrate the superior performance of NPG-HM over other\nstate-of-the-art policy gradient methods.", "published": "2024-01-02", "categories": ["cs.LG", "math.OC"], "links": "http://arxiv.org/abs/2401.01084v1"}
{"title": "Aircraft Landing Time Prediction with Deep Learning on Trajectory Images", "author": "Liping Huang, Sheng Zhang, Yicheng Zhang, Yi Zhang, Yifang Yin", "abstract": "Aircraft landing time (ALT) prediction is crucial for air traffic management,\nespecially for arrival aircraft sequencing on the runway. In this study, a\ntrajectory image-based deep learning method is proposed to predict ALTs for the\naircraft entering the research airspace that covers the Terminal Maneuvering\nArea (TMA). Specifically, the trajectories of all airborne arrival aircraft\nwithin the temporal capture window are used to generate an image with the\ntarget aircraft trajectory labeled as red and all background aircraft\ntrajectory labeled as blue. The trajectory images contain various information,\nincluding the aircraft position, speed, heading, relative distances, and\narrival traffic flows. It enables us to use state-of-the-art deep convolution\nneural networks for ALT modeling. We also use real-time runway usage obtained\nfrom the trajectory data and the external information such as aircraft types\nand weather conditions as additional inputs. Moreover, a convolution neural\nnetwork (CNN) based module is designed for automatic holding-related\nfeaturizing, which takes the trajectory images, the leading aircraft holding\nstatus, and their time and speed gap at the research airspace boundary as its\ninputs. Its output is further fed into the final end-to-end ALT prediction. The\nproposed ALT prediction approach is applied to Singapore Changi Airport (ICAO\nCode: WSSS) using one-month Automatic Dependent Surveillance-Broadcast (ADS-B)\ndata from November 1 to November 30, 2022. Experimental results show that by\nintegrating the holding featurization, we can reduce the mean absolute error\n(MAE) from 82.23 seconds to 43.96 seconds, and achieve an average accuracy of\n96.1\\%, with 79.4\\% of the predictions errors being less than 60 seconds.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01083v1"}
{"title": "Constrained Online Two-stage Stochastic Optimization: Algorithm with (and without) Predictions", "author": "Piao Hu, Jiashuo Jiang, Guodong Lyu, Hao Su", "abstract": "We consider an online two-stage stochastic optimization with long-term\nconstraints over a finite horizon of $T$ periods. At each period, we take the\nfirst-stage action, observe a model parameter realization and then take the\nsecond-stage action from a feasible set that depends both on the first-stage\ndecision and the model parameter. We aim to minimize the cumulative objective\nvalue while guaranteeing that the long-term average second-stage decision\nbelongs to a set. We develop online algorithms for the online two-stage problem\nfrom adversarial learning algorithms. Also, the regret bound of our algorithm\ncan be reduced to the regret bound of embedded adversarial learning algorithms.\nBased on this framework, we obtain new results under various settings. When the\nmodel parameters are drawn from unknown non-stationary distributions and we are\ngiven machine-learned predictions of the distributions, we develop a new\nalgorithm from our framework with a regret $O(W_T+\\sqrt{T})$, where $W_T$\nmeasures the total inaccuracy of the machine-learned predictions. We then\ndevelop another algorithm that works when no machine-learned predictions are\ngiven and show the performances.", "published": "2024-01-02", "categories": ["cs.LG"], "links": "http://arxiv.org/abs/2401.01077v1"}
{"title": "Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction", "author": "Yunpeng Qu, Zhilin Lu, Rui Zeng, Jintao Wang, Jian Wang", "abstract": "Automatic Modulation Recognition (AMR) plays a crucial role in wireless\ncommunication systems. Deep learning AMR strategies have achieved tremendous\nsuccess in recent years. Modulated signals exhibit long temporal dependencies,\nand extracting global features is crucial in identifying modulation schemes.\nTraditionally, human experts analyze patterns in constellation diagrams to\nclassify modulation schemes. Classical convolutional-based networks, due to\ntheir limited receptive fields, excel at extracting local features but struggle\nto capture global relationships. To address this limitation, we introduce a\nnovel hybrid deep framework named TLDNN, which incorporates the architectures\nof the transformer and long short-term memory (LSTM). We utilize the\nself-attention mechanism of the transformer to model the global correlations in\nsignal sequences while employing LSTM to enhance the capture of temporal\ndependencies. To mitigate the impact like RF fingerprint features and channel\ncharacteristics on model generalization, we propose data augmentation\nstrategies known as segment substitution (SS) to enhance the model's robustness\nto modulation-related features. Experimental results on widely-used datasets\ndemonstrate that our method achieves state-of-the-art performance and exhibits\nsignificant advantages in terms of complexity. Our proposed framework serves as\na foundational backbone that can be extended to different datasets. We have\nverified the effectiveness of our augmentation approach in enhancing the\ngeneralization of the models, particularly in few-shot scenarios. Code is\navailable at \\url{https://github.com/AMR-Master/TLDNN}.", "published": "2024-01-02", "categories": ["eess.SP", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01056v1"}
{"title": "Elastic Multi-Gradient Descent for Parallel Continual Learning", "author": "Fan Lyu, Wei Feng, Yuepan Li, Qing Sun, Fanhua Shang, Liang Wan, Liang Wang", "abstract": "The goal of Continual Learning (CL) is to continuously learn from new data\nstreams and accomplish the corresponding tasks. Previously studied CL assumes\nthat data are given in sequence nose-to-tail for different tasks, thus indeed\nbelonging to Serial Continual Learning (SCL). This paper studies the novel\nparadigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios,\nwhere a diverse set of tasks is encountered at different time points. PCL\npresents challenges due to the training of an unspecified number of tasks with\nvarying learning progress, leading to the difficulty of guaranteeing effective\nmodel updates for all encountered tasks. In our previous conference work, we\nfocused on measuring and reducing the discrepancy among gradients in a\nmulti-objective optimization problem, which, however, may still contain\nnegative transfers in every model update. To address this issue, in the dynamic\nmulti-objective optimization problem, we introduce task-specific elastic\nfactors to adjust the descent direction towards the Pareto front. The proposed\nmethod, called Elastic Multi-Gradient Descent (EMGD), ensures that each update\nfollows an appropriate Pareto descent direction, minimizing any negative impact\non previously learned tasks. To balance the training between old and new tasks,\nwe also propose a memory editing mechanism guided by the gradient computed\nusing EMGD. This editing process updates the stored data points, reducing\ninterference in the Pareto descent direction from previous tasks. Experiments\non public datasets validate the effectiveness of our EMGD in the PCL setting.", "published": "2024-01-02", "categories": ["cs.LG", "cs.AI"], "links": "http://arxiv.org/abs/2401.01054v1"}
{"title": "PAC-Bayesian Domain Adaptation Bounds for Multi-view learning", "author": "Mehdi Hennequin, Khalid Benabdeslem, Haytham Elghazel", "abstract": "This paper presents a series of new results for domain adaptation in the\nmulti-view learning setting. The incorporation of multiple views in the domain\nadaptation was paid little attention in the previous studies. In this way, we\npropose an analysis of generalization bounds with Pac-Bayesian theory to\nconsolidate the two paradigms, which are currently treated separately. Firstly,\nbuilding on previous work by Germain et al., we adapt the distance between\ndistribution proposed by Germain et al. for domain adaptation with the concept\nof multi-view learning. Thus, we introduce a novel distance that is tailored\nfor the multi-view domain adaptation setting. Then, we give Pac-Bayesian bounds\nfor estimating the introduced divergence. Finally, we compare the different new\nbounds with the previous studies.", "published": "2024-01-02", "categories": ["cs.LG", "stat.ML"], "links": "http://arxiv.org/abs/2401.01048v1"}
{"title": "Sharp Analysis of Power Iteration for Tensor PCA", "author": "Yuchen Wu, Kangjie Zhou", "abstract": "We investigate the power iteration algorithm for the tensor PCA model\nintroduced in Richard and Montanari (2014). Previous work studying the\nproperties of tensor power iteration is either limited to a constant number of\niterations, or requires a non-trivial data-independent initialization. In this\npaper, we move beyond these limitations and analyze the dynamics of randomly\ninitialized tensor power iteration up to polynomially many steps. Our\ncontributions are threefold: First, we establish sharp bounds on the number of\niterations required for power method to converge to the planted signal, for a\nbroad range of the signal-to-noise ratios. Second, our analysis reveals that\nthe actual algorithmic threshold for power iteration is smaller than the one\nconjectured in literature by a polylog(n) factor, where n is the ambient\ndimension. Finally, we propose a simple and effective stopping criterion for\npower iteration, which provably outputs a solution that is highly correlated\nwith the true signal. Extensive numerical experiments verify our theoretical\nresults.", "published": "2024-01-02", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "links": "http://arxiv.org/abs/2401.01047v1"}
{"title": "CautionSuicide: A Deep Learning Based Approach for Detecting Suicidal Ideation in Real Time Chatbot Conversation", "author": "Nelly Elsayed, Zag ElSayed, Murat Ozer", "abstract": "Suicide is recognized as one of the most serious concerns in the modern\nsociety. Suicide causes tragedy that affects countries, communities, and\nfamilies. There are many factors that lead to suicidal ideations. Early\ndetection of suicidal ideations can help to prevent suicide occurrence by\nproviding the victim with the required professional support, especially when\nthe victim does not recognize the danger of having suicidal ideations. As\ntechnology usage has increased, people share and express their ideations\ndigitally via social media, chatbots, and other digital platforms. In this\npaper, we proposed a novel, simple deep learning-based model to detect suicidal\nideations in digital content, mainly focusing on chatbots as the primary data\nsource. In addition, we provide a framework that employs the proposed suicide\ndetection integration with a chatbot-based support system.", "published": "2024-01-02", "categories": ["cs.HC", "cs.LG"], "links": "http://arxiv.org/abs/2401.01023v1"}
{"title": "Boosting Transformer's Robustness and Efficacy in PPG Signal Artifact Detection with Self-Supervised Learning", "author": "Thanh-Dung Le", "abstract": "Recent research at CHU Sainte Justine's Pediatric Critical Care Unit (PICU)\nhas revealed that traditional machine learning methods, such as semi-supervised\nlabel propagation and K-nearest neighbors, outperform Transformer-based models\nin artifact detection from PPG signals, mainly when data is limited. This study\naddresses the underutilization of abundant unlabeled data by employing\nself-supervised learning (SSL) to extract latent features from these data,\nfollowed by fine-tuning on labeled data. Our experiments demonstrate that SSL\nsignificantly enhances the Transformer model's ability to learn\nrepresentations, improving its robustness in artifact classification tasks.\nAmong various SSL techniques, including masking, contrastive learning, and DINO\n(self-distillation with no labels)-contrastive learning exhibited the most\nstable and superior performance in small PPG datasets. Further, we delve into\noptimizing contrastive loss functions, which are crucial for contrastive SSL.\nInspired by InfoNCE, we introduce a novel contrastive loss function that\nfacilitates smoother training and better convergence, thereby enhancing\nperformance in artifact classification. In summary, this study establishes the\nefficacy of SSL in leveraging unlabeled data, particularly in enhancing the\ncapabilities of the Transformer model. This approach holds promise for broader\napplications in PICU environments, where annotated data is often limited.", "published": "2024-01-02", "categories": ["cs.LG", "eess.SP"], "links": "http://arxiv.org/abs/2401.01013v1"}
{"title": "Unsupervised Continual Anomaly Detection with Contrastively-learned Prompt", "author": "Jiaqi Liu, Kai Wu, Qiang Nie, Ying Chen, Bin-Bin Gao, Yong Liu, Jinbao Wang, Chengjie Wang, Feng Zheng", "abstract": "Unsupervised Anomaly Detection (UAD) with incremental training is crucial in\nindustrial manufacturing, as unpredictable defects make obtaining sufficient\nlabeled data infeasible. However, continual learning methods primarily rely on\nsupervised annotations, while the application in UAD is limited due to the\nabsence of supervision. Current UAD methods train separate models for different\nclasses sequentially, leading to catastrophic forgetting and a heavy\ncomputational burden. To address this issue, we introduce a novel Unsupervised\nContinual Anomaly Detection framework called UCAD, which equips the UAD with\ncontinual learning capability through contrastively-learned prompts. In the\nproposed UCAD, we design a Continual Prompting Module (CPM) by utilizing a\nconcise key-prompt-knowledge memory bank to guide task-invariant `anomaly'\nmodel predictions using task-specific `normal' knowledge. Moreover,\nStructure-based Contrastive Learning (SCL) is designed with the Segment\nAnything Model (SAM) to improve prompt learning and anomaly segmentation\nresults. Specifically, by treating SAM's masks as structure, we draw features\nwithin the same mask closer and push others apart for general feature\nrepresentations. We conduct comprehensive experiments and set the benchmark on\nunsupervised continual anomaly detection and segmentation, demonstrating that\nour method is significantly better than anomaly detection methods, even with\nrehearsal training. The code will be available at\nhttps://github.com/shirowalker/UCAD.", "published": "2024-01-02", "categories": ["cs.CV", "cs.LG"], "links": "http://arxiv.org/abs/2401.01010v1"}
{"title": "Shrinking Your TimeStep: Towards Low-Latency Neuromorphic Object Recognition with Spiking Neural Network", "author": "Yongqi Ding, Lin Zuo, Mengmeng Jing, Pei He, Yongjun Xiao", "abstract": "Neuromorphic object recognition with spiking neural networks (SNNs) is the\ncornerstone of low-power neuromorphic computing. However, existing SNNs suffer\nfrom significant latency, utilizing 10 to 40 timesteps or more, to recognize\nneuromorphic objects. At low latencies, the performance of existing SNNs is\ndrastically degraded. In this work, we propose the Shrinking SNN (SSNN) to\nachieve low-latency neuromorphic object recognition without reducing\nperformance. Concretely, we alleviate the temporal redundancy in SNNs by\ndividing SNNs into multiple stages with progressively shrinking timesteps,\nwhich significantly reduces the inference latency. During timestep shrinkage,\nthe temporal transformer smoothly transforms the temporal scale and preserves\nthe information maximally. Moreover, we add multiple early classifiers to the\nSNN during training to mitigate the mismatch between the surrogate gradient and\nthe true gradient, as well as the gradient vanishing/exploding, thus\neliminating the performance degradation at low latency. Extensive experiments\non neuromorphic datasets, CIFAR10-DVS, N-Caltech101, and DVS-Gesture have\nrevealed that SSNN is able to improve the baseline accuracy by 6.55% ~ 21.41%.\nWith only 5 average timesteps and without any data augmentation, SSNN is able\nto achieve an accuracy of 73.63% on CIFAR10-DVS. This work presents a\nheterogeneous temporal scale SNN and provides valuable insights into the\ndevelopment of high-performance, low-latency SNNs.", "published": "2024-01-02", "categories": ["cs.CV", "cs.LG", "eess.IV"], "links": "http://arxiv.org/abs/2401.01912v1"}
{"title": "Machine Learning Classification of Alzheimer's Disease Stages Using Cerebrospinal Fluid Biomarkers Alone", "author": "Vivek Kumar Tiwari, Premananda Indic, Shawana Tabassum", "abstract": "Early diagnosis of Alzheimer's disease is a challenge because the existing\nmethodologies do not identify the patients in their preclinical stage, which\ncan last up to a decade prior to the onset of clinical symptoms. Several\nresearch studies demonstrate the potential of cerebrospinal fluid biomarkers,\namyloid beta 1-42, T-tau, and P-tau, in early diagnosis of Alzheimer's disease\nstages. In this work, we used machine learning models to classify different\nstages of Alzheimer's disease based on the cerebrospinal fluid biomarker levels\nalone. An electronic health record of patients from the National Alzheimer's\nCoordinating Centre database was analyzed and the patients were subdivided\nbased on mini-mental state scores and clinical dementia ratings. Statistical\nand correlation analyses were performed to identify significant differences\nbetween the Alzheimer's stages. Afterward, machine learning classifiers\nincluding K-Nearest Neighbors, Ensemble Boosted Tree, Ensemble Bagged Tree,\nSupport Vector Machine, Logistic Regression, and Naive Bayes classifiers were\nemployed to classify the Alzheimer's disease stages. The results demonstrate\nthat Ensemble Boosted Tree (84.4%) and Logistic Regression (73.4%) provide the\nhighest accuracy for binary classification, while Ensemble Bagged Tree (75.4%)\ndemonstrates better accuracy for multiclassification. The findings from this\nresearch are expected to help clinicians in making an informed decision\nregarding the early diagnosis of Alzheimer's from the cerebrospinal fluid\nbiomarkers alone, monitoring of the disease progression, and implementation of\nappropriate intervention measures.", "published": "2024-01-02", "categories": ["cs.LG", "q-bio.QM", "stat.AP"], "links": "http://arxiv.org/abs/2401.00981v1"}
