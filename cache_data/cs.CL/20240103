{"title": "Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias", "author": "Anshuman Chhabra, Hadi Askari, Prasant Mohapatra", "abstract": "We characterize and study zero-shot abstractive summarization in Large\nLanguage Models (LLMs) by measuring position bias, which we propose as a\ngeneral formulation of the more restrictive lead bias phenomenon studied\npreviously in the literature. Position bias captures the tendency of a model\nunfairly prioritizing information from certain parts of the input text over\nothers, leading to undesirable behavior. Through numerous experiments on four\ndiverse real-world datasets, we study position bias in multiple LLM models such\nas GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained\nencoder-decoder abstractive summarization models such as Pegasus and BART. Our\nfindings lead to novel insights and discussion on performance and position bias\nof models for zero-shot summarization tasks.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01989v1"}
{"title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity", "author": "Andrew Lee, Xiaoyan Bai, Itamar Pres, Martin Wattenberg, Jonathan K. Kummerfeld, Rada Mihalcea", "abstract": "While alignment algorithms are now commonly used to tune pre-trained language\nmodels towards a user's preferences, we lack explanations for the underlying\nmechanisms in which models become ``aligned'', thus making it difficult to\nexplain phenomena like jailbreaks. In this work we study a popular algorithm,\ndirect preference optimization (DPO), and the mechanisms by which it reduces\ntoxicity. Namely, we first study how toxicity is represented and elicited in a\npre-trained language model, GPT2-medium. We then apply DPO with a carefully\ncrafted pairwise dataset to reduce toxicity. We examine how the resulting model\naverts toxic outputs, and find that capabilities learned from pre-training are\nnot removed, but rather bypassed. We use this insight to demonstrate a simple\nmethod to un-align the model, reverting it back to its toxic behavior.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01967v1"}
{"title": "Instruct-Imagen: Image Generation with Multi-modal Instruction", "author": "Hexiang Hu, Kelvin C. K. Chan, Yu-Chuan Su, Wenhu Chen, Yandong Li, Kihyuk Sohn, Yang Zhao, Xue Ben, Boqing Gong, William Cohen, Ming-Wei Chang, Xuhui Jia", "abstract": "This paper presents instruct-imagen, a model that tackles heterogeneous image\ngeneration tasks and generalizes across unseen tasks. We introduce *multi-modal\ninstruction* for image generation, a task representation articulating a range\nof generation intents with precision. It uses natural language to amalgamate\ndisparate modalities (e.g., text, edge, style, subject, etc.), such that\nabundant generation intents can be standardized in a uniform format.\n  We then build instruct-imagen by fine-tuning a pre-trained text-to-image\ndiffusion model with a two-stage framework. First, we adapt the model using the\nretrieval-augmented training, to enhance model's capabilities to ground its\ngeneration on external multimodal context. Subsequently, we fine-tune the\nadapted model on diverse image generation tasks that requires vision-language\nunderstanding (e.g., subject-driven generation, etc.), each paired with a\nmulti-modal instruction encapsulating the task's essence. Human evaluation on\nvarious image generation datasets reveals that instruct-imagen matches or\nsurpasses prior task-specific models in-domain and demonstrates promising\ngeneralization to unseen and more complex tasks.", "published": "2024-01-03", "categories": ["cs.CV", "cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01952v1"}
{"title": "Generalist embedding models are better at short-context clinical semantic search than specialized embedding models", "author": "Jean-Baptiste Excoffier, Tom Roehr, Alexei Figueroa, Michalis Papaaioannou, Keno Bressem, Matthieu Ortala", "abstract": "The increasing use of tools and solutions based on Large Language Models\n(LLMs) for various tasks in the medical domain has become a prominent trend.\nTheir use in this highly critical and sensitive domain has thus raised\nimportant questions about their robustness, especially in response to\nvariations in input, and the reliability of the generated outputs. This study\naddresses these questions by constructing a textual dataset based on the\nICD-10-CM code descriptions, widely used in US hospitals and containing many\nclinical terms, and their easily reproducible rephrasing. We then benchmarked\nexisting embedding models, either generalist or specialized in the clinical\ndomain, in a semantic search task where the goal was to correctly match the\nrephrased text to the original description. Our results showed that generalist\nmodels performed better than clinical models, suggesting that existing clinical\nspecialized models are more sensitive to small changes in input that confuse\nthem. The highlighted problem of specialized models may be due to the fact that\nthey have not been trained on sufficient data, and in particular on datasets\nthat are not diverse enough to have a reliable global language understanding,\nwhich is still necessary for accurate handling of medical documents.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01943v1"}
{"title": "Theoretical guarantees on the best-of-n alignment policy", "author": "Ahmad Beirami, Alekh Agarwal, Jonathan Berant, Alexander D'Amour, Jacob Eisenstein, Chirag Nagpal, Ananda Theertha Suresh", "abstract": "A simple and effective method for the alignment of generative models is the\nbest-of-$n$ policy, where $n$ samples are drawn from a base policy, and ranked\nbased on a reward function, and the highest ranking one is selected. A commonly\nused analytical expression in the literature claims that the KL divergence\nbetween the best-of-$n$ policy and the base policy is equal to $\\log (n) -\n(n-1)/n.$ We disprove the validity of this claim, and show that it is an upper\nbound on the actual KL divergence. We also explore the tightness of this upper\nbound in different regimes. Finally, we propose a new estimator for the KL\ndivergence and empirically show that it provides a tight approximation through\na few examples.", "published": "2024-01-03", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "links": "http://arxiv.org/abs/2401.01879v1"}
{"title": "A Vision Check-up for Language Models", "author": "Pratyusha Sharma, Tamar Rott Shaham, Manel Baradad, Stephanie Fu, Adrian Rodriguez-Munoz, Shivam Duggal, Phillip Isola, Antonio Torralba", "abstract": "What does learning to model relationships between strings teach large\nlanguage models (LLMs) about the visual world? We systematically evaluate LLMs'\nabilities to generate and recognize an assortment of visual concepts of\nincreasing complexity and then demonstrate how a preliminary visual\nrepresentation learning system can be trained using models of text. As language\nmodels lack the ability to consume or output visual information as pixels, we\nuse code to represent images in our study. Although LLM-generated images do not\nlook like natural images, results on image generation and the ability of models\nto correct these generated images indicate that precise modeling of strings can\nteach language models about numerous aspects of the visual world. Furthermore,\nexperiments on self-supervised visual representation learning, utilizing images\ngenerated with text models, highlight the potential to train vision models\ncapable of making semantic assessments of natural images using just LLMs.", "published": "2024-01-03", "categories": ["cs.CV", "cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.01862v1"}
{"title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality", "author": "Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, Matan Eyal", "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. One promising approach is cross-lingual transfer, where a model\nacquires specific functionality on some language by finetuning on another\nlanguage. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages. We\nfirst show that many languages transfer some instruction-following capabilities\nto other languages from even monolingual tuning. Furthermore, we find that only\n40 multilingual examples in an English tuning set substantially improve\nmultilingual instruction-following, both in seen and unseen languages during\ntuning. In general, we observe that models tuned on multilingual mixtures\nexhibit comparable or superior performance in several languages compared to\nmonolingually tuned models, despite training on 10x fewer examples in those\nlanguages. Finally, we find that increasing the number of languages in the\ninstruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual\ngeneralization. Our results suggest that building massively multilingual\ninstruction-tuned models can be done with only a very small set of multilingual\ninstruction-responses.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01854v1"}
{"title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets", "author": "Himmet Toprak Kesgin, Mehmet Fatih Amasyali", "abstract": "Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01843v1"}
{"title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling", "author": "Himmet Toprak Kesgin, Mehmet Fatih Amasyali", "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.LG"], "links": "http://arxiv.org/abs/2401.01830v1"}
{"title": "Physio: An LLM-Based Physiotherapy Advisor", "author": "Rúben Almeida, Hugo Sousa, Luís F. Cunha, Nuno Guimarães, Ricardo Campos, Alípio Jorge", "abstract": "The capabilities of the most recent language models have increased the\ninterest in integrating them into real-world applications. However, the fact\nthat these models generate plausible, yet incorrect text poses a constraint\nwhen considering their use in several domains. Healthcare is a prime example of\na domain where text-generative trustworthiness is a hard requirement to\nsafeguard patient well-being. In this paper, we present Physio, a chat-based\napplication for physical rehabilitation. Physio is capable of making an initial\ndiagnosis while citing reliable health sources to support the information\nprovided. Furthermore, drawing upon external knowledge databases, Physio can\nrecommend rehabilitation exercises and over-the-counter medication for symptom\nrelief. By combining these features, Physio can leverage the power of\ngenerative models for language processing while also conditioning its response\non dependable and verifiable sources. A live demo of Physio is available at\nhttps://physio.inesctec.pt.", "published": "2024-01-03", "categories": ["cs.CL", "cs.IR", "68T07", "I.2; J.3"], "links": "http://arxiv.org/abs/2401.01825v1"}
{"title": "Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering", "author": "Pierre Erbacher, Louis Falissar, Vincent Guigue, Laure Soulier", "abstract": "While Large Language Models (LLM) are able to accumulate and restore\nknowledge, they are still prone to hallucination. Especially when faced with\nfactual questions, LLM cannot only rely on knowledge stored in parameters to\nguarantee truthful and correct answers. Augmenting these models with the\nability to search on external information sources, such as the web, is a\npromising approach to ground knowledge to retrieve information. However,\nsearching in a large collection of documents introduces additional\ncomputational/time costs. An optimal behavior would be to query external\nresources only when the LLM is not confident about answers. In this paper, we\npropose a new LLM able to self-estimate if it is able to answer directly or\nneeds to request an external tool. We investigate a supervised approach by\nintroducing a hallucination masking mechanism in which labels are generated\nusing a close book question-answering task. In addition, we propose to leverage\nparameter-efficient fine-tuning techniques to train our model on a small amount\nof data. Our model directly provides answers for $78.2\\%$ of the known queries\nand opts to search for $77.2\\%$ of the unknown ones. This results in the API\nbeing utilized only $62\\%$ of the time.", "published": "2024-01-03", "categories": ["cs.CL", "cs.IR"], "links": "http://arxiv.org/abs/2401.01780v1"}
{"title": "Cross-target Stance Detection by Exploiting Target Analytical Perspectives", "author": "Daijun Ding, Rong Chen, Liwen Jing, Bowen Zhang, Xu Huang, Li Dong, Xiaowen Zhao, Ge Song", "abstract": "Cross-target stance detection (CTSD) is an important task, which infers the\nattitude of the destination target by utilizing annotated data derived from the\nsource target. One important approach in CTSD is to extract domain-invariant\nfeatures to bridge the knowledge gap between multiple targets. However, the\nanalysis of informal and short text structure, and implicit expressions,\ncomplicate the extraction of domain-invariant knowledge. In this paper, we\npropose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the\nanalysis perspective as a bridge to transfer knowledge. First, we develop a\ntwo-stage instruct-based chain-of-thought method (TsCoT) to elicit target\nanalysis perspectives and provide natural language explanations (NLEs) from\nmultiple viewpoints by formulating instructions based on large language model\n(LLM). Second, we propose a multi-perspective prompt-tuning framework\n(MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments\nresults demonstrate the superiority of MPPT against the state-of-the-art\nbaseline methods.", "published": "2024-01-03", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.01761v2"}
{"title": "VGA: Vision and Graph Fused Attention Network for Rumor Detection", "author": "Lin Bai, Caiyan Jia, Ziying Song, Chaoqun Cui", "abstract": "With the development of social media, rumors have been spread broadly on\nsocial media platforms, causing great harm to society. Beside textual\ninformation, many rumors also use manipulated images or conceal textual\ninformation within images to deceive people and avoid being detected, making\nmultimodal rumor detection be a critical problem. The majority of multimodal\nrumor detection methods mainly concentrate on extracting features of source\nclaims and their corresponding images, while ignoring the comments of rumors\nand their propagation structures. These comments and structures imply the\nwisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these\nmethods usually only extract visual features in a basic manner, seldom consider\ntampering or textual information in images. Therefore, in this study, we\npropose a novel Vision and Graph Fused Attention Network (VGA) for rumor\ndetection to utilize propagation structures among posts so as to obtain the\ncrowd opinions and further explore visual tampering features, as well as the\ntextual information hidden in images. We conduct extensive experiments on three\ndatasets, demonstrating that VGA can effectively detect multimodal rumors and\noutperform state-of-the-art methods significantly.", "published": "2024-01-03", "categories": ["cs.SI", "cs.CL", "cs.CV", "cs.MM"], "links": "http://arxiv.org/abs/2401.01759v1"}
{"title": "Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs", "author": "Phillip Schneider, Manuel Klettner, Kristiina Jokinen, Elena Simperl, Florian Matthes", "abstract": "Conversational question answering systems often rely on semantic parsing to\nenable interactive information retrieval, which involves the generation of\nstructured database queries from a natural language input. For\ninformation-seeking conversations about facts stored within a knowledge graph,\ndialogue utterances are transformed into graph queries in a process that is\ncalled knowledge-based conversational question answering. This paper evaluates\nthe performance of large language models that have not been explicitly\npre-trained on this task. Through a series of experiments on an extensive\nbenchmark dataset, we compare models of varying sizes with different prompting\ntechniques and identify common issue types in the generated output. Our results\ndemonstrate that large language models are capable of generating graph queries\nfrom dialogues, with significant improvements achievable through few-shot\nprompting and fine-tuning techniques, especially for smaller models that\nexhibit lower zero-shot performance.", "published": "2024-01-03", "categories": ["cs.CL", "cs.IR"], "links": "http://arxiv.org/abs/2401.01711v1"}
{"title": "WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope", "author": "Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Wangmeng Xiang, Yusen Hu, Xianhui Lin, Xiaoyang Kang, Zengke Jin, Bin Luo, Yifeng Geng, Xuansong Xie, Jingren Zhou", "abstract": "This paper introduces the WordArt Designer API, a novel framework for\nuser-driven artistic typography synthesis utilizing Large Language Models\n(LLMs) on ModelScope. We address the challenge of simplifying artistic\ntypography for non-professionals by offering a dynamic, adaptive, and\ncomputationally efficient alternative to traditional rigid templates. Our\napproach leverages the power of LLMs to understand and interpret user input,\nfacilitating a more intuitive design process. We demonstrate through various\ncase studies how users can articulate their aesthetic preferences and\nfunctional requirements, which the system then translates into unique and\ncreative typographic designs. Our evaluations indicate significant improvements\nin user satisfaction, design flexibility, and creative expression over existing\nsystems. The WordArt Designer API not only democratizes the art of typography\nbut also opens up new possibilities for personalized digital communication and\ndesign.", "published": "2024-01-03", "categories": ["cs.CV", "cs.CL", "cs.MM"], "links": "http://arxiv.org/abs/2401.01699v1"}
{"title": "Patterns of Persistence and Diffusibility across World's Languages", "author": "Yiyi Chen, Johannes Bjerva", "abstract": "Language similarities can be caused by genetic relatedness, areal contact,\nuniversality, or chance. Colexification, i.e.~a type of similarity where a\nsingle lexical form is used to convey multiple meanings, is underexplored. In\nour work, we shed light on the linguistic causes of cross-lingual similarity in\ncolexification and phonology, by exploring genealogical stability (persistence)\nand contact-induced change (diffusibility). We construct large-scale graphs\nincorporating semantic, genealogical, phonological and geographical data for\n1,966 languages. We then show the potential of this resource, by investigating\nseveral established hypotheses from previous work in linguistics, while\nproposing new ones. Our results strongly support a previously established\nhypothesis in the linguistic literature, while offering contradicting evidence\nto another. Our large scale resource opens for further research across\ndisciplines, e.g.~in multilingual NLP and comparative linguistics.", "published": "2024-01-03", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.01698v1"}
{"title": "Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches", "author": "Wannapon Suraworachet, Jennifer Seon, Mutlu Cukurova", "abstract": "Effective collaboration requires groups to strategically regulate themselves\nto overcome challenges. Research has shown that groups may fail to regulate due\nto differences in members' perceptions of challenges which may benefit from\nexternal support. In this study, we investigated the potential of leveraging\nthree distinct natural language processing models: an expert knowledge\nrule-based model, a supervised machine learning (ML) model and a Large Language\nmodel (LLM), in challenge detection and challenge dimension identification\n(cognitive, metacognitive, emotional and technical/other challenges) from\nstudent discourse, was investigated. The results show that the supervised ML\nand the LLM approaches performed considerably well in both tasks, in contrast\nto the rule-based approach, whose efficacy heavily relies on the engineered\nfeatures by experts. The paper provides an extensive discussion of the three\napproaches' performance for automated detection and support of students'\nchallenge moments in collaborative learning activities. It argues that,\nalthough LLMs provide many advantages, they are unlikely to be the panacea to\nissues of the detection and feedback provision of socially shared regulation of\nlearning due to their lack of reliability, as well as issues of validity\nevaluation, privacy and confabulation. We conclude the paper with a discussion\non additional considerations, including model transparency to explore feasible\nand meaningful analytical feedback for students and educators using LLMs.", "published": "2024-01-03", "categories": ["cs.CL", "cs.CY"], "links": "http://arxiv.org/abs/2401.01692v1"}
{"title": "MLPs Compass: What is learned when MLPs are combined with PLMs?", "author": "Li Zhou, Wenyu Chen, Yong Cao, Dingyi Zeng, Wanlong Liu, Hong Qu", "abstract": "While Transformer-based pre-trained language models and their variants\nexhibit strong semantic representation capabilities, the question of\ncomprehending the information gain derived from the additional components of\nPLMs remains an open question in this field. Motivated by recent efforts that\nprove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture\ncapabilities, even outperforming Graph Neural Networks (GNNs), this paper aims\nto quantify whether simple MLPs can further enhance the already potent ability\nof PLMs to capture linguistic information. Specifically, we design a simple yet\neffective probing framework containing MLPs components based on BERT structure\nand conduct extensive experiments encompassing 10 probing tasks spanning three\ndistinct linguistic levels. The experimental results demonstrate that MLPs can\nindeed enhance the comprehension of linguistic structure by PLMs. Our research\nprovides interpretable and valuable insights into crafting variations of PLMs\nutilizing MLPs for tasks that emphasize diverse linguistic structures.", "published": "2024-01-03", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.01667v1"}
{"title": "Social Media Ready Caption Generation for Brands", "author": "Himanshu Maheshwari, Koustava Goswami, Apoorv Saxena, Balaji Vasan Srinivasan", "abstract": "Social media advertisements are key for brand marketing, aiming to attract\nconsumers with captivating captions and pictures or logos. While previous\nresearch has focused on generating captions for general images, incorporating\nbrand personalities into social media captioning remains unexplored. Brand\npersonalities are shown to be affecting consumers' behaviours and social\ninteractions and thus are proven to be a key aspect of marketing strategies.\nCurrent open-source multimodal LLMs are not directly suited for this task.\nHence, we propose a pipeline solution to assist brands in creating engaging\nsocial media captions that align with the image and the brand personalities.\nOur architecture is based on two parts: a the first part contains an image\ncaptioning model that takes in an image that the brand wants to post online and\ngives a plain English caption; b the second part takes in the generated caption\nalong with the target brand personality and outputs a catchy\npersonality-aligned social media caption. Along with brand personality, our\nsystem also gives users the flexibility to provide hashtags, Instagram handles,\nURLs, and named entities they want the caption to contain, making the captions\nmore semantically related to the social media handles. Comparative evaluations\nagainst various baselines demonstrate the effectiveness of our approach, both\nqualitatively and quantitatively.", "published": "2024-01-03", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.01637v1"}
{"title": "Can AI Be as Creative as Humans?", "author": "Haonan Wang, James Zou, Michael Mozer, Linjun Zhang, Anirudh Goyal, Alex Lamb, Zhun Deng, Michael Qizhe Xie, Hannah Brown, Kenji Kawaguchi", "abstract": "Creativity serves as a cornerstone for societal progress and innovation, but\nits assessment remains a complex and often subjective endeavor. With the rise\nof advanced generative AI models capable of tasks once reserved for human\ncreativity, the study of AI's creative potential becomes imperative for its\nresponsible development and application. This paper addresses the complexities\nin defining and evaluating creativity by introducing a new concept called\nRelative Creativity. Instead of trying to define creativity universally, we\nshift the focus to whether AI can match the creative abilities of a\nhypothetical human. This perspective draws inspiration from the Turing Test,\nexpanding upon it to address the challenges and subjectivities inherent in\nevaluating creativity. This methodological shift facilitates a statistically\nquantifiable evaluation of AI's creativity, which we term Statistical\nCreativity. This approach allows for direct comparisons of AI's creative\nabilities with those of specific human groups. Building on this foundation, we\ndiscuss the application of statistical creativity in contemporary\nprompt-conditioned autoregressive models. In addition to defining and analyzing\na measure of creativity, we introduce an actionable training guideline,\neffectively bridging the gap between theoretical quantification of creativity\nand practical model training. Through these multifaceted contributions, the\npaper establishes a cohesive, continuously evolving, and transformative\nframework for assessing and fostering statistical creativity in AI models.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01623v1"}
{"title": "Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication", "author": "Philip Chung, Christine T Fong, Andrew M Walters, Nima Aghaeepour, Meliha Yetisgen, Vikas N O'Reilly-Shah", "abstract": "We investigate whether general-domain large language models such as GPT-4\nTurbo can perform risk stratification and predict post-operative outcome\nmeasures using a description of the procedure and a patient's clinical notes\nderived from the electronic health record. We examine predictive performance on\n8 different tasks: prediction of ASA Physical Status Classification, hospital\nadmission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1\nduration, hospital duration, and ICU duration. Few-shot and chain-of-thought\nprompting improves predictive performance for several of the tasks. We achieve\nF1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU\nadmission, and 0.86 for hospital mortality. Performance on duration prediction\ntasks were universally poor across all prompt strategies. Current generation\nlarge language models can assist clinicians in perioperative risk\nstratification on classification tasks and produce high-quality natural\nlanguage summaries and explanations.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01620v1"}
{"title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded", "author": "Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, Yu Su", "abstract": "The recent development on large multimodal models (LMMs), especially\nGPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries\nof multimodal models beyond traditional tasks like image captioning and visual\nquestion answering. In this work, we explore the potential of LMMs like GPT-4V\nas a generalist web agent that can follow natural language instructions to\ncomplete tasks on any given website. We propose SEEACT, a generalist web agent\nthat harnesses the power of LMMs for integrated visual understanding and acting\non the web. We evaluate on the recent MIND2WEB benchmark. In addition to\nstandard offline evaluation on cached websites, we enable a new online\nevaluation setting by developing a tool that allows running web agents on live\nwebsites. We show that GPT-4V presents a great potential for web agents - it\ncan successfully complete 50% of the tasks on live websites if we manually\nground its textual plans into actions on the websites. This substantially\noutperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)\nspecifically fine-tuned for web agents. However, grounding still remains a\nmajor challenge. Existing LMM grounding strategies like set-of-mark prompting\nturns out not effective for web agents, and the best grounding strategy we\ndevelop in this paper leverages both the HTML text and visuals. Yet, there is\nstill a substantial gap with oracle grounding, leaving ample room for further\nimprovement.", "published": "2024-01-03", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "links": "http://arxiv.org/abs/2401.01614v1"}
{"title": "PLLaMa: An Open-source Large Language Model for Plant Science", "author": "Xianjun Yang, Junfeng Gao, Wenxin Xue, Erik Alexandersson", "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "links": "http://arxiv.org/abs/2401.01600v1"}
{"title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries", "author": "Akash Ghosh, Arkadeep Acharya, Prince Jha, Aniket Gaudgaul, Rajdeep Majumdar, Sriparna Saha, Aman Chadha, Raghav Jain, Setu Sinha, Shivani Agarwal", "abstract": "In the healthcare domain, summarizing medical questions posed by patients is\ncritical for improving doctor-patient interactions and medical decision-making.\nAlthough medical data has grown in complexity and quantity, the current body of\nresearch in this domain has primarily concentrated on text-based methods,\noverlooking the integration of visual cues. Also prior works in the area of\nmedical question summarisation have been limited to the English language. This\nwork introduces the task of multimodal medical question summarization for\ncodemixed input in a low-resource setting. To address this gap, we introduce\nthe Multimodal Medical Codemixed Question Summarization MMCQS dataset, which\ncombines Hindi-English codemixed medical queries with visual aids. This\nintegration enriches the representation of a patient's medical condition,\nproviding a more comprehensive perspective. We also propose a framework named\nMedSumm that leverages the power of LLMs and VLMs for this task. By utilizing\nour MMCQS dataset, we demonstrate the value of integrating visual information\nfrom images to improve the creation of medically detailed summaries. This\nmultimodal strategy not only improves healthcare decision-making but also\npromotes a deeper comprehension of patient queries, paving the way for future\nexploration in personalized and responsive medical care. Our dataset, code, and\npre-trained models will be made publicly available.", "published": "2024-01-03", "categories": ["cs.AI", "cs.CL"], "links": "http://arxiv.org/abs/2401.01596v1"}
{"title": "Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models", "author": "Rita Frieske, Bertram E. Shi", "abstract": "Hallucinations are a type of output error produced by deep neural networks.\nWhile this has been studied in natural language processing, they have not been\nresearched previously in automatic speech recognition. Here, we define\nhallucinations in ASR as transcriptions generated by a model that are\nsemantically unrelated to the source utterance, yet still fluent and coherent.\nThe similarity of hallucinations to probable natural language outputs of the\nmodel creates a danger of deception and impacts the credibility of the system.\nWe show that commonly used metrics, such as word error rates, cannot\ndifferentiate between hallucinatory and non-hallucinatory models. To address\nthis, we propose a perturbation-based method for assessing the susceptibility\nof an automatic speech recognition (ASR) model to hallucination at test time,\nwhich does not require access to the training dataset. We demonstrate that this\nmethod helps to distinguish between hallucinatory and non-hallucinatory models\nthat have similar baseline word error rates. We further explore the\nrelationship between the types of ASR errors and the types of dataset noise to\ndetermine what types of noise are most likely to create hallucinatory outputs.\nWe devise a framework for identifying hallucinations by analysing their\nsemantic connection with the ground truth and their fluency. Finally, we\ndiscover how to induce hallucinations with a random noise injection to the\nutterance.", "published": "2024-01-03", "categories": ["cs.CL", "cs.SD", "eess.AS"], "links": "http://arxiv.org/abs/2401.01572v1"}
{"title": "AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets", "author": "Ernest Perkowski, Rui Pan, Tuan Dung Nguyen, Yuan-Sen Ting, Sandor Kruk, Tong Zhang, Charlie O'Neill, Maja Jablonska, Michael J. Smith, Kevin Schawinski, Kartheik Iyer, Ioana Ciucă for UniverseTBD", "abstract": "We explore the potential of enhancing LLM performance in astronomy-focused\nquestion-answering through targeted, continual pre-training. By employing a\ncompact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of\nastronomy corpus -- comprising abstracts, introductions, and conclusions -- we\nachieve notable improvements in specialized topic comprehension. While general\nLLMs like GPT-4 outperform in broader question-answering scenarios due to\nsuperior reasoning capabilities, our findings suggest that continual\npre-training with limited resources can still enhance model performance on\nspecialized topics. Additionally, we present an extension of AstroLLaMA: the\nfine-tuning of the 7B LLaMA model on a domain-specific conversational dataset,\nculminating in the release of the chat-enabled AstroLLaMA for community use.\nComprehensive quantitative benchmarking is currently in progress and will be\ndetailed in an upcoming full paper. The model, AstroLLaMA-Chat, is now\navailable at https://huggingface.co/universeTBD, providing the first\nopen-source conversational AI tool tailored for the astronomy community.", "published": "2024-01-03", "categories": ["astro-ph.IM", "astro-ph.CO", "astro-ph.GA", "astro-ph.SR", "cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.01916v1"}
{"title": "GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse", "author": "Hongzhan Lin, Ziyang Luo, Bo Wang, Ruichao Yang, Jing Ma", "abstract": "The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and imagery. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01523v1"}
{"title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction", "author": "Minchan Kim, Myeonghun Jeong, Byoung Jin Choi, Semin Kim, Joun Yeop Lee, Nam Soo Kim", "abstract": "We propose a novel text-to-speech (TTS) framework centered around a neural\ntransducer. Our approach divides the whole TTS pipeline into semantic-level\nsequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling\nstages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings.\nFor a robust and efficient alignment modeling, we employ a neural transducer\nnamed token transducer for the semantic token prediction, benefiting from its\nhard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR)\nspeech generator efficiently synthesizes waveforms from these semantic tokens.\nAdditionally, a reference speech controls temporal dynamics and acoustic\nconditions at each stage. This decoupled framework reduces the training\ncomplexity of TTS while allowing each stage to focus on semantic and acoustic\nmodeling. Our experimental results on zero-shot adaptive TTS demonstrate that\nour model surpasses the baseline in terms of speech quality and speaker\nsimilarity, both objectively and subjectively. We also delve into the inference\nspeed and prosody control capabilities of our approach, highlighting the\npotential of neural transducers in TTS frameworks.", "published": "2024-01-03", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.01498v1"}
{"title": "A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning", "author": "Wei Ai, FuChen Zhang, Tao Meng, YunTao Shou, HongEn Shao, Keqin Li", "abstract": "In terms of human-computer interaction, it is becoming more and more\nimportant to correctly understand the user's emotional state in a conversation,\nso the task of multimodal emotion recognition (MER) started to receive more\nattention. However, existing emotion classification methods usually perform\nclassification only once. Sentences are likely to be misclassified in a single\nround of classification. Previous work usually ignores the similarities and\ndifferences between different morphological features in the fusion process. To\naddress the above issues, we propose a two-stage emotion recognition model\nbased on graph contrastive learning (TS-GCL). First, we encode the original\ndataset with different preprocessing modalities. Second, a graph contrastive\nlearning (GCL) strategy is introduced for these three modal data with other\nstructures to learn similarities and differences within and between modalities.\nFinally, we use MLP twice to achieve the final emotion classification. This\nstaged classification method can help the model to better focus on different\nlevels of emotional information, thereby improving the performance of the\nmodel. Extensive experiments show that TS-GCL has superior performance on\nIEMOCAP and MELD datasets compared with previous methods.", "published": "2024-01-03", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.01495v1"}
{"title": "Natural Language Processing and Multimodal Stock Price Prediction", "author": "Kevin Taylor, Jerry Ng", "abstract": "In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.", "published": "2024-01-03", "categories": ["cs.LG", "cs.CL"], "links": "http://arxiv.org/abs/2401.01487v1"}
{"title": "A First Look at Information Highlighting in Stack Overflow Answers", "author": "Shahla Shaan Ahmed, Shaowei Wang, Yuan Tian, Tse-Hsun, Chen, Haoxiang Zhang", "abstract": "Context: Navigating the knowledge of Stack Overflow (SO) remains challenging.\nTo make the posts vivid to users, SO allows users to write and edit posts with\nMarkdown or HTML so that users can leverage various formatting styles (e.g.,\nbold, italic, and code) to highlight the important information. Nonetheless,\nthere have been limited studies on the highlighted information. Objective: We\ncarried out the first large-scale exploratory study on the information\nhighlighted in SO answers in our recent study. To extend our previous study, we\ndevelop approaches to automatically recommend highlighted content with\nformatting styles using neural network architectures initially designed for the\nNamed Entity Recognition task. Method: In this paper, we studied 31,169,429\nanswers of Stack Overflow. For training recommendation models, we choose CNN\nand BERT models for each type of formatting (i.e., Bold, Italic, Code, and\nHeading) using the information highlighting dataset we collected from SO\nanswers. Results: Our models based on CNN architecture achieve precision\nranging from 0.71 to 0.82. The trained model for automatic code content\nhighlighting achieves a recall of 0.73 and an F1 score of 0.71, outperforming\nthe trained models for other formatting styles. The BERT models have even lower\nrecalls and F1 scores than the CNN models. Our analysis of failure cases\nindicates that the majority of the failure cases are missing identification\n(i.e., the model misses the content that is supposed to be highlighted) due to\nthe models tend to learn the frequently highlighted words while struggling to\nlearn less frequent words. Conclusion: Our findings suggest that it is possible\nto develop recommendation models for highlighting information for answers with\ndifferent formatting styles on Stack Overflow.", "published": "2024-01-03", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SE"], "links": "http://arxiv.org/abs/2401.01472v1"}
{"title": "Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation", "author": "Walid Saba, Suzanne Wendelken, James. Shanahan", "abstract": "Summarization of electronic health records (EHRs) can substantially minimize\n'screen time' for both patients as well as medical personnel. In recent years\nsummarization of EHRs have employed machine learning pipelines using state of\nthe art neural models. However, these models have produced less than adequate\nresults that are attributed to the difficulty of obtaining sufficient annotated\ndata for training. Moreover, the requirement to consider the entire content of\nan EHR in summarization has resulted in poor performance due to the fact that\nattention mechanisms in modern large language models (LLMs) adds a quadratic\ncomplexity in terms of the size of the input. We propose here a method that\nmitigates these shortcomings by combining semantic search, retrieval augmented\ngeneration (RAG) and question-answering using the latest LLMs. In our approach\nsummarization is the extraction of answers to specific questions that are\ndeemed important by subject-matter experts (SMEs). Our approach is quite\nefficient; requires minimal to no training; does not suffer from the\n'hallucination' problem of LLMs; and it ensures diversity, since the summary\nwill not have repeated content but diverse answers to specific questions.", "published": "2024-01-03", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.01469v1"}
