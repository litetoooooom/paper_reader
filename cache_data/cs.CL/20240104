{"title": "Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic Speech Recognition", "author": "David M. Chan, Shalini Ghosh, Hitesh Tulsiani, Ariya Rastrow, Björn Hoffmeister", "abstract": "While word error rates of automatic speech recognition (ASR) systems have\nconsistently fallen, natural language understanding (NLU) applications built on\ntop of ASR systems still attribute significant numbers of failures to\nlow-quality speech recognition results. Existing assistant systems collect\nlarge numbers of these unsuccessful interactions, but these systems usually\nfail to learn from these interactions, even in an offline fashion. In this\nwork, we introduce CLC: Contrastive Learning for Conversations, a family of\nmethods for contrastive fine-tuning of models in a self-supervised fashion,\nmaking use of easily detectable artifacts in unsuccessful conversations with\nassistants. We demonstrate that our CLC family of approaches can improve the\nperformance of ASR models on OD3, a new public large-scale semi-synthetic\nmeta-dataset of audio task-oriented dialogues, by up to 19.2%. These gains\ntransfer to real-world systems as well, where we show that CLC can help to\nimprove performance by up to 6.7% over baselines. We make OD3 publicly\navailable at https://github.com/amazon-science/amazon-od3 .", "published": "2024-01-04", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "links": "http://arxiv.org/abs/2401.02417v1"}
{"title": "LLaMA Pro: Progressive LLaMA with Block Expansion", "author": "Chengyue Wu, Yukang Gan, Yixiao Ge, Zeyu Lu, Jiahao Wang, Ye Feng, Ping Luo, Ying Shan", "abstract": "Humans generally acquire new skills without compromising the old; however,\nthe opposite holds for Large Language Models (LLMs), e.g., from LLaMA to\nCodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with\nan expansion of Transformer blocks. We tune the expanded blocks using only new\ncorpus, efficiently and effectively improving the model's knowledge without\ncatastrophic forgetting. In this paper, we experiment on the corpus of code and\nmath, yielding LLaMA Pro-8.3B, a versatile foundation model initialized from\nLLaMA2-7B, excelling in general tasks, programming, and mathematics. LLaMA Pro\nand its instruction-following counterpart (LLaMA Pro-Instruct) achieve advanced\nperformance among various benchmarks, demonstrating superiority over existing\nopen models in the LLaMA family and the immense potential of reasoning and\naddressing diverse tasks as an intelligent agent. Our findings provide valuable\ninsights into integrating natural and programming languages, laying a solid\nfoundation for developing advanced language agents that operate effectively in\nvarious environments.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02415v1"}
{"title": "LLM Augmented LLMs: Expanding Capabilities through Composition", "author": "Rachit Bansal, Bidisha Samanta, Siddharth Dalmia, Nitish Gupta, Shikhar Vashishth, Sriram Ganapathy, Abhishek Bapna, Prateek Jain, Partha Talukdar", "abstract": "Foundational models with billions of parameters which have been trained on\nlarge corpora of data have demonstrated non-trivial skills in a variety of\ndomains. However, due to their monolithic structure, it is challenging and\nexpensive to augment them or impart new skills. On the other hand, due to their\nadaptation abilities, several new instances of these models are being trained\ntowards new domains and tasks. In this work, we study the problem of efficient\nand practical composition of existing foundation models with more specific\nmodels to enable newer capabilities. To this end, we propose CALM --\nComposition to Augment Language Models -- which introduces cross-attention\nbetween models to compose their representations and enable new capabilities.\nSalient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'\nexisting LLMs along with a few additional parameters and data, (ii) Existing\nmodel weights are kept intact, and hence preserves existing capabilities, and\n(iii) Applies to diverse domains and settings. We illustrate that augmenting\nPaLM2-S with a smaller model trained on low-resource languages results in an\nabsolute improvement of up to 13\\% on tasks like translation into English and\narithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is\naugmented with a code-specific model, we see a relative improvement of 40\\%\nover the base model for code generation and explanation tasks -- on-par with\nfully fine-tuned counterparts.", "published": "2024-01-04", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "links": "http://arxiv.org/abs/2401.02412v1"}
{"title": "TinyLlama: An Open-Source Small Language Model", "author": "Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, Wei Lu", "abstract": "We present TinyLlama, a compact 1.1B language model pretrained on around 1\ntrillion tokens for approximately 3 epochs. Building on the architecture and\ntokenizer of Llama 2, TinyLlama leverages various advances contributed by the\nopen-source community (e.g., FlashAttention), achieving better computational\nefficiency. Despite its relatively small size, TinyLlama demonstrates\nremarkable performance in a series of downstream tasks. It significantly\noutperforms existing open-source language models with comparable sizes. Our\nmodel checkpoints and code are publicly available on GitHub at\nhttps://github.com/jzhang38/TinyLlama.", "published": "2024-01-04", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.02385v1"}
{"title": "SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval", "author": "Griffin Adams, Jason Zucker, Noémie Elhadad", "abstract": "Clinician must write a lengthy summary each time a patient is discharged from\nthe hospital. This task is time-consuming due to the sheer number of unique\nclinical concepts covered in the admission. Identifying and covering salient\nentities is vital for the summary to be clinically useful. We fine-tune\nopen-source LLMs (Mistral-7B-Instruct and Zephyr-7B-\\b{eta}) on the task and\nfind that they generate incomplete and unfaithful summaries. To increase entity\ncoverage, we train a smaller, encoder-only model to predict salient entities,\nwhich are treated as content-plans to guide the LLM. To encourage the LLM to\nfocus on specific mentions in the source notes, we propose SPEER:\nSentence-level Planning via Embedded Entity Retrieval. Specifically, we mark\neach salient entity span with special \"{{ }}\" boundary tags and instruct the\nLLM to retrieve marked spans before generating each sentence. Sentence-level\nplanning acts as a form of state tracking in that the model is explicitly\nrecording the entities it uses. We fine-tune Mistral and Zephyr variants on a\nlarge-scale, diverse dataset of ~167k in-patient hospital admissions and\nevaluate on 3 datasets. SPEER shows gains in both coverage and faithfulness\nmetrics over non-guided and guided baselines.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02369v1"}
{"title": "Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models", "author": "Uday Allu, Biddwan Ahmed, Vishesh Tripathi", "abstract": "The conventional use of the Retrieval-Augmented Generation (RAG) architecture\nhas proven effective for retrieving information from diverse documents.\nHowever, challenges arise in handling complex table queries, especially within\nPDF documents containing intricate tabular structures.This research introduces\nan innovative approach to enhance the accuracy of complex table queries in\nRAG-based systems. Our methodology involves storing PDFs in the retrieval\ndatabase and extracting tabular content separately. The extracted tables\nundergo a process of context enrichment, concatenating headers with\ncorresponding values. To ensure a comprehensive understanding of the enriched\ndata, we employ a fine-tuned version of the Llama-2-chat language model for\nsummarisation within the RAG architecture. Furthermore, we augment the tabular\ndata with contextual sense using the ChatGPT 3.5 API through a one-shot prompt.\nThis enriched data is then fed into the retrieval database alongside other\nPDFs. Our approach aims to significantly improve the precision of complex table\nqueries, offering a promising solution to a longstanding challenge in\ninformation retrieval.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CL"], "links": "http://arxiv.org/abs/2401.02333v1"}
{"title": "LLaVA-$φ$: Efficient Multi-Modal Assistant with Small Language Model", "author": "Yichen Zhu, Minjie Zhu, Ning Liu, Zhicai Ou, Xiaofeng Mou, Jian Tang", "abstract": "In this paper, we introduce LLaVA-$\\phi$ (LLaVA-Phi), an efficient\nmulti-modal assistant that harnesses the power of the recently advanced small\nlanguage model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks a\nnotable advancement in the realm of compact multi-modal models. It demonstrates\nthat even smaller language models, with as few as 2.7B parameters, can\neffectively engage in intricate dialogues that integrate both textual and\nvisual elements, provided they are trained with high-quality corpora. Our model\ndelivers commendable performance on publicly available benchmarks that\nencompass visual comprehension, reasoning, and knowledge-based perception.\nBeyond its remarkable performance in multi-modal dialogue tasks, our model\nopens new avenues for applications in time-sensitive environments and systems\nthat require real-time interaction, such as embodied agents. It highlights the\npotential of smaller language models to achieve sophisticated levels of\nunderstanding and interaction, while maintaining greater resource\nefficiency.The project is available at {https://github.com/zhuyiche/llava-phi}.", "published": "2024-01-04", "categories": ["cs.CV", "cs.CL"], "links": "http://arxiv.org/abs/2401.02330v1"}
{"title": "Are LLMs Robust for Spoken Dialogues?", "author": "Seyed Mahed Mousavi, Gabriel Roccabruna, Simone Alghisi, Massimo Rizzoli, Mirco Ravanelli, Giuseppe Riccardi", "abstract": "Large Pre-Trained Language Models have demonstrated state-of-the-art\nperformance in different downstream tasks, including dialogue state tracking\nand end-to-end response generation. Nevertheless, most of the publicly\navailable datasets and benchmarks on task-oriented dialogues focus on written\nconversations. Consequently, the robustness of the developed models to spoken\ninteractions is unknown. In this work, we have evaluated the performance of\nLLMs for spoken task-oriented dialogues on the DSTC11 test sets. Due to the\nlack of proper spoken dialogue datasets, we have automatically transcribed a\ndevelopment set of spoken dialogues with a state-of-the-art ASR engine. We have\ncharacterized the ASR-error types and their distributions and simulated these\nerrors in a large dataset of dialogues. We report the intrinsic (perplexity)\nand extrinsic (human evaluation) performance of fine-tuned GPT-2 and T5 models\nin two subtasks of response generation and dialogue state tracking,\nrespectively. The results show that LLMs are not robust to spoken noise by\ndefault, however, fine-tuning/training such models on a proper dataset of\nspoken TODs can result in a more robust performance.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02297v1"}
{"title": "Rethinking Response Evaluation from Interlocutor's Eye for Open-Domain Dialogue Systems", "author": "Yuma Tsuta, Naoki Yoshinaga, Shoetsu Sato, Masashi Toyoda", "abstract": "Open-domain dialogue systems have started to engage in continuous\nconversations with humans. Those dialogue systems are required to be adjusted\nto the human interlocutor and evaluated in terms of their perspective. However,\nit is questionable whether the current automatic evaluation methods can\napproximate the interlocutor's judgments. In this study, we analyzed and\nexamined what features are needed in an automatic response evaluator from the\ninterlocutor's perspective. The first experiment on the Hazumi dataset revealed\nthat interlocutor awareness plays a critical role in making automatic response\nevaluation correlate with the interlocutor's judgments. The second experiment\nusing massive conversations on X (formerly Twitter) confirmed that dialogue\ncontinuity prediction can train an interlocutor-aware response evaluator\nwithout human feedback while revealing the difficulty in evaluating generated\nresponses compared to human responses.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02256v1"}
{"title": "L3Cube-IndicNews: News-based Short Text and Long Document Classification Datasets in Indic Languages", "author": "Aishwarya Mirashi, Srushti Sonavane, Purva Lingayat, Tejas Padhiyar, Raviraj Joshi", "abstract": "In this work, we introduce L3Cube-IndicNews, a multilingual text\nclassification corpus aimed at curating a high-quality dataset for Indian\nregional languages, with a specific focus on news headlines and articles. We\nhave centered our work on 10 prominent Indic languages, including Hindi,\nBengali, Marathi, Telugu, Tamil, Gujarati, Kannada, Odia, Malayalam, and\nPunjabi. Each of these news datasets comprises 10 or more classes of news\narticles. L3Cube-IndicNews offers 3 distinct datasets tailored to handle\ndifferent document lengths that are classified as: Short Headlines\nClassification (SHC) dataset containing the news headline and news category,\nLong Document Classification (LDC) dataset containing the whole news article\nand the news category, and Long Paragraph Classification (LPC) containing\nsub-articles of the news and the news category. We maintain consistent labeling\nacross all 3 datasets for in-depth length-based analysis. We evaluate each of\nthese Indic language datasets using 4 different models including monolingual\nBERT, multilingual Indic Sentence BERT (IndicSBERT), and IndicBERT. This\nresearch contributes significantly to expanding the pool of available text\nclassification datasets and also makes it possible to develop topic\nclassification models for Indian regional languages. This also serves as an\nexcellent resource for cross-lingual analysis owing to the high overlap of\nlabels among languages. The datasets and models are shared publicly at\nhttps://github.com/l3cube-pune/indic-nlp", "published": "2024-01-04", "categories": ["cs.CL", "cs.LG"], "links": "http://arxiv.org/abs/2401.02254v1"}
{"title": "Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph", "author": "Rikui Huang, Wei Wei, Xiaoye Qu, Wenfeng Xie, Xianling Mao, Dangyang Chen", "abstract": "Temporal Knowledge Graph (TKG) is an extension of regular knowledge graph by\nattaching the time scope. Existing temporal knowledge graph question answering\n(TKGQA) models solely approach simple questions, owing to the prior assumption\nthat each question only contains a single temporal fact with explicit/implicit\ntemporal constraints. Hence, they perform poorly on questions which own\nmultiple temporal facts. In this paper, we propose \\textbf{\\underline{J}}oint\n\\textbf{\\underline{M}}ulti \\textbf{\\underline{F}}acts\n\\textbf{\\underline{R}}easoning \\textbf{\\underline{N}}etwork (JMFRN), to jointly\nreasoning multiple temporal facts for accurately answering \\emph{complex}\ntemporal questions. Specifically, JMFRN first retrieves question-related\ntemporal facts from TKG for each entity of the given complex question. For\njoint reasoning, we design two different attention (\\ie entity-aware and\ntime-aware) modules, which are suitable for universal settings, to aggregate\nentities and timestamps information of retrieved facts. Moreover, to filter\nincorrect type answers, we introduce an additional answer type discrimination\ntask. Extensive experiments demonstrate our proposed method significantly\noutperforms the state-of-art on the well-known complex temporal question\nbenchmark TimeQuestions.", "published": "2024-01-04", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.02212v1"}
{"title": "DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models", "author": "Songbo Hu, Xiaobin Wang, Zhangdie Yuan, Anna Korhonen, Ivan Vulić", "abstract": "We present DIALIGHT, a toolkit for developing and evaluating multilingual\nTask-Oriented Dialogue (ToD) systems which facilitates systematic evaluations\nand comparisons between ToD systems using fine-tuning of Pretrained Language\nModels (PLMs) and those utilising the zero-shot and in-context learning\ncapabilities of Large Language Models (LLMs). In addition to automatic\nevaluation, this toolkit features (i) a secure, user-friendly web interface for\nfine-grained human evaluation at both local utterance level and global dialogue\nlevel, and (ii) a microservice-based backend, improving efficiency and\nscalability. Our evaluations reveal that while PLM fine-tuning leads to higher\naccuracy and coherence, LLM-based systems excel in producing diverse and\nlikeable responses. However, we also identify significant challenges of LLMs in\nadherence to task-specific instructions and generating outputs in multiple\nlanguages, highlighting areas for future research. We hope this open-sourced\ntoolkit will serve as a valuable resource for researchers aiming to develop and\nproperly evaluate multilingual ToD systems and will lower, currently still\nhigh, entry barriers in the field.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02208v1"}
{"title": "Location Aware Modular Biencoder for Tourism Question Answering", "author": "Haonan Li, Martin Tomko, Timothy Baldwin", "abstract": "Answering real-world tourism questions that seek Point-of-Interest (POI)\nrecommendations is challenging, as it requires both spatial and non-spatial\nreasoning, over a large candidate pool. The traditional method of encoding each\npair of question and POI becomes inefficient when the number of candidates\nincreases, making it infeasible for real-world applications. To overcome this,\nwe propose treating the QA task as a dense vector retrieval problem, where we\nencode questions and POIs separately and retrieve the most relevant POIs for a\nquestion by utilizing embedding space similarity. We use pretrained language\nmodels (PLMs) to encode textual information, and train a location encoder to\ncapture spatial information of POIs. Experiments on a real-world tourism QA\ndataset demonstrate that our approach is effective, efficient, and outperforms\nprevious methods across all metrics. Enabled by the dense retrieval\narchitecture, we further build a global evaluation baseline, expanding the\nsearch space by 20 times compared to previous work. We also explore several\nfactors that impact on the model's performance through follow-up experiments.\nOur code and model are publicly available at https://github.com/haonan-li/LAMB.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02187v1"}
{"title": "Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and LightGBM models", "author": "Rushi Chavda, Darshan Makwana, Vraj Patel, Anupam Shukla", "abstract": "This paper describes approaches and results for shared Task 1 and 4 of\nSMMH4-23 by Team Shayona. Shared Task-1 was binary classification of english\ntweets self-reporting a COVID-19 diagnosis, and Shared Task-4 was Binary\nclassification of English Reddit posts self-reporting a social anxiety disorder\ndiagnosis. Our team has achieved the highest f1-score 0.94 in Task-1 among all\nparticipants. We have leveraged the Transformer model (BERT) in combination\nwith the LightGBM model for both tasks.", "published": "2024-01-04", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.02158v1"}
{"title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study", "author": "Ziqiang Zheng, Yiwei Chen, Jipeng Zhang, Tuan-Anh Vu, Huimin Zeng, Yue Him Wong Tim, Sai-Kit Yeung", "abstract": "Large language models (LLMs) have demonstrated a powerful ability to answer\nvarious queries as a general-purpose assistant. The continuous multi-modal\nlarge language models (MLLM) empower LLMs with the ability to perceive visual\nsignals. The launch of GPT-4 (Generative Pre-trained Transformers) has\ngenerated significant interest in the research communities. GPT-4V(ison) has\ndemonstrated significant power in both academia and industry fields, as a focal\npoint in a new artificial intelligence generation. Though significant success\nwas achieved by GPT-4V, exploring MLLMs in domain-specific analysis (e.g.,\nmarine analysis) that required domain-specific knowledge and expertise has\ngained less attention. In this study, we carry out the preliminary and\ncomprehensive case study of utilizing GPT-4V for marine analysis. This report\nconducts a systematic evaluation of existing GPT-4V, assessing the performance\nof GPT-4V on marine research and also setting a new standard for future\ndevelopments in MLLMs. The experimental results of GPT-4V show that the\nresponses generated by GPT-4V are still far away from satisfying the\ndomain-specific requirements of the marine professions. All images and prompts\nused in this study will be available at\nhttps://github.com/hkust-vgd/Marine_GPT-4V_Eval", "published": "2024-01-04", "categories": ["cs.CL", "cs.CV"], "links": "http://arxiv.org/abs/2401.02147v1"}
{"title": "DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models", "author": "Wendi Cui, Jiaxin Zhang, Zhuohang Li, Lopez Damien, Kamalika Das, Bradley Malin, Sricharan Kumar", "abstract": "Evaluating the quality and variability of text generated by Large Language\nModels (LLMs) poses a significant, yet unresolved research challenge.\nTraditional evaluation methods, such as ROUGE and BERTScore, which measure\ntoken similarity, often fail to capture the holistic semantic equivalence. This\nresults in a low correlation with human judgments and intuition, which is\nespecially problematic in high-stakes applications like healthcare and finance\nwhere reliability, safety, and robust decision-making are highly critical. This\nwork proposes DCR, an automated framework for evaluating and improving the\nconsistency of LLM-generated texts using a divide-conquer-reasoning approach.\nUnlike existing LLM-based evaluators that operate at the paragraph level, our\nmethod employs a divide-and-conquer evaluator (DCE) that breaks down the\nparagraph-to-paragraph comparison between two generated responses into\nindividual sentence-to-paragraph comparisons, each evaluated based on\npredefined criteria. To facilitate this approach, we introduce an automatic\nmetric converter (AMC) that translates the output from DCE into an\ninterpretable numeric score. Beyond the consistency evaluation, we further\npresent a reason-assisted improver (RAI) that leverages the analytical reasons\nwith explanations identified by DCE to generate new responses aimed at reducing\nthese inconsistencies. Through comprehensive and systematic empirical analysis,\nwe show that our approach outperforms state-of-the-art methods by a large\nmargin (e.g., +19.3% and +24.3% on the SummEval dataset) in evaluating the\nconsistency of LLM generation across multiple benchmarks in semantic, factual,\nand summarization consistency tasks. Our approach also substantially reduces\nnearly 90% of output inconsistencies, showing promise for effective\nhallucination mitigation.", "published": "2024-01-04", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.02132v1"}
{"title": "PEFT for Speech: Unveiling Optimal Placement, Merging Strategies, and Ensemble Techniques", "author": "Tzu-Han Lin, How-Shing Wang, Hao-Yung Weng, Kuang-Chen Peng, Zih-Ching Chen, Hung-yi Lee", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) is increasingly recognized as an\neffective method in speech processing. However, the optimal approach and the\nplacement of PEFT methods remain inconclusive. Our study conducts extensive\nexperiments to compare different PEFT methods and their layer-wise placement\nadapting Differentiable Architecture Search (DARTS). We also explore the use of\nensemble learning to leverage diverse PEFT strategies. The results reveal that\nDARTS does not outperform the baseline approach, which involves inserting the\nsame PEFT method into all layers of a Self-Supervised Learning (SSL) model. In\ncontrast, an ensemble learning approach, particularly one employing majority\nvoting, demonstrates superior performance. Our statistical evidence indicates\nthat different PEFT methods learn in varied ways. This variation might explain\nwhy the synergistic integration of various PEFT methods through ensemble\nlearning can harness their unique learning capabilities more effectively\ncompared to individual layer-wise optimization.", "published": "2024-01-04", "categories": ["cs.CL", "cs.SD", "eess.AS"], "links": "http://arxiv.org/abs/2401.02122v1"}
{"title": "Using LLM to select the right SQL Query from candidates", "author": "Zhenwen Li, Tao Xie", "abstract": "Text-to-SQL models can generate a list of candidate SQL queries, and the best\nquery is often in the candidate list, but not at the top of the list. An\neffective re-rank method can select the right SQL query from the candidate list\nand improve the model's performance. Previous studies on code generation\nautomatically generate test cases and use them to re-rank candidate codes.\nHowever, automatic test case generation for text-to-SQL is an understudied\nfield. We propose an automatic test case generation method that first generates\na database and then uses LLMs to predict the ground truth, which is the\nexpected execution results of the ground truth SQL query on this database. To\nreduce the difficulty for LLMs to predict, we conduct experiments to search for\nways to generate easy databases for LLMs and design easy-to-understand prompts.\nBased on our test case generation method, we propose a re-rank method to select\nthe right SQL query from the candidate list. Given a candidate list, our method\ncan generate test cases and re-rank the candidate list according to their pass\nnumbers on these test cases and their generation probabilities. The experiment\nresults on the validation dataset of Spider show that the performance of some\nstate-of-the-art models can get a 3.6\\% improvement after applying our re-rank\nmethod.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02115v1"}
{"title": "Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe", "author": "Mincong Huang, Chao Wang, Chi Ma, Yineng Zhang, Peng Zhang, Lei Yu", "abstract": "Pipeline parallelism is an essential technique in the training of large-scale\nTransformer models. However, it suffers from imbalanced memory consumption,\nleading to insufficient memory utilization. The BPipe technique was proposed to\naddress this issue and has proven effective in the GPT-3 model. Nevertheless,\nour experiments have not yielded similar benefits for LLaMA training.\nAdditionally, BPipe only yields negligible benefits for GPT-3 training when\napplying flash attention. We analyze the underlying causes of the divergent\nperformance of BPipe on GPT-3 and LLaMA. Furthermore, we introduce a novel\nmethod to estimate the performance of BPipe.", "published": "2024-01-04", "categories": ["cs.LG", "cs.CL", "cs.DC"], "links": "http://arxiv.org/abs/2401.02088v1"}
{"title": "ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers", "author": "Chen Zheng, Ke Sun, Da Tang, Yukun Ma, Yuyu Zhang, Chenguang Xi, Xun Zhou", "abstract": "The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA\nencounter limitations in domain-specific tasks, with these models often lacking\ndepth and accuracy in specialized areas, and exhibiting a decrease in general\ncapabilities when fine-tuned, particularly analysis ability in small sized\nmodels. To address these gaps, we introduce ICE-GRT, utilizing Reinforcement\nLearning from Human Feedback (RLHF) grounded in Proximal Policy Optimization\n(PPO), demonstrating remarkable ability in in-domain scenarios without\ncompromising general task performance. Our exploration of ICE-GRT highlights\nits understanding and reasoning ability to not only generate robust answers but\nalso to provide detailed analyses of the reasons behind the answer. This\ncapability marks a significant progression beyond the scope of Supervised\nFine-Tuning models. The success of ICE-GRT is dependent on several crucial\nfactors, including Appropriate Data, Reward Size Scaling, KL-Control, Advantage\nNormalization, etc. The ICE-GRT model exhibits state-of-the-art performance in\ndomain-specific tasks and across 12 general Language tasks against equivalent\nsize and even larger size LLMs, highlighting the effectiveness of our approach.\nWe provide a comprehensive analysis of the ICE-GRT, underscoring the\nsignificant advancements it brings to the field of LLM.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02072v1"}
{"title": "Understanding LLMs: A Comprehensive Overview from Training to Inference", "author": "Yiheng Liu, Hao He, Tianle Han, Xu Zhang, Mengyuan Liu, Jiaming Tian, Yutong Zhang, Jiaqi Wang, Xiaohui Gao, Tianyang Zhong, Yi Pan, Shaochen Xu, Zihao Wu, Zhengliang Liu, Xin Zhang, Shu Zhang, Xintao Hu, Tuo Zhang, Ning Qiang, Tianming Liu, Bao Ge", "abstract": "The introduction of ChatGPT has led to a significant increase in the\nutilization of Large Language Models (LLMs) for addressing downstream tasks.\nThere's an increasing focus on cost-efficient training and deployment within\nthis context. Low-cost training and deployment of LLMs represent the future\ndevelopment trend. This paper reviews the evolution of large language model\ntraining techniques and inference deployment technologies aligned with this\nemerging trend. The discussion on training includes various aspects, including\ndata preprocessing, training architecture, pre-training tasks, parallel\ntraining, and relevant content related to model fine-tuning. On the inference\nside, the paper covers topics such as model compression, parallel computation,\nmemory scheduling, and structural optimization. It also explores LLMs'\nutilization and provides insights into their future development.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02038v1"}
{"title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts", "author": "Wei Zhu, Wenfeng Li, Xing Tian, Pengfei Wang, Xiaoling Wang, Jin Chen, Yuanbin Wu, Yuan Ni, Guotong Xie", "abstract": "Knowledge of the medical decision process, which can be modeled as medical\ndecision trees (MDTs), is critical to build clinical decision support systems.\nHowever, the current MDT construction methods rely heavily on time-consuming\nand laborious manual annotation. In this work, we propose a novel task,\nText2MDT, to explore the automatic extraction of MDTs from medical texts such\nas medical guidelines and textbooks. We normalize the form of the MDT and\ncreate an annotated Text-to-MDT dataset in Chinese with the participation of\nmedical experts. We investigate two different methods for the Text2MDT tasks:\n(a) an end-to-end framework which only relies on a GPT style large language\nmodels (LLM) instruction tuning to generate all the node information and tree\nstructures. (b) The pipeline framework which decomposes the Text2MDT task to\nthree subtasks. Experiments on our Text2MDT dataset demonstrate that: (a) the\nend-to-end method basd on LLMs (7B parameters or larger) show promising\nresults, and successfully outperform the pipeline methods. (b) The\nchain-of-thought (COT) prompting method \\cite{Wei2022ChainOT} can improve the\nperformance of the fine-tuned LLMs on the Text2MDT test set. (c) the\nlightweight pipelined method based on encoder-based pretrained models can\nperform comparably with LLMs with model complexity two magnititudes smaller.\nOur Text2MDT dataset is open-sourced at\n\\url{https://tianchi.aliyun.com/dataset/95414}, and the source codes are\nopen-sourced at \\url{https://github.com/michael-wzhu/text2dt}.", "published": "2024-01-04", "categories": ["cs.CL"], "links": "http://arxiv.org/abs/2401.02034v1"}
{"title": "Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives", "author": "Wenqi Zhang, Yongliang Shen, Linjuan Wu, Qiuying Peng, Jun Wang, Yueting Zhuang, Weiming Lu", "abstract": "The reflection capacity of Large Language Model (LLM) has garnered extensive\nattention. A post-hoc prompting strategy, e.g., reflexion and self-refine,\nrefines LLM's response based on self-evaluated or external feedback. However,\nrecent research indicates without external feedback, LLM's intrinsic reflection\nis unstable. Our investigation unveils that the key bottleneck is the quality\nof the self-evaluated feedback. We find LLMs often exhibit overconfidence or\nhigh randomness when self-evaluate, offering stubborn or inconsistent feedback,\nwhich causes poor reflection. To remedy this, we advocate Self-Contrast: It\nadaptively explores diverse solving perspectives tailored to the request,\ncontrasts the differences, and summarizes these discrepancies into a checklist\nwhich could be used to re-examine and eliminate discrepancies. Our method\nendows LLM with diverse perspectives to alleviate stubborn biases. Moreover,\ntheir discrepancies indicate potential errors or inherent uncertainties that\nLLM often overlooks. Reflecting upon these can catalyze more accurate and\nstable reflection. Experiments conducted on a series of reasoning and\ntranslation tasks with different LLMs serve to underscore the effectiveness and\ngenerality of our strategy.", "published": "2024-01-04", "categories": ["cs.CL", "cs.AI"], "links": "http://arxiv.org/abs/2401.02009v1"}
